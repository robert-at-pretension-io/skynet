2024-01-13 14:29:56,541 - INFO - __main__ - Skynet started
2024-01-13 14:29:56,541 - INFO - __main__ - Loading environment variables
2024-01-13 14:29:56,541 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-13 14:29:56,541 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-13 14:29:56,541 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-13 14:29:56,541 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-13 14:29:56,541 - INFO - __main__ - Loaded functions from functions
2024-01-13 14:29:56,542 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-13 14:29:56,542 - INFO - functions.get_functions - file size: 2609
2024-01-13 14:29:56,543 - INFO - functions.get_functions - tree size: 16
2024-01-13 14:29:56,689 - INFO - functions.get_functions - Looking at function: get_links
2024-01-13 14:29:56,790 - INFO - functions.get_functions - Looking at function: process_command
2024-01-13 14:29:56,792 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-13 14:29:56,792 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-13 14:29:56,793 - INFO - functions.get_functions - file size: 1926
2024-01-13 14:29:56,793 - INFO - functions.get_functions - tree size: 5
2024-01-13 14:29:56,794 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-13 14:29:56,795 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-13 14:29:56,795 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-13 14:29:56,796 - INFO - functions.get_functions - file size: 2971
2024-01-13 14:29:56,797 - INFO - functions.get_functions - tree size: 10
2024-01-13 14:29:56,803 - INFO - functions.get_functions - Looking at function: read_file
2024-01-13 14:29:56,808 - INFO - functions.get_functions - Looking at function: write_file
2024-01-13 14:29:56,809 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-13 14:29:56,810 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-13 14:29:56,811 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-13 14:29:56,816 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-13 14:29:56,816 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-13 14:29:56,818 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-13 14:29:56,824 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-13 14:29:56,825 - INFO - functions.get_functions - file size: 0
2024-01-13 14:29:56,825 - INFO - functions.get_functions - tree size: 0
2024-01-13 14:29:56,825 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-13 14:29:56,826 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-13 14:29:56,826 - INFO - functions.get_functions - file size: 2135
2024-01-13 14:29:56,827 - INFO - functions.get_functions - tree size: 8
2024-01-13 14:29:56,827 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-13 14:29:56,828 - INFO - functions.get_functions - Looking at function: create_function
2024-01-13 14:29:56,829 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-13 14:29:56,830 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-13 14:29:56,832 - INFO - __main__ - Loaded 4 functions from ./functions/prompt_creation.py
2024-01-13 14:29:56,840 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-13 14:29:56,841 - INFO - functions.get_functions - file size: 0
2024-01-13 14:29:56,841 - INFO - functions.get_functions - tree size: 0
2024-01-13 14:29:56,841 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-13 14:29:56,843 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-13 14:29:56,846 - INFO - functions.get_functions - file size: 5276
2024-01-13 14:29:56,850 - INFO - functions.get_functions - tree size: 9
2024-01-13 14:29:56,854 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-13 14:29:56,857 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-13 14:29:56,861 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-13 14:29:56,866 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-13 14:29:56,872 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-13 14:29:56,873 - INFO - functions.prompt_creation - Describing function
2024-01-13 14:29:56,879 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def load_functions_from_file(file_path) -> [FunctionInfo]:\n    try:\n        with open(file_path, 'r') as file:\n            file_contents = file.read()\n            logger.info(f'file size: {len(file_contents)}')\n            try:\n                tree = ast.parse(file_contents, type_comments=True)\n                logger.info(f'tree size: {len(tree.body)}')\n                functions = []\n                imported_modules = {}\n                for node in ast.walk(tree):\n                    if isinstance(node, ast.Import):\n                        for name in node.names:\n                            imported_modules[name.name] = importlib.import_module(name.name)\n                    elif isinstance(node, ast.ImportFrom):\n                        module = importlib.import_module(node.module)\n                        for name in node.names:\n                            imported_modules[name.name] = getattr(module, name.name)\n                    if isinstance(node, ast.FunctionDef):\n                        logger.info(f'Looking at function: {node.name}')\n                        func_name = node.name\n                        func_code = compile(ast.Module(body=[node], type_ignores=[]), filename='<ast>', mode='exec')\n                        temp_namespace = {**imported_modules}\n                        exec(func_code, temp_namespace)\n                        func = temp_namespace[func_name]\n                        sig = inspect.signature(func)\n                        arg_types = {param_name: param.annotation for param_name, param in sig.parameters.items()}\n                        source_code = ast.unparse(node)\n                        function_info = FunctionInfo(func_name, file_path, source_code, '')\n                        functions.append(function_info)\n                return functions\n            except SyntaxError as e:\n                logger.error(f'Syntax error in {file_path}: {e}')\n                return []\n            except Exception as e:\n                logger.error(f'Error loading functions from {file_path}: {e}')\n                return []\n    except FileNotFoundError:\n        logger.error(f'The file {file_path} was not found.')\n        return []\n    except IOError:\n        logger.error(f'Error reading the file {file_path}.')\n        return []\n    \n    Description:"}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-13 14:29:56,917 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-13 14:29:57,053 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8f9d3b2390>
2024-01-13 14:29:57,053 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8f9dd06600> server_hostname='api.openai.com' timeout=5.0
2024-01-13 14:29:57,117 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8f9db7ecd0>
2024-01-13 14:29:57,118 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-13 14:29:57,118 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-13 14:29:57,118 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-13 14:29:57,119 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-13 14:29:57,119 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-13 14:29:59,062 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 13 Jan 2024 19:29:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1832'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79370'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'472ms'), (b'x-request-id', b'7fa1197b44352f0c7b3406b7f62617d0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=IXURbJxAgM8SVdq6AuN2P5xzRW8pph50VAcI_7DPaec-1705174199-1-AQ6eEn3+TnBBa7Bb0KRmFIRySzJflux59DpiHYpWqdCgHJC8OxXDuTwhcVbNf8jnvLtqqF39WVs4yxY2jzwVMOg=; path=/; expires=Sat, 13-Jan-24 19:59:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=pKqUAUfvVxrme34W1Y2v6q9TQ.eRooValIW8LL7mqPY-1705174199041-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84500d0c2eb97bb1-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-13 14:29:59,063 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-13 14:29:59,064 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-13 14:29:59,065 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-13 14:29:59,065 - DEBUG - httpcore.http11 - response_closed.started
2024-01-13 14:29:59,065 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-13 14:29:59,066 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-13 14:29:59,069 - INFO - functions.prompt_creation - Describing function
2024-01-13 14:29:59,080 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def load_functions_from_file(file_path) -> [FunctionInfo]:\n    try:\n        with open(file_path, 'r') as file:\n            file_contents = file.read()\n            logger.info(f'file size: {len(file_contents)}')\n            try:\n                tree = ast.parse(file_contents, type_comments=True)\n                logger.info(f'tree size: {len(tree.body)}')\n                functions = []\n                imported_modules = {}\n                for node in ast.walk(tree):\n                    if isinstance(node, ast.Import):\n                        for name in node.names:\n                            imported_modules[name.name] = importlib.import_module(name.name)\n                    elif isinstance(node, ast.ImportFrom):\n                        module = importlib.import_module(node.module)\n                        for name in node.names:\n                            imported_modules[name.name] = getattr(module, name.name)\n                    if isinstance(node, ast.FunctionDef):\n                        logger.info(f'Looking at function: {node.name}')\n                        func_name = node.name\n                        func_code = compile(ast.Module(body=[node], type_ignores=[]), filename='<ast>', mode='exec')\n                        temp_namespace = {**imported_modules}\n                        exec(func_code, temp_namespace)\n                        func = temp_namespace[func_name]\n                        sig = inspect.signature(func)\n                        arg_types = {param_name: param.annotation for param_name, param in sig.parameters.items()}\n                        source_code = ast.unparse(node)\n                        function_info = FunctionInfo(func_name, file_path, source_code, '')\n                        functions.append(function_info)\n                return functions\n            except SyntaxError as e:\n                logger.error(f'Syntax error in {file_path}: {e}')\n                return []\n            except Exception as e:\n                logger.error(f'Error loading functions from {file_path}: {e}')\n                return []\n    except FileNotFoundError:\n        logger.error(f'The file {file_path} was not found.')\n        return []\n    except IOError:\n        logger.error(f'Error reading the file {file_path}.')\n        return []\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def list_functions(functions):\n    logger.info('Available functions:')\n    for func_name, func_info in functions.items():\n        arg_types = func_info['arg_types']\n        logger.info(f'Function: {func_name}, Argument Types: {arg_types}')\n    \n    Description:"}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-13 14:29:59,082 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-13 14:29:59,083 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-13 14:29:59,083 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-13 14:29:59,084 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-13 14:29:59,084 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-13 14:30:01,213 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 13 Jan 2024 19:30:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1987'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79266'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'550ms'), (b'x-request-id', b'871161f984fbfa4b6370f8f7ae47ff72'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84500d18684d7bb1-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-13 14:30:01,214 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-13 14:30:01,215 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-13 14:30:01,215 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-13 14:30:01,216 - DEBUG - httpcore.http11 - response_closed.started
2024-01-13 14:30:01,216 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-13 14:30:01,216 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-13 14:30:01,218 - INFO - functions.prompt_creation - Describing function
2024-01-13 14:30:01,229 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def load_functions_from_file(file_path) -> [FunctionInfo]:\n    try:\n        with open(file_path, 'r') as file:\n            file_contents = file.read()\n            logger.info(f'file size: {len(file_contents)}')\n            try:\n                tree = ast.parse(file_contents, type_comments=True)\n                logger.info(f'tree size: {len(tree.body)}')\n                functions = []\n                imported_modules = {}\n                for node in ast.walk(tree):\n                    if isinstance(node, ast.Import):\n                        for name in node.names:\n                            imported_modules[name.name] = importlib.import_module(name.name)\n                    elif isinstance(node, ast.ImportFrom):\n                        module = importlib.import_module(node.module)\n                        for name in node.names:\n                            imported_modules[name.name] = getattr(module, name.name)\n                    if isinstance(node, ast.FunctionDef):\n                        logger.info(f'Looking at function: {node.name}')\n                        func_name = node.name\n                        func_code = compile(ast.Module(body=[node], type_ignores=[]), filename='<ast>', mode='exec')\n                        temp_namespace = {**imported_modules}\n                        exec(func_code, temp_namespace)\n                        func = temp_namespace[func_name]\n                        sig = inspect.signature(func)\n                        arg_types = {param_name: param.annotation for param_name, param in sig.parameters.items()}\n                        source_code = ast.unparse(node)\n                        function_info = FunctionInfo(func_name, file_path, source_code, '')\n                        functions.append(function_info)\n                return functions\n            except SyntaxError as e:\n                logger.error(f'Syntax error in {file_path}: {e}')\n                return []\n            except Exception as e:\n                logger.error(f'Error loading functions from {file_path}: {e}')\n                return []\n    except FileNotFoundError:\n        logger.error(f'The file {file_path} was not found.')\n        return []\n    except IOError:\n        logger.error(f'Error reading the file {file_path}.')\n        return []\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def list_functions(functions):\n    logger.info('Available functions:')\n    for func_name, func_info in functions.items():\n        arg_types = func_info['arg_types']\n        logger.info(f'Function: {func_name}, Argument Types: {arg_types}')\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_argument_values(arg_types):\n    args = []\n    for arg_name, arg_type in arg_types.items():\n        while True:\n            user_input = input(f'Enter value for {arg_name} ({arg_type}): ')\n            try:\n                if arg_type == int:\n                    converted_value = int(user_input)\n                elif arg_type == float:\n                    converted_value = float(user_input)\n                elif arg_type == bool:\n                    converted_value = user_input.lower() in ['true', '1', 'yes']\n                elif arg_type == str:\n                    converted_value = user_input\n                else:\n                    converted_value = eval(user_input)\n                if not isinstance(converted_value, arg_type) and arg_type != inspect._empty:\n                    raise TypeError(f'Incorrect type for {arg_name}, expected {arg_type}')\n                break\n            except ValueError as e:\n                logger.error(f'Invalid input: {e}')\n            except TypeError as e:\n                logger.error(e)\n            except Exception as e:\n                logger.error(f'Error processing input: {e}')\n        args.append(converted_value)\n    return args\n    \n    Description:"}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-13 14:30:01,230 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-13 14:30:01,231 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-13 14:30:01,231 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-13 14:30:01,231 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-13 14:30:01,231 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-13 14:30:02,748 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 13 Jan 2024 19:30:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1174'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78923'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'807ms'), (b'x-request-id', b'f21e679a51c0ea669e3063e7cb2f2599'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84500d25da217bb1-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-13 14:30:02,749 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-13 14:30:02,749 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-13 14:30:02,751 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-13 14:30:02,751 - DEBUG - httpcore.http11 - response_closed.started
2024-01-13 14:30:02,751 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-13 14:30:02,751 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-13 14:30:02,754 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-13 14:30:02,903 - DEBUG - httpcore.connection - close.started
2024-01-13 14:30:02,904 - DEBUG - httpcore.connection - close.complete
2024-01-14 11:11:53,924 - INFO - __main__ - Skynet started
2024-01-14 11:11:53,924 - INFO - __main__ - Loading environment variables
2024-01-14 11:11:53,924 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 11:11:53,924 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 11:11:53,924 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 11:11:53,924 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 11:11:53,925 - INFO - __main__ - Loaded functions from functions
2024-01-14 11:11:53,925 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 11:11:53,925 - INFO - functions.get_functions - file size: 2609
2024-01-14 11:11:53,926 - INFO - functions.get_functions - tree size: 16
2024-01-14 11:11:54,101 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 11:11:54,230 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 11:11:54,232 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 11:11:54,232 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 11:11:54,232 - INFO - functions.get_functions - file size: 1926
2024-01-14 11:11:54,233 - INFO - functions.get_functions - tree size: 5
2024-01-14 11:11:54,233 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 11:11:54,234 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 11:11:54,234 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 11:11:54,234 - INFO - functions.get_functions - file size: 2971
2024-01-14 11:11:54,236 - INFO - functions.get_functions - tree size: 10
2024-01-14 11:11:54,236 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 11:11:54,237 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 11:11:54,237 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 11:11:54,238 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 11:11:54,238 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 11:11:54,239 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 11:11:54,240 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 11:11:54,241 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 11:11:54,241 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 11:11:54,242 - INFO - functions.get_functions - file size: 0
2024-01-14 11:11:54,242 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:11:54,242 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 11:11:54,242 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 11:11:54,242 - INFO - functions.get_functions - file size: 2135
2024-01-14 11:11:54,243 - INFO - functions.get_functions - tree size: 8
2024-01-14 11:11:54,243 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 11:11:54,306 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 11:11:54,307 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 11:11:54,308 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 11:11:54,309 - INFO - __main__ - Loaded 4 functions from ./functions/prompt_creation.py
2024-01-14 11:11:54,309 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 11:11:54,310 - INFO - functions.get_functions - file size: 0
2024-01-14 11:11:54,310 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:11:54,310 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 11:11:54,310 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 11:11:54,310 - INFO - functions.get_functions - file size: 5276
2024-01-14 11:11:54,312 - INFO - functions.get_functions - tree size: 9
2024-01-14 11:11:54,312 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 11:11:54,314 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 11:11:54,315 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 11:11:54,317 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 11:11:54,318 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 11:11:54,318 - ERROR - __main__ - Error loading existing function info from serialized_function_info.json
2024-01-14 11:13:25,327 - INFO - __main__ - Skynet started
2024-01-14 11:13:25,328 - INFO - __main__ - Loading environment variables
2024-01-14 11:13:25,328 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 11:13:25,328 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 11:13:25,328 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 11:13:25,328 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 11:13:25,328 - INFO - __main__ - Loaded functions from functions
2024-01-14 11:13:25,328 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 11:13:25,328 - INFO - functions.get_functions - file size: 2609
2024-01-14 11:13:25,330 - INFO - functions.get_functions - tree size: 16
2024-01-14 11:13:25,483 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 11:13:25,579 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 11:13:25,581 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 11:13:25,581 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 11:13:25,581 - INFO - functions.get_functions - file size: 1926
2024-01-14 11:13:25,582 - INFO - functions.get_functions - tree size: 5
2024-01-14 11:13:25,582 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 11:13:25,583 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 11:13:25,584 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 11:13:25,584 - INFO - functions.get_functions - file size: 2971
2024-01-14 11:13:25,585 - INFO - functions.get_functions - tree size: 10
2024-01-14 11:13:25,586 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 11:13:25,587 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 11:13:25,589 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 11:13:25,590 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 11:13:25,591 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 11:13:25,595 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 11:13:25,596 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 11:13:25,598 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 11:13:25,600 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 11:13:25,600 - INFO - functions.get_functions - file size: 0
2024-01-14 11:13:25,601 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:13:25,601 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 11:13:25,602 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 11:13:25,602 - INFO - functions.get_functions - file size: 2135
2024-01-14 11:13:25,603 - INFO - functions.get_functions - tree size: 8
2024-01-14 11:13:25,605 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 11:13:25,607 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 11:13:25,609 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 11:13:25,611 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 11:13:25,613 - INFO - __main__ - Loaded 4 functions from ./functions/prompt_creation.py
2024-01-14 11:13:25,614 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 11:13:25,615 - INFO - functions.get_functions - file size: 0
2024-01-14 11:13:25,616 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:13:25,616 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 11:13:25,617 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 11:13:25,618 - INFO - functions.get_functions - file size: 5276
2024-01-14 11:13:25,621 - INFO - functions.get_functions - tree size: 9
2024-01-14 11:13:25,622 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 11:13:25,625 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 11:13:25,626 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 11:13:25,631 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 11:13:25,633 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 11:13:25,635 - ERROR - __main__ - Error creating file serialized_function_info.json
2024-01-14 11:29:21,576 - INFO - __main__ - Skynet started
2024-01-14 11:29:21,579 - INFO - __main__ - Loading environment variables
2024-01-14 11:29:21,579 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 11:29:21,579 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 11:29:21,579 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 11:29:21,580 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 11:29:21,580 - INFO - __main__ - Loaded functions from functions
2024-01-14 11:29:21,580 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 11:29:21,580 - INFO - functions.get_functions - file size: 2609
2024-01-14 11:29:21,581 - INFO - functions.get_functions - tree size: 16
2024-01-14 11:29:21,815 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 11:29:21,994 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 11:29:21,995 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 11:29:21,995 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 11:29:21,996 - INFO - functions.get_functions - file size: 1926
2024-01-14 11:29:21,996 - INFO - functions.get_functions - tree size: 5
2024-01-14 11:29:21,996 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 11:29:21,998 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 11:29:21,998 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 11:29:21,998 - INFO - functions.get_functions - file size: 2971
2024-01-14 11:29:21,999 - INFO - functions.get_functions - tree size: 10
2024-01-14 11:29:21,999 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 11:29:22,000 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 11:29:22,000 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 11:29:22,001 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 11:29:22,001 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 11:29:22,002 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 11:29:22,002 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 11:29:22,004 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 11:29:22,004 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 11:29:22,004 - INFO - functions.get_functions - file size: 0
2024-01-14 11:29:22,004 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:29:22,004 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 11:29:22,004 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 11:29:22,005 - INFO - functions.get_functions - file size: 2135
2024-01-14 11:29:22,005 - INFO - functions.get_functions - tree size: 8
2024-01-14 11:29:22,005 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 11:29:22,007 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 11:29:22,007 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 11:29:22,008 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 11:29:22,013 - INFO - __main__ - Loaded 4 functions from ./functions/prompt_creation.py
2024-01-14 11:29:22,013 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 11:29:22,014 - INFO - functions.get_functions - file size: 0
2024-01-14 11:29:22,014 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:29:22,014 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 11:29:22,014 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 11:29:22,014 - INFO - functions.get_functions - file size: 5276
2024-01-14 11:29:22,016 - INFO - functions.get_functions - tree size: 9
2024-01-14 11:29:22,016 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 11:29:22,018 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 11:29:22,018 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 11:29:22,021 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 11:29:22,021 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 11:29:22,021 - ERROR - __main__ - Error loading existing function info from serialized_function_info.json
2024-01-14 11:30:59,896 - INFO - __main__ - Skynet started
2024-01-14 11:30:59,898 - INFO - __main__ - Loading environment variables
2024-01-14 11:30:59,898 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 11:30:59,899 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 11:30:59,899 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 11:30:59,900 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 11:30:59,900 - INFO - __main__ - Loaded functions from functions
2024-01-14 11:30:59,901 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 11:30:59,902 - INFO - functions.get_functions - file size: 2609
2024-01-14 11:30:59,903 - INFO - functions.get_functions - tree size: 16
2024-01-14 11:31:00,074 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 11:31:00,240 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 11:31:00,241 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 11:31:00,248 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 11:31:00,249 - INFO - functions.get_functions - file size: 1926
2024-01-14 11:31:00,250 - INFO - functions.get_functions - tree size: 5
2024-01-14 11:31:00,250 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 11:31:00,255 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 11:31:00,255 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 11:31:00,256 - INFO - functions.get_functions - file size: 2971
2024-01-14 11:31:00,257 - INFO - functions.get_functions - tree size: 10
2024-01-14 11:31:00,265 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 11:31:00,267 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 11:31:00,273 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 11:31:00,274 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 11:31:00,279 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 11:31:00,280 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 11:31:00,281 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 11:31:00,283 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 11:31:00,297 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 11:31:00,297 - INFO - functions.get_functions - file size: 0
2024-01-14 11:31:00,297 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:31:00,298 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 11:31:00,298 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 11:31:00,298 - INFO - functions.get_functions - file size: 2135
2024-01-14 11:31:00,299 - INFO - functions.get_functions - tree size: 8
2024-01-14 11:31:00,299 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 11:31:00,301 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 11:31:00,302 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 11:31:00,302 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 11:31:00,303 - INFO - __main__ - Loaded 4 functions from ./functions/prompt_creation.py
2024-01-14 11:31:00,309 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 11:31:00,309 - INFO - functions.get_functions - file size: 0
2024-01-14 11:31:00,309 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:31:00,310 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 11:31:00,310 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 11:31:00,310 - INFO - functions.get_functions - file size: 5276
2024-01-14 11:31:00,312 - INFO - functions.get_functions - tree size: 9
2024-01-14 11:31:00,320 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 11:31:00,322 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 11:31:00,329 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 11:31:00,332 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 11:31:00,333 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 11:31:00,335 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:31:00,354 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def load_functions_from_file(file_path) -> [FunctionInfo]:\n    try:\n        with open(file_path, 'r') as file:\n            file_contents = file.read()\n            logger.info(f'file size: {len(file_contents)}')\n            try:\n                tree = ast.parse(file_contents, type_comments=True)\n                logger.info(f'tree size: {len(tree.body)}')\n                functions = []\n                imported_modules = {}\n                for node in ast.walk(tree):\n                    if isinstance(node, ast.Import):\n                        for name in node.names:\n                            imported_modules[name.name] = importlib.import_module(name.name)\n                    elif isinstance(node, ast.ImportFrom):\n                        module = importlib.import_module(node.module)\n                        for name in node.names:\n                            imported_modules[name.name] = getattr(module, name.name)\n                    if isinstance(node, ast.FunctionDef):\n                        logger.info(f'Looking at function: {node.name}')\n                        func_name = node.name\n                        func_code = compile(ast.Module(body=[node], type_ignores=[]), filename='<ast>', mode='exec')\n                        temp_namespace = {**imported_modules}\n                        exec(func_code, temp_namespace)\n                        func = temp_namespace[func_name]\n                        sig = inspect.signature(func)\n                        arg_types = {param_name: param.annotation for param_name, param in sig.parameters.items()}\n                        source_code = ast.unparse(node)\n                        function_info = FunctionInfo(func_name, file_path, source_code, '')\n                        functions.append(function_info)\n                return functions\n            except SyntaxError as e:\n                logger.error(f'Syntax error in {file_path}: {e}')\n                return []\n            except Exception as e:\n                logger.error(f'Error loading functions from {file_path}: {e}')\n                return []\n    except FileNotFoundError:\n        logger.error(f'The file {file_path} was not found.')\n        return []\n    except IOError:\n        logger.error(f'Error reading the file {file_path}.')\n        return []\n    \n    Description:"}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:31:00,442 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 11:31:00,565 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50ca8472d0>
2024-01-14 11:31:00,567 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f50cae46690> server_hostname='api.openai.com' timeout=5.0
2024-01-14 11:31:00,862 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50cacc6310>
2024-01-14 11:31:00,862 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:31:00,863 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:31:00,863 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:31:00,863 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:31:00,863 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:31:03,538 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:31:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'2532'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79370'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'472ms'), (b'x-request-id', b'8572ba8735df2b9fe7a4ca842575525c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hJVq9k1eTddKJ3Erby9lHBklyvIg61LcOOWqu4mqEfI-1705249863-1-ATtgHJMontWTprnUe+LNZuHYahL3qsAyTVz7ThpWjtH29Hi6uMB+XB8v+dgoosGfWsvYzRluIuemNivEcOxUSkI=; path=/; expires=Sun, 14-Jan-24 17:01:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fpEFH5Aq.ka4s_W9Tgdo3QD_F1VuSlU6l610xJS_EXQ-1705249863506-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8457444e79477ced-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:31:03,539 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:31:03,540 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:31:03,541 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:31:03,541 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:31:03,541 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:31:03,541 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:31:03,576 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:31:03,584 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def load_functions_from_file(file_path) -> [FunctionInfo]:\n    try:\n        with open(file_path, 'r') as file:\n            file_contents = file.read()\n            logger.info(f'file size: {len(file_contents)}')\n            try:\n                tree = ast.parse(file_contents, type_comments=True)\n                logger.info(f'tree size: {len(tree.body)}')\n                functions = []\n                imported_modules = {}\n                for node in ast.walk(tree):\n                    if isinstance(node, ast.Import):\n                        for name in node.names:\n                            imported_modules[name.name] = importlib.import_module(name.name)\n                    elif isinstance(node, ast.ImportFrom):\n                        module = importlib.import_module(node.module)\n                        for name in node.names:\n                            imported_modules[name.name] = getattr(module, name.name)\n                    if isinstance(node, ast.FunctionDef):\n                        logger.info(f'Looking at function: {node.name}')\n                        func_name = node.name\n                        func_code = compile(ast.Module(body=[node], type_ignores=[]), filename='<ast>', mode='exec')\n                        temp_namespace = {**imported_modules}\n                        exec(func_code, temp_namespace)\n                        func = temp_namespace[func_name]\n                        sig = inspect.signature(func)\n                        arg_types = {param_name: param.annotation for param_name, param in sig.parameters.items()}\n                        source_code = ast.unparse(node)\n                        function_info = FunctionInfo(func_name, file_path, source_code, '')\n                        functions.append(function_info)\n                return functions\n            except SyntaxError as e:\n                logger.error(f'Syntax error in {file_path}: {e}')\n                return []\n            except Exception as e:\n                logger.error(f'Error loading functions from {file_path}: {e}')\n                return []\n    except FileNotFoundError:\n        logger.error(f'The file {file_path} was not found.')\n        return []\n    except IOError:\n        logger.error(f'Error reading the file {file_path}.')\n        return []\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def list_functions(functions):\n    logger.info('Available functions:')\n    for func_name, func_info in functions.items():\n        arg_types = func_info['arg_types']\n        logger.info(f'Function: {func_name}, Argument Types: {arg_types}')\n    \n    Description:"}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:31:03,590 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:31:03,591 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:31:03,591 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:31:03,592 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:31:03,593 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:31:04,901 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:31:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'830'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79266'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'550ms'), (b'x-request-id', b'3be9c92ed30557c5cf18f2780f529916'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8457445f7d637ced-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:31:04,903 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:31:04,904 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:31:04,905 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:31:04,906 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:31:04,906 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:31:04,907 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:31:04,917 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:31:04,926 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def load_functions_from_file(file_path) -> [FunctionInfo]:\n    try:\n        with open(file_path, 'r') as file:\n            file_contents = file.read()\n            logger.info(f'file size: {len(file_contents)}')\n            try:\n                tree = ast.parse(file_contents, type_comments=True)\n                logger.info(f'tree size: {len(tree.body)}')\n                functions = []\n                imported_modules = {}\n                for node in ast.walk(tree):\n                    if isinstance(node, ast.Import):\n                        for name in node.names:\n                            imported_modules[name.name] = importlib.import_module(name.name)\n                    elif isinstance(node, ast.ImportFrom):\n                        module = importlib.import_module(node.module)\n                        for name in node.names:\n                            imported_modules[name.name] = getattr(module, name.name)\n                    if isinstance(node, ast.FunctionDef):\n                        logger.info(f'Looking at function: {node.name}')\n                        func_name = node.name\n                        func_code = compile(ast.Module(body=[node], type_ignores=[]), filename='<ast>', mode='exec')\n                        temp_namespace = {**imported_modules}\n                        exec(func_code, temp_namespace)\n                        func = temp_namespace[func_name]\n                        sig = inspect.signature(func)\n                        arg_types = {param_name: param.annotation for param_name, param in sig.parameters.items()}\n                        source_code = ast.unparse(node)\n                        function_info = FunctionInfo(func_name, file_path, source_code, '')\n                        functions.append(function_info)\n                return functions\n            except SyntaxError as e:\n                logger.error(f'Syntax error in {file_path}: {e}')\n                return []\n            except Exception as e:\n                logger.error(f'Error loading functions from {file_path}: {e}')\n                return []\n    except FileNotFoundError:\n        logger.error(f'The file {file_path} was not found.')\n        return []\n    except IOError:\n        logger.error(f'Error reading the file {file_path}.')\n        return []\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def list_functions(functions):\n    logger.info('Available functions:')\n    for func_name, func_info in functions.items():\n        arg_types = func_info['arg_types']\n        logger.info(f'Function: {func_name}, Argument Types: {arg_types}')\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_argument_values(arg_types):\n    args = []\n    for arg_name, arg_type in arg_types.items():\n        while True:\n            user_input = input(f'Enter value for {arg_name} ({arg_type}): ')\n            try:\n                if arg_type == int:\n                    converted_value = int(user_input)\n                elif arg_type == float:\n                    converted_value = float(user_input)\n                elif arg_type == bool:\n                    converted_value = user_input.lower() in ['true', '1', 'yes']\n                elif arg_type == str:\n                    converted_value = user_input\n                else:\n                    converted_value = eval(user_input)\n                if not isinstance(converted_value, arg_type) and arg_type != inspect._empty:\n                    raise TypeError(f'Incorrect type for {arg_name}, expected {arg_type}')\n                break\n            except ValueError as e:\n                logger.error(f'Invalid input: {e}')\n            except TypeError as e:\n                logger.error(e)\n            except Exception as e:\n                logger.error(f'Error processing input: {e}')\n        args.append(converted_value)\n    return args\n    \n    Description:"}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:31:04,928 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:31:04,929 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:31:04,929 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:31:04,930 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:31:04,930 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:31:07,063 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:31:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1974'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78923'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'807ms'), (b'x-request-id', b'dc0d02383447c16537d20379d2c19f5b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84574467eed37ced-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:31:07,063 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:31:07,063 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:31:07,065 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:31:07,066 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:31:07,067 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:31:07,068 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:31:07,073 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 11:31:07,224 - DEBUG - httpcore.connection - close.started
2024-01-14 11:31:07,224 - DEBUG - httpcore.connection - close.complete
2024-01-14 11:31:27,391 - INFO - __main__ - Skynet started
2024-01-14 11:31:27,391 - INFO - __main__ - Loading environment variables
2024-01-14 11:31:27,391 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 11:31:27,391 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 11:31:27,392 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 11:31:27,392 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 11:31:27,392 - INFO - __main__ - Loaded functions from functions
2024-01-14 11:31:27,392 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 11:31:27,393 - INFO - functions.get_functions - file size: 2609
2024-01-14 11:31:27,394 - INFO - functions.get_functions - tree size: 16
2024-01-14 11:31:27,534 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 11:31:27,621 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 11:31:27,622 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 11:31:27,622 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 11:31:27,623 - INFO - functions.get_functions - file size: 1926
2024-01-14 11:31:27,623 - INFO - functions.get_functions - tree size: 5
2024-01-14 11:31:27,623 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 11:31:27,625 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 11:31:27,625 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 11:31:27,625 - INFO - functions.get_functions - file size: 2971
2024-01-14 11:31:27,626 - INFO - functions.get_functions - tree size: 10
2024-01-14 11:31:27,626 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 11:31:27,627 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 11:31:27,628 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 11:31:27,628 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 11:31:27,629 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 11:31:27,630 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 11:31:27,630 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 11:31:27,632 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 11:31:27,632 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 11:31:27,632 - INFO - functions.get_functions - file size: 0
2024-01-14 11:31:27,633 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:31:27,633 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 11:31:27,633 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 11:31:27,633 - INFO - functions.get_functions - file size: 2135
2024-01-14 11:31:27,634 - INFO - functions.get_functions - tree size: 8
2024-01-14 11:31:27,634 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 11:31:27,635 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 11:31:27,636 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 11:31:27,637 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 11:31:27,638 - INFO - __main__ - Loaded 4 functions from ./functions/prompt_creation.py
2024-01-14 11:31:27,638 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 11:31:27,638 - INFO - functions.get_functions - file size: 0
2024-01-14 11:31:27,638 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:31:27,639 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 11:31:27,639 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 11:31:27,639 - INFO - functions.get_functions - file size: 5276
2024-01-14 11:31:27,641 - INFO - functions.get_functions - tree size: 9
2024-01-14 11:31:27,641 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 11:31:27,643 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 11:31:27,644 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 11:31:27,646 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 11:31:27,647 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 11:31:27,647 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 11:50:01,581 - INFO - __main__ - Skynet started
2024-01-14 11:50:01,582 - INFO - __main__ - Loading environment variables
2024-01-14 11:50:01,582 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 11:50:01,583 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 11:50:01,583 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 11:50:01,583 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 11:50:01,583 - INFO - __main__ - Loaded functions from functions
2024-01-14 11:50:01,583 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 11:50:01,583 - INFO - functions.get_functions - file size: 2609
2024-01-14 11:50:01,584 - INFO - functions.get_functions - tree size: 16
2024-01-14 11:50:01,815 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 11:50:01,921 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 11:50:01,923 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 11:50:01,923 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 11:50:01,923 - INFO - functions.get_functions - file size: 1926
2024-01-14 11:50:01,924 - INFO - functions.get_functions - tree size: 5
2024-01-14 11:50:01,924 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 11:50:01,925 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 11:50:01,926 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 11:50:01,926 - INFO - functions.get_functions - file size: 2971
2024-01-14 11:50:01,927 - INFO - functions.get_functions - tree size: 10
2024-01-14 11:50:01,927 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 11:50:01,928 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 11:50:01,929 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 11:50:01,929 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 11:50:01,930 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 11:50:01,931 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 11:50:01,932 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 11:50:01,933 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 11:50:01,934 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 11:50:01,934 - INFO - functions.get_functions - file size: 0
2024-01-14 11:50:01,934 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:50:01,934 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 11:50:01,934 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 11:50:01,934 - INFO - functions.get_functions - file size: 2135
2024-01-14 11:50:01,935 - INFO - functions.get_functions - tree size: 8
2024-01-14 11:50:01,935 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 11:50:01,937 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 11:50:01,937 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 11:50:01,938 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 11:50:01,939 - INFO - __main__ - Loaded 4 functions from ./functions/prompt_creation.py
2024-01-14 11:50:01,939 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 11:50:01,939 - INFO - functions.get_functions - file size: 0
2024-01-14 11:50:01,940 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:50:01,940 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 11:50:01,940 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 11:50:01,940 - INFO - functions.get_functions - file size: 5276
2024-01-14 11:50:01,942 - INFO - functions.get_functions - tree size: 9
2024-01-14 11:50:01,942 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 11:50:01,945 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 11:50:01,945 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 11:50:01,952 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 11:50:01,952 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 11:50:01,954 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 11:50:01,957 - INFO - __main__ - The following 3 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values']
2024-01-14 11:53:30,107 - INFO - __main__ - Skynet started
2024-01-14 11:53:30,108 - INFO - __main__ - Loading environment variables
2024-01-14 11:53:30,108 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 11:53:30,108 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 11:53:30,108 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 11:53:30,108 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 11:53:30,108 - INFO - __main__ - Loaded functions from functions
2024-01-14 11:53:30,109 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 11:53:30,109 - INFO - functions.get_functions - file size: 2609
2024-01-14 11:53:30,110 - INFO - functions.get_functions - tree size: 16
2024-01-14 11:53:30,254 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 11:53:30,390 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 11:53:30,391 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 11:53:30,393 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 11:53:30,393 - INFO - functions.get_functions - file size: 1926
2024-01-14 11:53:30,394 - INFO - functions.get_functions - tree size: 5
2024-01-14 11:53:30,394 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 11:53:30,396 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 11:53:30,396 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 11:53:30,397 - INFO - functions.get_functions - file size: 2971
2024-01-14 11:53:30,398 - INFO - functions.get_functions - tree size: 10
2024-01-14 11:53:30,398 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 11:53:30,399 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 11:53:30,400 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 11:53:30,401 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 11:53:30,404 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 11:53:30,406 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 11:53:30,406 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 11:53:30,414 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 11:53:30,414 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 11:53:30,415 - INFO - functions.get_functions - file size: 0
2024-01-14 11:53:30,415 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:53:30,415 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 11:53:30,415 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 11:53:30,415 - INFO - functions.get_functions - file size: 2135
2024-01-14 11:53:30,416 - INFO - functions.get_functions - tree size: 8
2024-01-14 11:53:30,416 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 11:53:30,417 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 11:53:30,418 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 11:53:30,418 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 11:53:30,419 - INFO - __main__ - Loaded 4 functions from ./functions/prompt_creation.py
2024-01-14 11:53:30,419 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 11:53:30,419 - INFO - functions.get_functions - file size: 0
2024-01-14 11:53:30,420 - INFO - functions.get_functions - tree size: 0
2024-01-14 11:53:30,420 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 11:53:30,420 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 11:53:30,420 - INFO - functions.get_functions - file size: 5276
2024-01-14 11:53:30,422 - INFO - functions.get_functions - tree size: 9
2024-01-14 11:53:30,422 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 11:53:30,424 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 11:53:30,425 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 11:53:30,427 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 11:53:30,428 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 11:53:30,428 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:30,463 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:30,546 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 11:53:30,857 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f847392b990>
2024-01-14 11:53:30,858 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f847428e720> server_hostname='api.openai.com' timeout=5.0
2024-01-14 11:53:31,088 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8473c98050>
2024-01-14 11:53:31,089 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:31,089 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:31,090 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:31,090 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:31,090 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:33,057 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1657'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79891'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'81ms'), (b'x-request-id', b'503e5ca08253064767c5efdc0462fdec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Vjux58Fwd5S0xww_Co37P_4dhhiPZ9Gk5EhZcbalA34-1705251212-1-AXDg0Ztig/CKebgUMHZ4+gCyNTl2ZILMcG78OlpKEo4dsshe5mRBHPMwpfZTZRr1Pk/JxZ9GovmAhCaS8NDdMxg=; path=/; expires=Sun, 14-Jan-24 17:23:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=xQ.NvK7TMOMaXU0_ec0Pq6yjRfzsSWYWAizC6EGfie4-1705251212916-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84576545b9b44344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:33,059 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:33,060 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:33,061 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:33,062 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:33,062 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:33,062 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:33,067 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:33,075 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:33,077 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:33,079 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:33,079 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:33,080 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:33,082 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:35,250 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1963'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79759'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'180ms'), (b'x-request-id', b'1bc6458a4b929791f304a7389ddd358e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845765522f274344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:35,251 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:35,252 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:35,253 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:35,254 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:35,255 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:35,256 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:35,262 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:35,273 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_gpt_response(message_log=[], prompt='', model='', return_json_oject=False):\n    if message_log == [] and prompt == '':\n        raise ValueError('Both message_log and prompt cannot be empty when calling return_chat_response.')\n    if model == '':\n        model = os.environ['DEFAULT_GPT_MODEL']\n    if prompt != '':\n        message_log.append({'role': 'user', 'content': prompt})\n    if return_json_oject:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log, response_format={'type': 'json_object'})\n        try:\n            return_value = json.loads(chat_completion.choices[0].message.content)\n            return return_value\n        except:\n            raise ValueError('The response from the AI could not be converted to a json object.')\n    else:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log)\n        return chat_completion.choices[0].message.content\n    \n    Description:"}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:35,275 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:35,276 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:35,276 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:35,277 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:35,277 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:37,553 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1762'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79477'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'392ms'), (b'x-request-id', b'086fa87dc6ffd9fe296ba2de9ccea59e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8457655fedb24344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:37,554 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:37,554 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:37,555 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:37,555 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:37,555 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:37,556 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:37,558 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:37,567 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_gpt_response(message_log=[], prompt='', model='', return_json_oject=False):\n    if message_log == [] and prompt == '':\n        raise ValueError('Both message_log and prompt cannot be empty when calling return_chat_response.')\n    if model == '':\n        model = os.environ['DEFAULT_GPT_MODEL']\n    if prompt != '':\n        message_log.append({'role': 'user', 'content': prompt})\n    if return_json_oject:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log, response_format={'type': 'json_object'})\n        try:\n            return_value = json.loads(chat_completion.choices[0].message.content)\n            return return_value\n        except:\n            raise ValueError('The response from the AI could not be converted to a json object.')\n    else:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log)\n        return chat_completion.choices[0].message.content\n    \n    Description:"}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def read_file(file_path):\n    """Reads and returns the content of a file."""\n    try:\n        logger.info(f\'Reading file {file_path}\')\n        with open(file_path, \'r\') as file:\n            return file.read()\n    except FileNotFoundError:\n        print(f\'The file {file_path} was not found.\')\n    except IOError:\n        print(f\'Error reading the file {file_path}.\')\n    \n    Description:'}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:37,575 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:37,577 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:37,579 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:37,580 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:37,580 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:39,432 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1396'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79341'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'494ms'), (b'x-request-id', b'fbab2a93fdc5177df8066ffada3a838c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8457656e4db44344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:39,433 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:39,433 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:39,434 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:39,434 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:39,434 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:39,434 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:39,436 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:39,445 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_gpt_response(message_log=[], prompt='', model='', return_json_oject=False):\n    if message_log == [] and prompt == '':\n        raise ValueError('Both message_log and prompt cannot be empty when calling return_chat_response.')\n    if model == '':\n        model = os.environ['DEFAULT_GPT_MODEL']\n    if prompt != '':\n        message_log.append({'role': 'user', 'content': prompt})\n    if return_json_oject:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log, response_format={'type': 'json_object'})\n        try:\n            return_value = json.loads(chat_completion.choices[0].message.content)\n            return return_value\n        except:\n            raise ValueError('The response from the AI could not be converted to a json object.')\n    else:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log)\n        return chat_completion.choices[0].message.content\n    \n    Description:"}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def read_file(file_path):\n    """Reads and returns the content of a file."""\n    try:\n        logger.info(f\'Reading file {file_path}\')\n        with open(file_path, \'r\') as file:\n            return file.read()\n    except FileNotFoundError:\n        print(f\'The file {file_path} was not found.\')\n    except IOError:\n        print(f\'Error reading the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def write_file(file_path, content, mode=\'w\'):\n    """Writes content to a file. By default, it overwrites the file.\n    \n    Args:\n    - file_path: Path to the file.\n    - content: Content to be written.\n    - mode: Writing mode (\'w\' for overwrite, \'a\' for append).\n    """\n    try:\n        logger.info(f\'Writing to file {file_path}\')\n        with open(file_path, mode) as file:\n            file.write(content)\n    except IOError:\n        print(f\'Error writing to the file {file_path}.\')\n    \n    Description:'}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:39,447 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:39,447 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:39,447 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:39,448 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:39,448 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:41,925 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'2305'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79175'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'618ms'), (b'x-request-id', b'b086782ed69e389c33adb9d188a35102'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84576579fae74344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:41,926 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:41,926 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:41,927 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:41,927 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:41,927 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:41,927 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:41,929 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:41,940 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_gpt_response(message_log=[], prompt='', model='', return_json_oject=False):\n    if message_log == [] and prompt == '':\n        raise ValueError('Both message_log and prompt cannot be empty when calling return_chat_response.')\n    if model == '':\n        model = os.environ['DEFAULT_GPT_MODEL']\n    if prompt != '':\n        message_log.append({'role': 'user', 'content': prompt})\n    if return_json_oject:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log, response_format={'type': 'json_object'})\n        try:\n            return_value = json.loads(chat_completion.choices[0].message.content)\n            return return_value\n        except:\n            raise ValueError('The response from the AI could not be converted to a json object.')\n    else:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log)\n        return chat_completion.choices[0].message.content\n    \n    Description:"}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def read_file(file_path):\n    """Reads and returns the content of a file."""\n    try:\n        logger.info(f\'Reading file {file_path}\')\n        with open(file_path, \'r\') as file:\n            return file.read()\n    except FileNotFoundError:\n        print(f\'The file {file_path} was not found.\')\n    except IOError:\n        print(f\'Error reading the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def write_file(file_path, content, mode=\'w\'):\n    """Writes content to a file. By default, it overwrites the file.\n    \n    Args:\n    - file_path: Path to the file.\n    - content: Content to be written.\n    - mode: Writing mode (\'w\' for overwrite, \'a\' for append).\n    """\n    try:\n        logger.info(f\'Writing to file {file_path}\')\n        with open(file_path, mode) as file:\n            file.write(content)\n    except IOError:\n        print(f\'Error writing to the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def append_to_file(file_path, content):\n    """Appends content to the end of a file."""\n    write_file(file_path, content, mode=\'a\')\n    \n    Description:'}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:41,941 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:41,942 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:41,942 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:41,942 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:41,942 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:42,741 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'389'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79098'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'676ms'), (b'x-request-id', b'6c45e465903ed84552c147efe9bda9bc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845765898f9f4344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:42,741 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:42,742 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:42,742 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:42,742 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:42,742 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:42,742 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:42,744 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:42,791 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_gpt_response(message_log=[], prompt='', model='', return_json_oject=False):\n    if message_log == [] and prompt == '':\n        raise ValueError('Both message_log and prompt cannot be empty when calling return_chat_response.')\n    if model == '':\n        model = os.environ['DEFAULT_GPT_MODEL']\n    if prompt != '':\n        message_log.append({'role': 'user', 'content': prompt})\n    if return_json_oject:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log, response_format={'type': 'json_object'})\n        try:\n            return_value = json.loads(chat_completion.choices[0].message.content)\n            return return_value\n        except:\n            raise ValueError('The response from the AI could not be converted to a json object.')\n    else:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log)\n        return chat_completion.choices[0].message.content\n    \n    Description:"}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def read_file(file_path):\n    """Reads and returns the content of a file."""\n    try:\n        logger.info(f\'Reading file {file_path}\')\n        with open(file_path, \'r\') as file:\n            return file.read()\n    except FileNotFoundError:\n        print(f\'The file {file_path} was not found.\')\n    except IOError:\n        print(f\'Error reading the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def write_file(file_path, content, mode=\'w\'):\n    """Writes content to a file. By default, it overwrites the file.\n    \n    Args:\n    - file_path: Path to the file.\n    - content: Content to be written.\n    - mode: Writing mode (\'w\' for overwrite, \'a\' for append).\n    """\n    try:\n        logger.info(f\'Writing to file {file_path}\')\n        with open(file_path, mode) as file:\n            file.write(content)\n    except IOError:\n        print(f\'Error writing to the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def append_to_file(file_path, content):\n    """Appends content to the end of a file."""\n    write_file(file_path, content, mode=\'a\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def delete_file(file_path):\n    """Deletes a file."""\n    try:\n        logger.info(f\'Deleting file {file_path}\')\n        os.remove(file_path)\n    except FileNotFoundError:\n        print(f\'The file {file_path} does not exist.\')\n    except OSError:\n        print(f\'Error deleting the file {file_path}.\')\n    \n    Description:'}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:42,805 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:42,808 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:42,812 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:42,815 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:42,821 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:45,390 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'2227'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78978'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'766ms'), (b'x-request-id', b'e973b192ad280341067d6b644cefd210'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8457658f9e194344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:45,391 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:45,391 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:45,393 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:45,394 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:45,395 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:45,395 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:45,398 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:45,413 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_gpt_response(message_log=[], prompt='', model='', return_json_oject=False):\n    if message_log == [] and prompt == '':\n        raise ValueError('Both message_log and prompt cannot be empty when calling return_chat_response.')\n    if model == '':\n        model = os.environ['DEFAULT_GPT_MODEL']\n    if prompt != '':\n        message_log.append({'role': 'user', 'content': prompt})\n    if return_json_oject:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log, response_format={'type': 'json_object'})\n        try:\n            return_value = json.loads(chat_completion.choices[0].message.content)\n            return return_value\n        except:\n            raise ValueError('The response from the AI could not be converted to a json object.')\n    else:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log)\n        return chat_completion.choices[0].message.content\n    \n    Description:"}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def read_file(file_path):\n    """Reads and returns the content of a file."""\n    try:\n        logger.info(f\'Reading file {file_path}\')\n        with open(file_path, \'r\') as file:\n            return file.read()\n    except FileNotFoundError:\n        print(f\'The file {file_path} was not found.\')\n    except IOError:\n        print(f\'Error reading the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def write_file(file_path, content, mode=\'w\'):\n    """Writes content to a file. By default, it overwrites the file.\n    \n    Args:\n    - file_path: Path to the file.\n    - content: Content to be written.\n    - mode: Writing mode (\'w\' for overwrite, \'a\' for append).\n    """\n    try:\n        logger.info(f\'Writing to file {file_path}\')\n        with open(file_path, mode) as file:\n            file.write(content)\n    except IOError:\n        print(f\'Error writing to the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def append_to_file(file_path, content):\n    """Appends content to the end of a file."""\n    write_file(file_path, content, mode=\'a\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def delete_file(file_path):\n    """Deletes a file."""\n    try:\n        logger.info(f\'Deleting file {file_path}\')\n        os.remove(file_path)\n    except FileNotFoundError:\n        print(f\'The file {file_path} does not exist.\')\n    except OSError:\n        print(f\'Error deleting the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def list_files_in_directory(directory=\'\'):\n    """Lists all files in a given directory.\n\n    Args:\n    - directory: The path to the directory.\n\n    Returns:\n    - A list of file names in the directory.\n    """\n    try:\n        logger.info(f\'Listing files in directory {directory}\')\n        return [file for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n    except FileNotFoundError:\n        print(f\'Directory {directory} not found.\')\n        return []\n    except OSError as e:\n        print(f\'Error accessing directory {directory}: {e}\')\n        return []\n    \n    Description:'}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:45,415 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:45,416 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:45,417 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:45,418 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:45,424 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:47,762 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'2152'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78786'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'910ms'), (b'x-request-id', b'59eb800fb805fda1b7b1a6d4d74ed90d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8457659f68ef4344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:47,763 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:47,792 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:47,793 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:47,797 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:47,799 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:47,800 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:47,803 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:47,826 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_gpt_response(message_log=[], prompt='', model='', return_json_oject=False):\n    if message_log == [] and prompt == '':\n        raise ValueError('Both message_log and prompt cannot be empty when calling return_chat_response.')\n    if model == '':\n        model = os.environ['DEFAULT_GPT_MODEL']\n    if prompt != '':\n        message_log.append({'role': 'user', 'content': prompt})\n    if return_json_oject:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log, response_format={'type': 'json_object'})\n        try:\n            return_value = json.loads(chat_completion.choices[0].message.content)\n            return return_value\n        except:\n            raise ValueError('The response from the AI could not be converted to a json object.')\n    else:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log)\n        return chat_completion.choices[0].message.content\n    \n    Description:"}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def read_file(file_path):\n    """Reads and returns the content of a file."""\n    try:\n        logger.info(f\'Reading file {file_path}\')\n        with open(file_path, \'r\') as file:\n            return file.read()\n    except FileNotFoundError:\n        print(f\'The file {file_path} was not found.\')\n    except IOError:\n        print(f\'Error reading the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def write_file(file_path, content, mode=\'w\'):\n    """Writes content to a file. By default, it overwrites the file.\n    \n    Args:\n    - file_path: Path to the file.\n    - content: Content to be written.\n    - mode: Writing mode (\'w\' for overwrite, \'a\' for append).\n    """\n    try:\n        logger.info(f\'Writing to file {file_path}\')\n        with open(file_path, mode) as file:\n            file.write(content)\n    except IOError:\n        print(f\'Error writing to the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def append_to_file(file_path, content):\n    """Appends content to the end of a file."""\n    write_file(file_path, content, mode=\'a\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def delete_file(file_path):\n    """Deletes a file."""\n    try:\n        logger.info(f\'Deleting file {file_path}\')\n        os.remove(file_path)\n    except FileNotFoundError:\n        print(f\'The file {file_path} does not exist.\')\n    except OSError:\n        print(f\'Error deleting the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def list_files_in_directory(directory=\'\'):\n    """Lists all files in a given directory.\n\n    Args:\n    - directory: The path to the directory.\n\n    Returns:\n    - A list of file names in the directory.\n    """\n    try:\n        logger.info(f\'Listing files in directory {directory}\')\n        return [file for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n    except FileNotFoundError:\n        print(f\'Directory {directory} not found.\')\n        return []\n    except OSError as e:\n        print(f\'Error accessing directory {directory}: {e}\')\n        return []\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_current_working_directory():\n    """Returns the current working directory."""\n    logger.info(\'Getting current working directory\')\n    return os.getcwd()\n    \n    Description:'}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:47,829 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:47,830 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:47,831 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:47,831 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:47,832 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:49,466 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1313'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78702'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'973ms'), (b'x-request-id', b'4e586f026d1cbbd58196528d43be4545'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845765ae596b4344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:49,467 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:49,467 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:49,468 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:49,469 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:49,469 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:49,470 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:49,482 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:49,507 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_gpt_response(message_log=[], prompt='', model='', return_json_oject=False):\n    if message_log == [] and prompt == '':\n        raise ValueError('Both message_log and prompt cannot be empty when calling return_chat_response.')\n    if model == '':\n        model = os.environ['DEFAULT_GPT_MODEL']\n    if prompt != '':\n        message_log.append({'role': 'user', 'content': prompt})\n    if return_json_oject:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log, response_format={'type': 'json_object'})\n        try:\n            return_value = json.loads(chat_completion.choices[0].message.content)\n            return return_value\n        except:\n            raise ValueError('The response from the AI could not be converted to a json object.')\n    else:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log)\n        return chat_completion.choices[0].message.content\n    \n    Description:"}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def read_file(file_path):\n    """Reads and returns the content of a file."""\n    try:\n        logger.info(f\'Reading file {file_path}\')\n        with open(file_path, \'r\') as file:\n            return file.read()\n    except FileNotFoundError:\n        print(f\'The file {file_path} was not found.\')\n    except IOError:\n        print(f\'Error reading the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def write_file(file_path, content, mode=\'w\'):\n    """Writes content to a file. By default, it overwrites the file.\n    \n    Args:\n    - file_path: Path to the file.\n    - content: Content to be written.\n    - mode: Writing mode (\'w\' for overwrite, \'a\' for append).\n    """\n    try:\n        logger.info(f\'Writing to file {file_path}\')\n        with open(file_path, mode) as file:\n            file.write(content)\n    except IOError:\n        print(f\'Error writing to the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def append_to_file(file_path, content):\n    """Appends content to the end of a file."""\n    write_file(file_path, content, mode=\'a\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def delete_file(file_path):\n    """Deletes a file."""\n    try:\n        logger.info(f\'Deleting file {file_path}\')\n        os.remove(file_path)\n    except FileNotFoundError:\n        print(f\'The file {file_path} does not exist.\')\n    except OSError:\n        print(f\'Error deleting the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def list_files_in_directory(directory=\'\'):\n    """Lists all files in a given directory.\n\n    Args:\n    - directory: The path to the directory.\n\n    Returns:\n    - A list of file names in the directory.\n    """\n    try:\n        logger.info(f\'Listing files in directory {directory}\')\n        return [file for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n    except FileNotFoundError:\n        print(f\'Directory {directory} not found.\')\n        return []\n    except OSError as e:\n        print(f\'Error accessing directory {directory}: {e}\')\n        return []\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_current_working_directory():\n    """Returns the current working directory."""\n    logger.info(\'Getting current working directory\')\n    return os.getcwd()\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def set_env_variables_with_defaults(env_vars_defaults):\n    """\n    Sets environment variables to default values if they are not already set.\n\n    Args:\n    - env_vars_defaults: A dictionary where keys are environment variable names \n                         and values are the default values for these variables.\n    """\n    for var, default in env_vars_defaults.items():\n        if var not in os.environ:\n            if default != \'error\':\n                logger.info(f\'Setting environment variable {var} to default value {default}\')\n                os.environ[var] = default\n            else:\n                logger.error(f\'Environment variable {var} not set. This is a required variable and no default value provided.\')\n                raise ValueError(f\'Environment variable {var} not set. This is a required variable and no default value provided.\')\n    \n    Description:'}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:49,509 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:49,510 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:49,510 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:49,511 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:49,512 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:51,346 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1161'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78443'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'1.167s'), (b'x-request-id', b'd9e58d32ae8fbe15e5b84f3cb1cf14e9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845765b8feeb4344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:51,347 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:51,348 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:51,349 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:51,349 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:51,349 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:51,349 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:51,351 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:51,383 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_gpt_response(message_log=[], prompt='', model='', return_json_oject=False):\n    if message_log == [] and prompt == '':\n        raise ValueError('Both message_log and prompt cannot be empty when calling return_chat_response.')\n    if model == '':\n        model = os.environ['DEFAULT_GPT_MODEL']\n    if prompt != '':\n        message_log.append({'role': 'user', 'content': prompt})\n    if return_json_oject:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log, response_format={'type': 'json_object'})\n        try:\n            return_value = json.loads(chat_completion.choices[0].message.content)\n            return return_value\n        except:\n            raise ValueError('The response from the AI could not be converted to a json object.')\n    else:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log)\n        return chat_completion.choices[0].message.content\n    \n    Description:"}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def read_file(file_path):\n    """Reads and returns the content of a file."""\n    try:\n        logger.info(f\'Reading file {file_path}\')\n        with open(file_path, \'r\') as file:\n            return file.read()\n    except FileNotFoundError:\n        print(f\'The file {file_path} was not found.\')\n    except IOError:\n        print(f\'Error reading the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def write_file(file_path, content, mode=\'w\'):\n    """Writes content to a file. By default, it overwrites the file.\n    \n    Args:\n    - file_path: Path to the file.\n    - content: Content to be written.\n    - mode: Writing mode (\'w\' for overwrite, \'a\' for append).\n    """\n    try:\n        logger.info(f\'Writing to file {file_path}\')\n        with open(file_path, mode) as file:\n            file.write(content)\n    except IOError:\n        print(f\'Error writing to the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def append_to_file(file_path, content):\n    """Appends content to the end of a file."""\n    write_file(file_path, content, mode=\'a\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def delete_file(file_path):\n    """Deletes a file."""\n    try:\n        logger.info(f\'Deleting file {file_path}\')\n        os.remove(file_path)\n    except FileNotFoundError:\n        print(f\'The file {file_path} does not exist.\')\n    except OSError:\n        print(f\'Error deleting the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def list_files_in_directory(directory=\'\'):\n    """Lists all files in a given directory.\n\n    Args:\n    - directory: The path to the directory.\n\n    Returns:\n    - A list of file names in the directory.\n    """\n    try:\n        logger.info(f\'Listing files in directory {directory}\')\n        return [file for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n    except FileNotFoundError:\n        print(f\'Directory {directory} not found.\')\n        return []\n    except OSError as e:\n        print(f\'Error accessing directory {directory}: {e}\')\n        return []\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_current_working_directory():\n    """Returns the current working directory."""\n    logger.info(\'Getting current working directory\')\n    return os.getcwd()\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def set_env_variables_with_defaults(env_vars_defaults):\n    """\n    Sets environment variables to default values if they are not already set.\n\n    Args:\n    - env_vars_defaults: A dictionary where keys are environment variable names \n                         and values are the default values for these variables.\n    """\n    for var, default in env_vars_defaults.items():\n        if var not in os.environ:\n            if default != \'error\':\n                logger.info(f\'Setting environment variable {var} to default value {default}\')\n                os.environ[var] = default\n            else:\n                logger.error(f\'Environment variable {var} not set. This is a required variable and no default value provided.\')\n                raise ValueError(f\'Environment variable {var} not set. This is a required variable and no default value provided.\')\n    \n    Description:'}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_function_options(functions: [FunctionInfo]) -> str:\n    function_options = ''\n    for function in functions:\n        function_options += f'{function.function_name} : {function.description}\\n'\n    return function_options\n    \n    Description:"}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:51,386 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:51,387 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:51,388 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:51,389 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:51,389 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:53,299 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1669'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78341'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'1.244s'), (b'x-request-id', b'84300a163449c08d2c97019b383293e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845765c48e344344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:53,300 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:53,300 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:53,301 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:53,301 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:53,301 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:53,301 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:53,303 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:53,321 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_gpt_response(message_log=[], prompt='', model='', return_json_oject=False):\n    if message_log == [] and prompt == '':\n        raise ValueError('Both message_log and prompt cannot be empty when calling return_chat_response.')\n    if model == '':\n        model = os.environ['DEFAULT_GPT_MODEL']\n    if prompt != '':\n        message_log.append({'role': 'user', 'content': prompt})\n    if return_json_oject:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log, response_format={'type': 'json_object'})\n        try:\n            return_value = json.loads(chat_completion.choices[0].message.content)\n            return return_value\n        except:\n            raise ValueError('The response from the AI could not be converted to a json object.')\n    else:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log)\n        return chat_completion.choices[0].message.content\n    \n    Description:"}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def read_file(file_path):\n    """Reads and returns the content of a file."""\n    try:\n        logger.info(f\'Reading file {file_path}\')\n        with open(file_path, \'r\') as file:\n            return file.read()\n    except FileNotFoundError:\n        print(f\'The file {file_path} was not found.\')\n    except IOError:\n        print(f\'Error reading the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def write_file(file_path, content, mode=\'w\'):\n    """Writes content to a file. By default, it overwrites the file.\n    \n    Args:\n    - file_path: Path to the file.\n    - content: Content to be written.\n    - mode: Writing mode (\'w\' for overwrite, \'a\' for append).\n    """\n    try:\n        logger.info(f\'Writing to file {file_path}\')\n        with open(file_path, mode) as file:\n            file.write(content)\n    except IOError:\n        print(f\'Error writing to the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def append_to_file(file_path, content):\n    """Appends content to the end of a file."""\n    write_file(file_path, content, mode=\'a\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def delete_file(file_path):\n    """Deletes a file."""\n    try:\n        logger.info(f\'Deleting file {file_path}\')\n        os.remove(file_path)\n    except FileNotFoundError:\n        print(f\'The file {file_path} does not exist.\')\n    except OSError:\n        print(f\'Error deleting the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def list_files_in_directory(directory=\'\'):\n    """Lists all files in a given directory.\n\n    Args:\n    - directory: The path to the directory.\n\n    Returns:\n    - A list of file names in the directory.\n    """\n    try:\n        logger.info(f\'Listing files in directory {directory}\')\n        return [file for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n    except FileNotFoundError:\n        print(f\'Directory {directory} not found.\')\n        return []\n    except OSError as e:\n        print(f\'Error accessing directory {directory}: {e}\')\n        return []\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_current_working_directory():\n    """Returns the current working directory."""\n    logger.info(\'Getting current working directory\')\n    return os.getcwd()\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def set_env_variables_with_defaults(env_vars_defaults):\n    """\n    Sets environment variables to default values if they are not already set.\n\n    Args:\n    - env_vars_defaults: A dictionary where keys are environment variable names \n                         and values are the default values for these variables.\n    """\n    for var, default in env_vars_defaults.items():\n        if var not in os.environ:\n            if default != \'error\':\n                logger.info(f\'Setting environment variable {var} to default value {default}\')\n                os.environ[var] = default\n            else:\n                logger.error(f\'Environment variable {var} not set. This is a required variable and no default value provided.\')\n                raise ValueError(f\'Environment variable {var} not set. This is a required variable and no default value provided.\')\n    \n    Description:'}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_function_options(functions: [FunctionInfo]) -> str:\n    function_options = ''\n    for function in functions:\n        function_options += f'{function.function_name} : {function.description}\\n'\n    return function_options\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def create_function(function_objective: str, language: str) -> object:\n    prompt = f'Create a function that accomplishes the following: {function_objective}\\n\\n    Using the {language} programming language.\\n\\n    it should return a json object with the following properties:\\n\\n    required_libraries: a list of strings\\n\\n    source_code: a string\\n\\n    The source code should ONLY be the function definition, including the function definition and the function body.\\n    '\n    try:\n        return return_gpt_response(prompt=prompt, return_json_oject=True)\n    except Exception as e:\n        raise ValueError(f'Error creating function: {e}')\n    \n    Description:"}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:53,323 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:53,323 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:53,324 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:53,324 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:53,324 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:55,215 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1719'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78136'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'1.398s'), (b'x-request-id', b'3ec4196ee95cf47639e8973cad1f721d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845765d0acc04344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:55,216 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:55,216 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:55,216 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:55,216 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:55,216 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:55,217 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:55,219 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:55,239 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_gpt_response(message_log=[], prompt='', model='', return_json_oject=False):\n    if message_log == [] and prompt == '':\n        raise ValueError('Both message_log and prompt cannot be empty when calling return_chat_response.')\n    if model == '':\n        model = os.environ['DEFAULT_GPT_MODEL']\n    if prompt != '':\n        message_log.append({'role': 'user', 'content': prompt})\n    if return_json_oject:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log, response_format={'type': 'json_object'})\n        try:\n            return_value = json.loads(chat_completion.choices[0].message.content)\n            return return_value\n        except:\n            raise ValueError('The response from the AI could not be converted to a json object.')\n    else:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log)\n        return chat_completion.choices[0].message.content\n    \n    Description:"}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def read_file(file_path):\n    """Reads and returns the content of a file."""\n    try:\n        logger.info(f\'Reading file {file_path}\')\n        with open(file_path, \'r\') as file:\n            return file.read()\n    except FileNotFoundError:\n        print(f\'The file {file_path} was not found.\')\n    except IOError:\n        print(f\'Error reading the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def write_file(file_path, content, mode=\'w\'):\n    """Writes content to a file. By default, it overwrites the file.\n    \n    Args:\n    - file_path: Path to the file.\n    - content: Content to be written.\n    - mode: Writing mode (\'w\' for overwrite, \'a\' for append).\n    """\n    try:\n        logger.info(f\'Writing to file {file_path}\')\n        with open(file_path, mode) as file:\n            file.write(content)\n    except IOError:\n        print(f\'Error writing to the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def append_to_file(file_path, content):\n    """Appends content to the end of a file."""\n    write_file(file_path, content, mode=\'a\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def delete_file(file_path):\n    """Deletes a file."""\n    try:\n        logger.info(f\'Deleting file {file_path}\')\n        os.remove(file_path)\n    except FileNotFoundError:\n        print(f\'The file {file_path} does not exist.\')\n    except OSError:\n        print(f\'Error deleting the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def list_files_in_directory(directory=\'\'):\n    """Lists all files in a given directory.\n\n    Args:\n    - directory: The path to the directory.\n\n    Returns:\n    - A list of file names in the directory.\n    """\n    try:\n        logger.info(f\'Listing files in directory {directory}\')\n        return [file for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n    except FileNotFoundError:\n        print(f\'Directory {directory} not found.\')\n        return []\n    except OSError as e:\n        print(f\'Error accessing directory {directory}: {e}\')\n        return []\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_current_working_directory():\n    """Returns the current working directory."""\n    logger.info(\'Getting current working directory\')\n    return os.getcwd()\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def set_env_variables_with_defaults(env_vars_defaults):\n    """\n    Sets environment variables to default values if they are not already set.\n\n    Args:\n    - env_vars_defaults: A dictionary where keys are environment variable names \n                         and values are the default values for these variables.\n    """\n    for var, default in env_vars_defaults.items():\n        if var not in os.environ:\n            if default != \'error\':\n                logger.info(f\'Setting environment variable {var} to default value {default}\')\n                os.environ[var] = default\n            else:\n                logger.error(f\'Environment variable {var} not set. This is a required variable and no default value provided.\')\n                raise ValueError(f\'Environment variable {var} not set. This is a required variable and no default value provided.\')\n    \n    Description:'}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_function_options(functions: [FunctionInfo]) -> str:\n    function_options = ''\n    for function in functions:\n        function_options += f'{function.function_name} : {function.description}\\n'\n    return function_options\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def create_function(function_objective: str, language: str) -> object:\n    prompt = f'Create a function that accomplishes the following: {function_objective}\\n\\n    Using the {language} programming language.\\n\\n    it should return a json object with the following properties:\\n\\n    required_libraries: a list of strings\\n\\n    source_code: a string\\n\\n    The source code should ONLY be the function definition, including the function definition and the function body.\\n    '\n    try:\n        return return_gpt_response(prompt=prompt, return_json_oject=True)\n    except Exception as e:\n        raise ValueError(f'Error creating function: {e}')\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def create_step_list(goal: str) -> object:\n    prompt = f'Create a step list that accomplishes the following: {goal}\\n\\n    The json object returned should have the following properties:\\n    step_list: a list of strings describing the steps to accomplish the goal\\n    verification: a string describing how to verify that the goal has been accomplished\\n    '\n    try:\n        return return_gpt_response(prompt=prompt, return_json_oject=True)\n    except Exception as e:\n        raise ValueError(f'Error creating step list: {e}')\n    \n    Description:"}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:55,241 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:55,241 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:55,241 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:55,242 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:55,242 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:57,296 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1211'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'77959'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'1.53s'), (b'x-request-id', b'f2f13a2db937ed039c888482ceb29a7d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845765dc99834344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:57,297 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:57,297 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:57,298 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:57,298 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:57,299 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:57,299 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:57,301 - INFO - functions.prompt_creation - Describing function
2024-01-14 11:53:57,327 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_links(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    links = [a.get('href') for a in soup.find_all('a', href=True)]\n    return links\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def process_command(command):\n    tokens = command.split()\n    if tokens[0] == 'get_links':\n        try:\n            links = get_links(tokens[1])\n            return links\n        except ValueError:\n            return 'Error: Please provide valid numbers.'\n    elif tokens[0] == 'exit':\n        return None\n    else:\n        return 'Unknown command'\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_gpt_response(message_log=[], prompt='', model='', return_json_oject=False):\n    if message_log == [] and prompt == '':\n        raise ValueError('Both message_log and prompt cannot be empty when calling return_chat_response.')\n    if model == '':\n        model = os.environ['DEFAULT_GPT_MODEL']\n    if prompt != '':\n        message_log.append({'role': 'user', 'content': prompt})\n    if return_json_oject:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log, response_format={'type': 'json_object'})\n        try:\n            return_value = json.loads(chat_completion.choices[0].message.content)\n            return return_value\n        except:\n            raise ValueError('The response from the AI could not be converted to a json object.')\n    else:\n        chat_completion = client.chat.completions.create(model=model, messages=message_log)\n        return chat_completion.choices[0].message.content\n    \n    Description:"}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def read_file(file_path):\n    """Reads and returns the content of a file."""\n    try:\n        logger.info(f\'Reading file {file_path}\')\n        with open(file_path, \'r\') as file:\n            return file.read()\n    except FileNotFoundError:\n        print(f\'The file {file_path} was not found.\')\n    except IOError:\n        print(f\'Error reading the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def write_file(file_path, content, mode=\'w\'):\n    """Writes content to a file. By default, it overwrites the file.\n    \n    Args:\n    - file_path: Path to the file.\n    - content: Content to be written.\n    - mode: Writing mode (\'w\' for overwrite, \'a\' for append).\n    """\n    try:\n        logger.info(f\'Writing to file {file_path}\')\n        with open(file_path, mode) as file:\n            file.write(content)\n    except IOError:\n        print(f\'Error writing to the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def append_to_file(file_path, content):\n    """Appends content to the end of a file."""\n    write_file(file_path, content, mode=\'a\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def delete_file(file_path):\n    """Deletes a file."""\n    try:\n        logger.info(f\'Deleting file {file_path}\')\n        os.remove(file_path)\n    except FileNotFoundError:\n        print(f\'The file {file_path} does not exist.\')\n    except OSError:\n        print(f\'Error deleting the file {file_path}.\')\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def list_files_in_directory(directory=\'\'):\n    """Lists all files in a given directory.\n\n    Args:\n    - directory: The path to the directory.\n\n    Returns:\n    - A list of file names in the directory.\n    """\n    try:\n        logger.info(f\'Listing files in directory {directory}\')\n        return [file for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n    except FileNotFoundError:\n        print(f\'Directory {directory} not found.\')\n        return []\n    except OSError as e:\n        print(f\'Error accessing directory {directory}: {e}\')\n        return []\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def get_current_working_directory():\n    """Returns the current working directory."""\n    logger.info(\'Getting current working directory\')\n    return os.getcwd()\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def set_env_variables_with_defaults(env_vars_defaults):\n    """\n    Sets environment variables to default values if they are not already set.\n\n    Args:\n    - env_vars_defaults: A dictionary where keys are environment variable names \n                         and values are the default values for these variables.\n    """\n    for var, default in env_vars_defaults.items():\n        if var not in os.environ:\n            if default != \'error\':\n                logger.info(f\'Setting environment variable {var} to default value {default}\')\n                os.environ[var] = default\n            else:\n                logger.error(f\'Environment variable {var} not set. This is a required variable and no default value provided.\')\n                raise ValueError(f\'Environment variable {var} not set. This is a required variable and no default value provided.\')\n    \n    Description:'}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def return_function_options(functions: [FunctionInfo]) -> str:\n    function_options = ''\n    for function in functions:\n        function_options += f'{function.function_name} : {function.description}\\n'\n    return function_options\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def create_function(function_objective: str, language: str) -> object:\n    prompt = f'Create a function that accomplishes the following: {function_objective}\\n\\n    Using the {language} programming language.\\n\\n    it should return a json object with the following properties:\\n\\n    required_libraries: a list of strings\\n\\n    source_code: a string\\n\\n    The source code should ONLY be the function definition, including the function definition and the function body.\\n    '\n    try:\n        return return_gpt_response(prompt=prompt, return_json_oject=True)\n    except Exception as e:\n        raise ValueError(f'Error creating function: {e}')\n    \n    Description:"}, {'role': 'user', 'content': "Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def create_step_list(goal: str) -> object:\n    prompt = f'Create a step list that accomplishes the following: {goal}\\n\\n    The json object returned should have the following properties:\\n    step_list: a list of strings describing the steps to accomplish the goal\\n    verification: a string describing how to verify that the goal has been accomplished\\n    '\n    try:\n        return return_gpt_response(prompt=prompt, return_json_oject=True)\n    except Exception as e:\n        raise ValueError(f'Error creating step list: {e}')\n    \n    Description:"}, {'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def describe_function(function_string):\n    """Returns a description of the function."""\n    prompt = f\'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \\n    \\n    {function_string}\\n    \\n    Description:\'\n    try:\n        logger.info(\'Describing function\')\n        return return_gpt_response(prompt=prompt)\n    except Exception as e:\n        logger.error(f\'Error describing function: {e}\')\n        raise ValueError(\'Error describing function.\')\n    \n    Description:'}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 11:53:57,329 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 11:53:57,330 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 11:53:57,331 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 11:53:57,332 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 11:53:57,332 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 11:53:59,242 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 16:53:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1581'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'77779'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'1.665s'), (b'x-request-id', b'c5da9590e4bc0f8a4a1bbfa51fecc0ea'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845765e9adde4344-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 11:53:59,251 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 11:53:59,251 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 11:53:59,252 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 11:53:59,252 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 11:53:59,252 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 11:53:59,252 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 11:53:59,255 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 11:53:59,257 - INFO - __main__ - The following 17 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function']
2024-01-14 11:53:59,391 - DEBUG - httpcore.connection - close.started
2024-01-14 11:53:59,393 - DEBUG - httpcore.connection - close.complete
2024-01-14 12:21:26,692 - INFO - __main__ - Skynet started
2024-01-14 12:21:26,694 - INFO - __main__ - Loading environment variables
2024-01-14 12:21:26,694 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 12:21:26,694 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 12:21:26,694 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 12:21:26,695 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 12:21:26,695 - INFO - __main__ - Loaded functions from functions
2024-01-14 12:21:26,695 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 12:21:26,695 - INFO - functions.get_functions - file size: 2609
2024-01-14 12:21:26,696 - INFO - functions.get_functions - tree size: 16
2024-01-14 12:21:26,908 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 12:21:27,031 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 12:21:27,033 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 12:21:27,033 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 12:21:27,034 - INFO - functions.get_functions - file size: 1926
2024-01-14 12:21:27,035 - INFO - functions.get_functions - tree size: 5
2024-01-14 12:21:27,036 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 12:21:27,038 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 12:21:27,038 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 12:21:27,038 - INFO - functions.get_functions - file size: 2971
2024-01-14 12:21:27,040 - INFO - functions.get_functions - tree size: 10
2024-01-14 12:21:27,040 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 12:21:27,041 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 12:21:27,042 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 12:21:27,043 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 12:21:27,043 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 12:21:27,045 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 12:21:27,045 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 12:21:27,047 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 12:21:27,047 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 12:21:27,047 - INFO - functions.get_functions - file size: 0
2024-01-14 12:21:27,047 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:21:27,048 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 12:21:27,048 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 12:21:27,048 - INFO - functions.get_functions - file size: 2959
2024-01-14 12:21:27,049 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:21:27,050 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 12:21:27,056 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 12:21:27,058 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 12:21:27,060 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 12:21:27,064 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 12:21:27,066 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 12:21:27,066 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 12:21:27,066 - INFO - functions.get_functions - file size: 0
2024-01-14 12:21:27,067 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:21:27,069 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 12:21:27,069 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 12:21:27,069 - INFO - functions.get_functions - file size: 5276
2024-01-14 12:21:27,071 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:21:27,074 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 12:21:27,076 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 12:21:27,080 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 12:21:27,083 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 12:21:27,084 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 12:21:27,084 - INFO - functions.prompt_creation - Describing function
2024-01-14 12:21:27,101 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def required_fields(fields: [str], json_object: object) -> bool:\n    """Returns true if the required fields are present in the json object"""\n    for field in fields:\n        if field not in json_object:\n            return False\n    return True\n    \n    Description:'}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 12:21:27,222 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 12:21:27,316 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3725909150>
2024-01-14 12:21:27,317 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3725a9e600> server_hostname='api.openai.com' timeout=5.0
2024-01-14 12:21:27,486 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3725e62090>
2024-01-14 12:21:27,487 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 12:21:27,488 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 12:21:27,489 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 12:21:27,489 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 12:21:27,489 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 12:21:28,323 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 17:21:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'482'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79878'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'91ms'), (b'x-request-id', b'9ea43e1db89eafc91daf67f1def65e95'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Q8lgdzZvBJGR.yIWGhf69xk7bLuzmcJKJF1xCL7beY4-1705252888-1-AbyqE63jFBVPKIGje0vm48HLqfNCyHx1lPnACxbKUKKksY0vC0MLTXtnHa9PVerbV0GgLL2vOxzfH8gQ0JIUgN8=; path=/; expires=Sun, 14-Jan-24 17:51:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=KBMYJT5T.eMqY1gRaCJ6fUSIJiXeC01iyAfCKwN5Lig-1705252888324-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84578e32f8b541bd-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 12:21:28,324 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 12:21:28,325 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 12:21:28,325 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 12:21:28,326 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 12:21:28,326 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 12:21:28,327 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 12:21:28,330 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 12:21:28,357 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 12:21:53,294 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def required_fields(fields: [str], json_object: object) -> bool:\n    """Returns true if the required fields are present in the json object"""\n    for field in fields:\n        if field not in json_object:\n            return False\n    return True\n    \n    Description:'}, {'role': 'user', 'content': 'Create a step list that accomplishes the following:  Please send an email to my co-worker, their email is robert@pretension.io\n\n    The json object returned should have the following properties:\n    step_list: a list of strings describing the steps to accomplish the goal\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 12:21:53,298 - DEBUG - httpcore.connection - close.started
2024-01-14 12:21:53,300 - DEBUG - httpcore.connection - close.complete
2024-01-14 12:21:53,301 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 12:21:53,637 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3725c87050>
2024-01-14 12:21:53,638 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3725a9e600> server_hostname='api.openai.com' timeout=5.0
2024-01-14 12:21:53,803 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3725127710>
2024-01-14 12:21:53,806 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 12:21:53,807 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 12:21:53,807 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 12:21:53,807 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 12:21:53,807 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 12:22:11,502 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 17:22:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'17505'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79808'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'144ms'), (b'x-request-id', b'b92d16042f2572642de3f28dee33da1b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84578ed77fb96a5c-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 12:22:11,503 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 12:22:11,504 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 12:22:11,504 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 12:22:11,505 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 12:22:11,505 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 12:22:11,505 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 12:22:11,507 - ERROR - __main__ - Error creating step list for  Please send an email to my co-worker, their email is robert@pretension.io
2024-01-14 12:22:11,632 - DEBUG - httpcore.connection - close.started
2024-01-14 12:22:11,633 - DEBUG - httpcore.connection - close.complete
2024-01-14 12:24:50,122 - INFO - __main__ - Skynet started
2024-01-14 12:24:50,123 - INFO - __main__ - Loading environment variables
2024-01-14 12:24:50,123 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 12:24:50,123 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 12:24:50,123 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 12:24:50,124 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 12:24:50,124 - INFO - __main__ - Loaded functions from functions
2024-01-14 12:24:50,125 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 12:24:50,125 - INFO - functions.get_functions - file size: 2609
2024-01-14 12:24:50,126 - INFO - functions.get_functions - tree size: 16
2024-01-14 12:24:50,310 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 12:24:50,434 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 12:24:50,435 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 12:24:50,435 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 12:24:50,435 - INFO - functions.get_functions - file size: 2088
2024-01-14 12:24:50,436 - INFO - functions.get_functions - tree size: 7
2024-01-14 12:24:50,436 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 12:24:50,438 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 12:24:50,438 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 12:24:50,439 - INFO - functions.get_functions - file size: 2971
2024-01-14 12:24:50,440 - INFO - functions.get_functions - tree size: 10
2024-01-14 12:24:50,440 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 12:24:50,441 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 12:24:50,442 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 12:24:50,442 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 12:24:50,443 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 12:24:50,444 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 12:24:50,444 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 12:24:50,446 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 12:24:50,446 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 12:24:50,446 - INFO - functions.get_functions - file size: 0
2024-01-14 12:24:50,447 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:24:50,447 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 12:24:50,447 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 12:24:50,447 - INFO - functions.get_functions - file size: 2959
2024-01-14 12:24:50,449 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:24:50,449 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 12:24:50,450 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 12:24:50,451 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 12:24:50,451 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 12:24:50,452 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 12:24:50,458 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 12:24:50,458 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 12:24:50,459 - INFO - functions.get_functions - file size: 0
2024-01-14 12:24:50,459 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:24:50,459 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 12:24:50,459 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 12:24:50,459 - INFO - functions.get_functions - file size: 5276
2024-01-14 12:24:50,461 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:24:50,461 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 12:24:50,464 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 12:24:50,465 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 12:24:50,467 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 12:24:50,468 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 12:24:50,469 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 12:24:50,471 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 12:25:05,198 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Create a step list that accomplishes the following: Please send an email to my co-worker whose email is robert@pretension.io\n\n    The json object returned should have the following properties:\n    step_list: a list of strings describing the steps to accomplish the goal\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 12:25:05,249 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 12:25:05,497 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9d284f60d0>
2024-01-14 12:25:05,498 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9d28e5a570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 12:25:05,732 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9d284dec10>
2024-01-14 12:25:05,733 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 12:25:05,734 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 12:25:05,734 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 12:25:05,735 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 12:25:05,735 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 12:25:07,810 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 17:25:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1493'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79914'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'64ms'), (b'x-request-id', b'43f469650f147ee0d9004ec89feee8a0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=86NCd6L6uFmTVi8fc_fSeoRVgHKzyqIAf7wbVqB8j9U-1705253107-1-AetFQ17mB+7lfk5yGh3g1o0r7IbhUwcQ0Y8G467whhQ3R56E9+kYKwB4rwyLZtCLYJEvl0YR90KjjTiCDe+dFvo=; path=/; expires=Sun, 14-Jan-24 17:55:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=nT.hGlUH1YsBTiV4kIOwfySpGAeEhp_Ax_v1SSMxCKE-1705253107573-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84579386f9f019e3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 12:25:07,812 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 12:25:07,840 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 12:25:07,842 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 12:25:07,843 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 12:25:07,843 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 12:25:07,844 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 12:25:07,853 - INFO - functions.openai_call - Converting response        {
    "step_list": [
      "Open your email client or email service provider",
      "Click on the 'Compose' or 'New Message' button",
      "In the 'To' field, type in 'robert@pretension.io'",
      "Write your message in the body of the email",
      "Check for any attachments or links you want to include",
      "Proofread your email for any errors",
      "Click 'Send' to send the email to robert@pretension.io"
    ]
  } to json object
2024-01-14 12:28:01,072 - DEBUG - httpcore.connection - close.started
2024-01-14 12:28:01,073 - DEBUG - httpcore.connection - close.complete
2024-01-14 12:28:03,075 - INFO - __main__ - Skynet started
2024-01-14 12:28:03,076 - INFO - __main__ - Loading environment variables
2024-01-14 12:28:03,076 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 12:28:03,076 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 12:28:03,077 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 12:28:03,077 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 12:28:03,077 - INFO - __main__ - Loaded functions from functions
2024-01-14 12:28:03,077 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 12:28:03,078 - INFO - functions.get_functions - file size: 2609
2024-01-14 12:28:03,079 - INFO - functions.get_functions - tree size: 16
2024-01-14 12:28:03,219 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 12:28:03,317 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 12:28:03,318 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 12:28:03,318 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 12:28:03,318 - INFO - functions.get_functions - file size: 2144
2024-01-14 12:28:03,319 - INFO - functions.get_functions - tree size: 7
2024-01-14 12:28:03,319 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 12:28:03,321 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 12:28:03,321 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 12:28:03,321 - INFO - functions.get_functions - file size: 2971
2024-01-14 12:28:03,322 - INFO - functions.get_functions - tree size: 10
2024-01-14 12:28:03,323 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 12:28:03,323 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 12:28:03,326 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 12:28:03,327 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 12:28:03,328 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 12:28:03,329 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 12:28:03,330 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 12:28:03,331 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 12:28:03,332 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 12:28:03,332 - INFO - functions.get_functions - file size: 0
2024-01-14 12:28:03,333 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:28:03,333 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 12:28:03,333 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 12:28:03,334 - INFO - functions.get_functions - file size: 3155
2024-01-14 12:28:03,335 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:28:03,336 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 12:28:03,337 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 12:28:03,341 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 12:28:03,343 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 12:28:03,344 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 12:28:03,345 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 12:28:03,346 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 12:28:03,346 - INFO - functions.get_functions - file size: 0
2024-01-14 12:28:03,346 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:28:03,347 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 12:28:03,347 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 12:28:03,347 - INFO - functions.get_functions - file size: 5276
2024-01-14 12:28:03,349 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:28:03,350 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 12:28:03,355 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 12:28:03,356 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 12:28:03,360 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 12:28:03,360 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 12:28:03,361 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 12:28:03,363 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 12:28:17,385 - INFO - functions.openai_call - 
Sending Prompt:
Create a step list that accomplishes the following: Please send an email to my co-worker whose email is: robert@pretension.io

    Note that you can only use the command line on the ubuntu operating system, and you can only use the following python functions:

    load_functions_from_file : This function loads Python function definitions from a given file path. It reads the file, analyses its contents, and returns a list of information about each function, including the function name, source code, and argument types. If it encounters errors such as syntax errors or file-related issues, it logs an error message and returns an empty list.
list_functions : The 'list_functions' function logs the available functions and their argument types from the input 'functions' dictionary. It outputs these details as informational log messages.
get_argument_values : This function takes argument types and prompts the user to enter values for each argument. The input is then converted to the corresponding type and added to a list. If the input is invalid, errors are logged. The function returns the list of argument values.
get_links : The function takes a URL as input, sends a request to the URL, and then scrapes the HTML content to find and return a list of all the links (URLs) found on the page.
process_command : The function processes a given command. If the command is 'get_links', it calls the get_links function with the input provided after 'get_links'. If the command is 'exit', it returns None. If the command is unknown, it returns 'Unknown command'. If there is a value error during 'get_links', it returns 'Error: Please provide valid numbers'.
return_gpt_response : The function `return_gpt_response` takes in input variables `message_log`, `prompt`, `model`, and `return_json_object`. It checks for empty inputs and then processes user chat input using OpenAI's GPT model to generate a response. If `return_json_object` is set to `True`, it returns a JSON object of the response; otherwise, it returns the generated chat response. If model type is not provided, it uses the default GPT model from the environment variables.
read_file : The function "read_file" takes a file path as input and returns the content of the file. It logs an info message for the file being read, and then attempts to read and return the file's contents. If the file is not found, it prints a message stating the file was not found. If there is an error reading the file, it prints a message indicating an error occurred.
write_file : The function "write_file" takes three input variables - "file_path", "content", and "mode" (with a default value of 'w'). It writes the given content to the file specified by "file_path" in the specified mode (either overwrite or append). If the file writing operation encounters an error, an appropriate error message is displayed.
append_to_file : The function "append_to_file" appends content to the end of a file by calling the "write_file" function with the append mode.
delete_file : The function "delete_file" deletes the specified file. It logs the file deletion, and if the file doesn't exist, it prints a message that the file does not exist. If there is any error during the file deletion, it prints an error message indicating an issue with the file deletion.
list_files_in_directory : This function lists all files in a given directory path. If the directory path exists, it returns a list of file names within that directory. If the directory does not exist or an error occurs during access, it returns an empty list with a corresponding error message.
get_current_working_directory : The "get_current_working_directory" function returns the path to the current working directory of the program. If the directory cannot be accessed or encountered during the process, the function logs an error and returns the failure message.
set_env_variables_with_defaults : This function sets environment variables to default values if they are not already set. It takes in a dictionary where keys are environment variable names and values are the default values for these variables. If the environment variable is not set, it is assigned the default value. If a required variable doesn't have a default value, it raises an error.
return_function_options : This function takes a list of FunctionInfo objects as input and returns a string containing the name and description of each function in the list. Each function's name and description is concatenated together into the output string, separated by a colon and a new line.
create_function : The `create_function` function generates a prompt for creating a function with a specified objective and programming language. It then uses the GPT (Generative Pre-trained Transformer) model to generate the source code for the function as a JSON object, including required libraries and the source code. If an error occurs during the function creation process, it raises an exception with a corresponding error message.
create_step_list : The function "create_step_list" takes in a goal and generates a step list in the form of a JSON object. It prompts the user with the goal and returns a structured step list as a JSON object containing a list of strings outlining the steps needed to achieve the goal, as well as a string describing how to verify the completion of the goal. If any errors occur during the process, it raises a value error along with the error message.
describe_function : The "describe_function" function takes a function string as input and returns a description of the function by using GPT-3 natural language processing. It creates a prompt matching the format of a succinct description for a function, then uses GPT-3 to generate the description based on the provided function string. If there are any errors during the process, it raises a ValueError.
required_fields : The function checks if all the required fields specified in the list are present in the given JSON object. If all the required fields are present, it returns `True`; otherwise, it returns `False`.


    The json object returned should have the following properties:
    step_list: a list of strings describing the steps to accomplish the goal
    


2024-01-14 12:28:17,390 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Create a step list that accomplishes the following: Please send an email to my co-worker whose email is: robert@pretension.io\n\n    Note that you can only use the command line on the ubuntu operating system, and you can only use the following python functions:\n\n    load_functions_from_file : This function loads Python function definitions from a given file path. It reads the file, analyses its contents, and returns a list of information about each function, including the function name, source code, and argument types. If it encounters errors such as syntax errors or file-related issues, it logs an error message and returns an empty list.\nlist_functions : The \'list_functions\' function logs the available functions and their argument types from the input \'functions\' dictionary. It outputs these details as informational log messages.\nget_argument_values : This function takes argument types and prompts the user to enter values for each argument. The input is then converted to the corresponding type and added to a list. If the input is invalid, errors are logged. The function returns the list of argument values.\nget_links : The function takes a URL as input, sends a request to the URL, and then scrapes the HTML content to find and return a list of all the links (URLs) found on the page.\nprocess_command : The function processes a given command. If the command is \'get_links\', it calls the get_links function with the input provided after \'get_links\'. If the command is \'exit\', it returns None. If the command is unknown, it returns \'Unknown command\'. If there is a value error during \'get_links\', it returns \'Error: Please provide valid numbers\'.\nreturn_gpt_response : The function `return_gpt_response` takes in input variables `message_log`, `prompt`, `model`, and `return_json_object`. It checks for empty inputs and then processes user chat input using OpenAI\'s GPT model to generate a response. If `return_json_object` is set to `True`, it returns a JSON object of the response; otherwise, it returns the generated chat response. If model type is not provided, it uses the default GPT model from the environment variables.\nread_file : The function "read_file" takes a file path as input and returns the content of the file. It logs an info message for the file being read, and then attempts to read and return the file\'s contents. If the file is not found, it prints a message stating the file was not found. If there is an error reading the file, it prints a message indicating an error occurred.\nwrite_file : The function "write_file" takes three input variables - "file_path", "content", and "mode" (with a default value of \'w\'). It writes the given content to the file specified by "file_path" in the specified mode (either overwrite or append). If the file writing operation encounters an error, an appropriate error message is displayed.\nappend_to_file : The function "append_to_file" appends content to the end of a file by calling the "write_file" function with the append mode.\ndelete_file : The function "delete_file" deletes the specified file. It logs the file deletion, and if the file doesn\'t exist, it prints a message that the file does not exist. If there is any error during the file deletion, it prints an error message indicating an issue with the file deletion.\nlist_files_in_directory : This function lists all files in a given directory path. If the directory path exists, it returns a list of file names within that directory. If the directory does not exist or an error occurs during access, it returns an empty list with a corresponding error message.\nget_current_working_directory : The "get_current_working_directory" function returns the path to the current working directory of the program. If the directory cannot be accessed or encountered during the process, the function logs an error and returns the failure message.\nset_env_variables_with_defaults : This function sets environment variables to default values if they are not already set. It takes in a dictionary where keys are environment variable names and values are the default values for these variables. If the environment variable is not set, it is assigned the default value. If a required variable doesn\'t have a default value, it raises an error.\nreturn_function_options : This function takes a list of FunctionInfo objects as input and returns a string containing the name and description of each function in the list. Each function\'s name and description is concatenated together into the output string, separated by a colon and a new line.\ncreate_function : The `create_function` function generates a prompt for creating a function with a specified objective and programming language. It then uses the GPT (Generative Pre-trained Transformer) model to generate the source code for the function as a JSON object, including required libraries and the source code. If an error occurs during the function creation process, it raises an exception with a corresponding error message.\ncreate_step_list : The function "create_step_list" takes in a goal and generates a step list in the form of a JSON object. It prompts the user with the goal and returns a structured step list as a JSON object containing a list of strings outlining the steps needed to achieve the goal, as well as a string describing how to verify the completion of the goal. If any errors occur during the process, it raises a value error along with the error message.\ndescribe_function : The "describe_function" function takes a function string as input and returns a description of the function by using GPT-3 natural language processing. It creates a prompt matching the format of a succinct description for a function, then uses GPT-3 to generate the description based on the provided function string. If there are any errors during the process, it raises a ValueError.\nrequired_fields : The function checks if all the required fields specified in the list are present in the given JSON object. If all the required fields are present, it returns `True`; otherwise, it returns `False`.\n\n\n    The json object returned should have the following properties:\n    step_list: a list of strings describing the steps to accomplish the goal\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 12:28:17,439 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 12:28:17,489 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f091bb43c90>
2024-01-14 12:28:17,489 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f091c4ae570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 12:28:17,596 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f091bb438d0>
2024-01-14 12:28:17,597 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 12:28:17,598 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 12:28:17,599 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 12:28:17,599 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 12:28:17,599 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 12:28:21,877 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 17:28:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'3370'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78428'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'1.179s'), (b'x-request-id', b'02cda5ec1723fa60bb7526af59059783'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=o74qEsYPe9APGIzWX8h2QlBjSqkJrRvOe04eK6GxU6U-1705253301-1-AZwv254ho2zv+i73nE5ukLSV83IOpkhn+GdhyyHGa0nS7K8cW4c8aNZqvR0Q8aZk9PdmnwDaivMXSN5U7v3SPdM=; path=/; expires=Sun, 14-Jan-24 17:58:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=g66JYc1oR4MkYbqhsroDmPzXsbDqmGNQ2_0Udj8n1UE-1705253301836-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845798361ac91a0f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 12:28:21,881 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 12:28:21,882 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 12:28:21,883 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 12:28:21,883 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 12:28:21,884 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 12:28:21,885 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 12:28:21,889 - INFO - functions.openai_call - Converting response 
   {
      "goal": "Send an email to the co-worker",
      "step_list": [
        "Open the terminal on the Ubuntu operating system",
        "Use the 'get_current_working_directory' function to ensure you are in the correct directory",
        "If not in the correct directory, use the 'list_files_in_directory' function to list the files in the current directory and navigate to the appropriate location",
        "Use the 'load_functions_from_file' function to load the necessary Python functions",
        "Create a list of required fields for the email such as recipient, subject, and body",
        "Prompt the user to enter the recipient, subject, and body using the 'get_argument_values' function",
        "Use the 'return_gpt_response' function to generate the email content based on the provided inputs",
        "Verify the generated email content",
        "Use the 'write_file' function to write the generated email content to a file",
        "Use the 'send_email' function to send the email to robert@pretension.io",
        "Verify that the email has been sent successfully"
      ]
    }
    
     to json object
2024-01-14 12:29:43,013 - DEBUG - httpcore.connection - close.started
2024-01-14 12:29:43,014 - DEBUG - httpcore.connection - close.complete
2024-01-14 12:33:09,137 - INFO - __main__ - Skynet started
2024-01-14 12:33:09,137 - INFO - __main__ - Loading environment variables
2024-01-14 12:33:09,137 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 12:33:09,137 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 12:33:09,138 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 12:33:09,138 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 12:33:09,138 - INFO - __main__ - Loaded functions from functions
2024-01-14 12:33:09,138 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 12:33:09,138 - INFO - functions.get_functions - file size: 2609
2024-01-14 12:33:09,139 - INFO - functions.get_functions - tree size: 16
2024-01-14 12:33:09,269 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 12:33:09,355 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 12:33:09,356 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 12:33:09,356 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 12:33:09,356 - INFO - functions.get_functions - file size: 2144
2024-01-14 12:33:09,357 - INFO - functions.get_functions - tree size: 7
2024-01-14 12:33:09,357 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 12:33:09,359 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 12:33:09,359 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 12:33:09,359 - INFO - functions.get_functions - file size: 2971
2024-01-14 12:33:09,361 - INFO - functions.get_functions - tree size: 10
2024-01-14 12:33:09,361 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 12:33:09,362 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 12:33:09,362 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 12:33:09,363 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 12:33:09,363 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 12:33:09,364 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 12:33:09,365 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 12:33:09,366 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 12:33:09,366 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 12:33:09,366 - INFO - functions.get_functions - file size: 0
2024-01-14 12:33:09,367 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:33:09,367 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 12:33:09,367 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 12:33:09,367 - INFO - functions.get_functions - file size: 3155
2024-01-14 12:33:09,368 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:33:09,368 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 12:33:09,368 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 12:33:09,369 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 12:33:09,370 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 12:33:09,370 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 12:33:09,371 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 12:33:09,372 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 12:33:09,372 - INFO - functions.get_functions - file size: 0
2024-01-14 12:33:09,372 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:33:09,372 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 12:33:09,372 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 12:33:09,372 - INFO - functions.get_functions - file size: 5276
2024-01-14 12:33:09,374 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:33:09,374 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 12:33:09,376 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 12:33:09,377 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 12:33:09,379 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 12:33:09,380 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 12:33:09,380 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 12:33:09,381 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 12:37:20,445 - INFO - __main__ - Skynet started
2024-01-14 12:37:20,445 - INFO - __main__ - Loading environment variables
2024-01-14 12:37:20,446 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 12:37:20,446 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 12:37:20,446 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 12:37:20,447 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 12:37:20,448 - INFO - __main__ - Loaded functions from functions
2024-01-14 12:37:20,448 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 12:37:20,448 - INFO - functions.get_functions - file size: 2609
2024-01-14 12:37:20,450 - INFO - functions.get_functions - tree size: 16
2024-01-14 12:37:20,583 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 12:37:20,690 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 12:37:20,692 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 12:37:20,692 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 12:37:20,693 - INFO - functions.get_functions - file size: 2144
2024-01-14 12:37:20,693 - INFO - functions.get_functions - tree size: 7
2024-01-14 12:37:20,694 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 12:37:20,696 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 12:37:20,696 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 12:37:20,697 - INFO - functions.get_functions - file size: 2971
2024-01-14 12:37:20,699 - INFO - functions.get_functions - tree size: 10
2024-01-14 12:37:20,699 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 12:37:20,700 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 12:37:20,702 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 12:37:20,703 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 12:37:20,704 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 12:37:20,705 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 12:37:20,706 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 12:37:20,709 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 12:37:20,709 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 12:37:20,709 - INFO - functions.get_functions - file size: 0
2024-01-14 12:37:20,709 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:37:20,710 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 12:37:20,710 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 12:37:20,710 - INFO - functions.get_functions - file size: 3362
2024-01-14 12:37:20,714 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:37:20,714 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 12:37:20,716 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 12:37:20,720 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 12:37:20,722 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 12:37:20,723 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 12:37:20,724 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 12:37:20,724 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 12:37:20,725 - INFO - functions.get_functions - file size: 0
2024-01-14 12:37:20,725 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:37:20,725 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 12:37:20,726 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 12:37:20,727 - INFO - functions.get_functions - file size: 5276
2024-01-14 12:37:20,728 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:37:20,729 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 12:37:20,731 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 12:37:20,732 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 12:37:20,735 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 12:37:20,735 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 12:37:20,736 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 12:37:20,738 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 12:37:29,407 - INFO - functions.openai_call - 
Sending Prompt:
Create a step list that accomplishes the following: Post a tweet on twitter

    Note that you can only use the command line on the ubuntu operating system, and you can only use the following python functions:

    
    load_functions_from_file : This function loads Python function definitions from a given file path. It reads the file, analyses its contents, and returns a list of information about each function, including the function name, source code, and argument types. If it encounters errors such as syntax errors or file-related issues, it logs an error message and returns an empty list.
    
    list_functions : The 'list_functions' function logs the available functions and their argument types from the input 'functions' dictionary. It outputs these details as informational log messages.
    
    get_argument_values : This function takes argument types and prompts the user to enter values for each argument. The input is then converted to the corresponding type and added to a list. If the input is invalid, errors are logged. The function returns the list of argument values.
    
    get_links : The function takes a URL as input, sends a request to the URL, and then scrapes the HTML content to find and return a list of all the links (URLs) found on the page.
    
    process_command : The function processes a given command. If the command is 'get_links', it calls the get_links function with the input provided after 'get_links'. If the command is 'exit', it returns None. If the command is unknown, it returns 'Unknown command'. If there is a value error during 'get_links', it returns 'Error: Please provide valid numbers'.
    
    return_gpt_response : The function `return_gpt_response` takes in input variables `message_log`, `prompt`, `model`, and `return_json_object`. It checks for empty inputs and then processes user chat input using OpenAI's GPT model to generate a response. If `return_json_object` is set to `True`, it returns a JSON object of the response; otherwise, it returns the generated chat response. If model type is not provided, it uses the default GPT model from the environment variables.
    
    read_file : The function "read_file" takes a file path as input and returns the content of the file. It logs an info message for the file being read, and then attempts to read and return the file's contents. If the file is not found, it prints a message stating the file was not found. If there is an error reading the file, it prints a message indicating an error occurred.
    
    write_file : The function "write_file" takes three input variables - "file_path", "content", and "mode" (with a default value of 'w'). It writes the given content to the file specified by "file_path" in the specified mode (either overwrite or append). If the file writing operation encounters an error, an appropriate error message is displayed.
    
    append_to_file : The function "append_to_file" appends content to the end of a file by calling the "write_file" function with the append mode.
    
    delete_file : The function "delete_file" deletes the specified file. It logs the file deletion, and if the file doesn't exist, it prints a message that the file does not exist. If there is any error during the file deletion, it prints an error message indicating an issue with the file deletion.
    
    list_files_in_directory : This function lists all files in a given directory path. If the directory path exists, it returns a list of file names within that directory. If the directory does not exist or an error occurs during access, it returns an empty list with a corresponding error message.
    
    get_current_working_directory : The "get_current_working_directory" function returns the path to the current working directory of the program. If the directory cannot be accessed or encountered during the process, the function logs an error and returns the failure message.
    
    set_env_variables_with_defaults : This function sets environment variables to default values if they are not already set. It takes in a dictionary where keys are environment variable names and values are the default values for these variables. If the environment variable is not set, it is assigned the default value. If a required variable doesn't have a default value, it raises an error.
    
    return_function_options : This function takes a list of FunctionInfo objects as input and returns a string containing the name and description of each function in the list. Each function's name and description is concatenated together into the output string, separated by a colon and a new line.
    
    create_function : The `create_function` function generates a prompt for creating a function with a specified objective and programming language. It then uses the GPT (Generative Pre-trained Transformer) model to generate the source code for the function as a JSON object, including required libraries and the source code. If an error occurs during the function creation process, it raises an exception with a corresponding error message.
    
    create_step_list : The function "create_step_list" takes in a goal and generates a step list in the form of a JSON object. It prompts the user with the goal and returns a structured step list as a JSON object containing a list of strings outlining the steps needed to achieve the goal, as well as a string describing how to verify the completion of the goal. If any errors occur during the process, it raises a value error along with the error message.
    
    describe_function : The "describe_function" function takes a function string as input and returns a description of the function by using GPT-3 natural language processing. It creates a prompt matching the format of a succinct description for a function, then uses GPT-3 to generate the description based on the provided function string. If there are any errors during the process, it raises a ValueError.
    
    required_fields : The function checks if all the required fields specified in the list are present in the given JSON object. If all the required fields are present, it returns `True`; otherwise, it returns `False`.
    

    The json object returned should have the following properties:
    step_list: a list of strings describing the steps to accomplish the goal
    additional_functions: a list of descriptions of functions that need to be written to accomplish the goal.

    Both properties must exist, it's okay if they're empty.
    


2024-01-14 12:37:29,413 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Create a step list that accomplishes the following: Post a tweet on twitter\n\n    Note that you can only use the command line on the ubuntu operating system, and you can only use the following python functions:\n\n    \n    load_functions_from_file : This function loads Python function definitions from a given file path. It reads the file, analyses its contents, and returns a list of information about each function, including the function name, source code, and argument types. If it encounters errors such as syntax errors or file-related issues, it logs an error message and returns an empty list.\n    \n    list_functions : The \'list_functions\' function logs the available functions and their argument types from the input \'functions\' dictionary. It outputs these details as informational log messages.\n    \n    get_argument_values : This function takes argument types and prompts the user to enter values for each argument. The input is then converted to the corresponding type and added to a list. If the input is invalid, errors are logged. The function returns the list of argument values.\n    \n    get_links : The function takes a URL as input, sends a request to the URL, and then scrapes the HTML content to find and return a list of all the links (URLs) found on the page.\n    \n    process_command : The function processes a given command. If the command is \'get_links\', it calls the get_links function with the input provided after \'get_links\'. If the command is \'exit\', it returns None. If the command is unknown, it returns \'Unknown command\'. If there is a value error during \'get_links\', it returns \'Error: Please provide valid numbers\'.\n    \n    return_gpt_response : The function `return_gpt_response` takes in input variables `message_log`, `prompt`, `model`, and `return_json_object`. It checks for empty inputs and then processes user chat input using OpenAI\'s GPT model to generate a response. If `return_json_object` is set to `True`, it returns a JSON object of the response; otherwise, it returns the generated chat response. If model type is not provided, it uses the default GPT model from the environment variables.\n    \n    read_file : The function "read_file" takes a file path as input and returns the content of the file. It logs an info message for the file being read, and then attempts to read and return the file\'s contents. If the file is not found, it prints a message stating the file was not found. If there is an error reading the file, it prints a message indicating an error occurred.\n    \n    write_file : The function "write_file" takes three input variables - "file_path", "content", and "mode" (with a default value of \'w\'). It writes the given content to the file specified by "file_path" in the specified mode (either overwrite or append). If the file writing operation encounters an error, an appropriate error message is displayed.\n    \n    append_to_file : The function "append_to_file" appends content to the end of a file by calling the "write_file" function with the append mode.\n    \n    delete_file : The function "delete_file" deletes the specified file. It logs the file deletion, and if the file doesn\'t exist, it prints a message that the file does not exist. If there is any error during the file deletion, it prints an error message indicating an issue with the file deletion.\n    \n    list_files_in_directory : This function lists all files in a given directory path. If the directory path exists, it returns a list of file names within that directory. If the directory does not exist or an error occurs during access, it returns an empty list with a corresponding error message.\n    \n    get_current_working_directory : The "get_current_working_directory" function returns the path to the current working directory of the program. If the directory cannot be accessed or encountered during the process, the function logs an error and returns the failure message.\n    \n    set_env_variables_with_defaults : This function sets environment variables to default values if they are not already set. It takes in a dictionary where keys are environment variable names and values are the default values for these variables. If the environment variable is not set, it is assigned the default value. If a required variable doesn\'t have a default value, it raises an error.\n    \n    return_function_options : This function takes a list of FunctionInfo objects as input and returns a string containing the name and description of each function in the list. Each function\'s name and description is concatenated together into the output string, separated by a colon and a new line.\n    \n    create_function : The `create_function` function generates a prompt for creating a function with a specified objective and programming language. It then uses the GPT (Generative Pre-trained Transformer) model to generate the source code for the function as a JSON object, including required libraries and the source code. If an error occurs during the function creation process, it raises an exception with a corresponding error message.\n    \n    create_step_list : The function "create_step_list" takes in a goal and generates a step list in the form of a JSON object. It prompts the user with the goal and returns a structured step list as a JSON object containing a list of strings outlining the steps needed to achieve the goal, as well as a string describing how to verify the completion of the goal. If any errors occur during the process, it raises a value error along with the error message.\n    \n    describe_function : The "describe_function" function takes a function string as input and returns a description of the function by using GPT-3 natural language processing. It creates a prompt matching the format of a succinct description for a function, then uses GPT-3 to generate the description based on the provided function string. If there are any errors during the process, it raises a ValueError.\n    \n    required_fields : The function checks if all the required fields specified in the list are present in the given JSON object. If all the required fields are present, it returns `True`; otherwise, it returns `False`.\n    \n\n    The json object returned should have the following properties:\n    step_list: a list of strings describing the steps to accomplish the goal\n    additional_functions: a list of descriptions of functions that need to be written to accomplish the goal.\n\n    Both properties must exist, it\'s okay if they\'re empty.\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 12:37:29,429 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 12:37:29,506 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f166ac37e10>
2024-01-14 12:37:29,506 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f166b59a450> server_hostname='api.openai.com' timeout=5.0
2024-01-14 12:37:29,614 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f166ac30990>
2024-01-14 12:37:29,614 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 12:37:29,615 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 12:37:29,615 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 12:37:29,616 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 12:37:29,616 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 12:38:29,764 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 17:38:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'59392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78357'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'1.232s'), (b'x-request-id', b'9126052f9735d941a18841a83bc69ec4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=v_dQqdWSnZfKUYLbXGjoREA4Fan2kRWZzUzs1J4HGPI-1705253909-1-AYJHELRTQHVFdn4I2mxZps4OkSV0SScBH5jzKFZEjauqFru2WwhnYZdkAsAZ5UQoP0jcfQ6vLmsPpypU9Rb2Efo=; path=/; expires=Sun, 14-Jan-24 18:08:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=.UeYFBNKoxc6bDeczQIg6CwmwncnQ3lpgwaTRhGZThM-1705253909624-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8457a5b0294a3308-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 12:38:29,765 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 12:38:29,766 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 12:38:29,766 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 12:38:29,766 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 12:38:29,766 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 12:38:29,767 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 12:38:29,770 - INFO - functions.openai_call - Converting response                        
                        
                     
                 
   
  
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 to json object
2024-01-14 12:38:29,770 - ERROR - __main__ - Error creating step list for Post a tweet on twitter
2024-01-14 12:38:29,872 - DEBUG - httpcore.connection - close.started
2024-01-14 12:38:29,873 - DEBUG - httpcore.connection - close.complete
2024-01-14 12:39:05,414 - INFO - __main__ - Skynet started
2024-01-14 12:39:05,414 - INFO - __main__ - Loading environment variables
2024-01-14 12:39:05,414 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 12:39:05,414 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 12:39:05,414 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 12:39:05,414 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 12:39:05,415 - INFO - __main__ - Loaded functions from functions
2024-01-14 12:39:05,415 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 12:39:05,415 - INFO - functions.get_functions - file size: 2609
2024-01-14 12:39:05,416 - INFO - functions.get_functions - tree size: 16
2024-01-14 12:39:05,549 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 12:39:05,634 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 12:39:05,635 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 12:39:05,635 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 12:39:05,635 - INFO - functions.get_functions - file size: 2144
2024-01-14 12:39:05,636 - INFO - functions.get_functions - tree size: 7
2024-01-14 12:39:05,636 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 12:39:05,638 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 12:39:05,638 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 12:39:05,638 - INFO - functions.get_functions - file size: 2971
2024-01-14 12:39:05,639 - INFO - functions.get_functions - tree size: 10
2024-01-14 12:39:05,640 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 12:39:05,641 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 12:39:05,641 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 12:39:05,642 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 12:39:05,642 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 12:39:05,643 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 12:39:05,643 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 12:39:05,645 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 12:39:05,645 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 12:39:05,645 - INFO - functions.get_functions - file size: 0
2024-01-14 12:39:05,645 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:39:05,646 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 12:39:05,646 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 12:39:05,646 - INFO - functions.get_functions - file size: 3362
2024-01-14 12:39:05,647 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:39:05,647 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 12:39:05,647 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 12:39:05,648 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 12:39:05,649 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 12:39:05,649 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 12:39:05,650 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 12:39:05,651 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 12:39:05,651 - INFO - functions.get_functions - file size: 0
2024-01-14 12:39:05,651 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:39:05,651 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 12:39:05,651 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 12:39:05,651 - INFO - functions.get_functions - file size: 5276
2024-01-14 12:39:05,653 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:39:05,653 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 12:39:05,655 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 12:39:05,656 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 12:39:05,658 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 12:39:05,658 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 12:39:05,659 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 12:39:05,660 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 12:39:42,366 - INFO - functions.openai_call - 
Sending Prompt:
Create a step list that accomplishes the following: Please post a tweet on twitter about how grskynet is

    Note that you can only use the command line on the ubuntu operating system, and you can only use the following python functions:

    
    load_functions_from_file : This function loads Python function definitions from a given file path. It reads the file, analyses its contents, and returns a list of information about each function, including the function name, source code, and argument types. If it encounters errors such as syntax errors or file-related issues, it logs an error message and returns an empty list.
    
    list_functions : The 'list_functions' function logs the available functions and their argument types from the input 'functions' dictionary. It outputs these details as informational log messages.
    
    get_argument_values : This function takes argument types and prompts the user to enter values for each argument. The input is then converted to the corresponding type and added to a list. If the input is invalid, errors are logged. The function returns the list of argument values.
    
    get_links : The function takes a URL as input, sends a request to the URL, and then scrapes the HTML content to find and return a list of all the links (URLs) found on the page.
    
    process_command : The function processes a given command. If the command is 'get_links', it calls the get_links function with the input provided after 'get_links'. If the command is 'exit', it returns None. If the command is unknown, it returns 'Unknown command'. If there is a value error during 'get_links', it returns 'Error: Please provide valid numbers'.
    
    return_gpt_response : The function `return_gpt_response` takes in input variables `message_log`, `prompt`, `model`, and `return_json_object`. It checks for empty inputs and then processes user chat input using OpenAI's GPT model to generate a response. If `return_json_object` is set to `True`, it returns a JSON object of the response; otherwise, it returns the generated chat response. If model type is not provided, it uses the default GPT model from the environment variables.
    
    read_file : The function "read_file" takes a file path as input and returns the content of the file. It logs an info message for the file being read, and then attempts to read and return the file's contents. If the file is not found, it prints a message stating the file was not found. If there is an error reading the file, it prints a message indicating an error occurred.
    
    write_file : The function "write_file" takes three input variables - "file_path", "content", and "mode" (with a default value of 'w'). It writes the given content to the file specified by "file_path" in the specified mode (either overwrite or append). If the file writing operation encounters an error, an appropriate error message is displayed.
    
    append_to_file : The function "append_to_file" appends content to the end of a file by calling the "write_file" function with the append mode.
    
    delete_file : The function "delete_file" deletes the specified file. It logs the file deletion, and if the file doesn't exist, it prints a message that the file does not exist. If there is any error during the file deletion, it prints an error message indicating an issue with the file deletion.
    
    list_files_in_directory : This function lists all files in a given directory path. If the directory path exists, it returns a list of file names within that directory. If the directory does not exist or an error occurs during access, it returns an empty list with a corresponding error message.
    
    get_current_working_directory : The "get_current_working_directory" function returns the path to the current working directory of the program. If the directory cannot be accessed or encountered during the process, the function logs an error and returns the failure message.
    
    set_env_variables_with_defaults : This function sets environment variables to default values if they are not already set. It takes in a dictionary where keys are environment variable names and values are the default values for these variables. If the environment variable is not set, it is assigned the default value. If a required variable doesn't have a default value, it raises an error.
    
    return_function_options : This function takes a list of FunctionInfo objects as input and returns a string containing the name and description of each function in the list. Each function's name and description is concatenated together into the output string, separated by a colon and a new line.
    
    create_function : The `create_function` function generates a prompt for creating a function with a specified objective and programming language. It then uses the GPT (Generative Pre-trained Transformer) model to generate the source code for the function as a JSON object, including required libraries and the source code. If an error occurs during the function creation process, it raises an exception with a corresponding error message.
    
    create_step_list : The function "create_step_list" takes in a goal and generates a step list in the form of a JSON object. It prompts the user with the goal and returns a structured step list as a JSON object containing a list of strings outlining the steps needed to achieve the goal, as well as a string describing how to verify the completion of the goal. If any errors occur during the process, it raises a value error along with the error message.
    
    describe_function : The "describe_function" function takes a function string as input and returns a description of the function by using GPT-3 natural language processing. It creates a prompt matching the format of a succinct description for a function, then uses GPT-3 to generate the description based on the provided function string. If there are any errors during the process, it raises a ValueError.
    
    required_fields : The function checks if all the required fields specified in the list are present in the given JSON object. If all the required fields are present, it returns `True`; otherwise, it returns `False`.
    

    The json object returned should have the following properties:
    step_list: a list of strings describing the steps to accomplish the goal
    additional_functions: a list of descriptions of functions that need to be written to accomplish the goal.

    Both properties must exist, it's okay if they're empty.
    


2024-01-14 12:39:42,375 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Create a step list that accomplishes the following: Please post a tweet on twitter about how grskynet is\n\n    Note that you can only use the command line on the ubuntu operating system, and you can only use the following python functions:\n\n    \n    load_functions_from_file : This function loads Python function definitions from a given file path. It reads the file, analyses its contents, and returns a list of information about each function, including the function name, source code, and argument types. If it encounters errors such as syntax errors or file-related issues, it logs an error message and returns an empty list.\n    \n    list_functions : The \'list_functions\' function logs the available functions and their argument types from the input \'functions\' dictionary. It outputs these details as informational log messages.\n    \n    get_argument_values : This function takes argument types and prompts the user to enter values for each argument. The input is then converted to the corresponding type and added to a list. If the input is invalid, errors are logged. The function returns the list of argument values.\n    \n    get_links : The function takes a URL as input, sends a request to the URL, and then scrapes the HTML content to find and return a list of all the links (URLs) found on the page.\n    \n    process_command : The function processes a given command. If the command is \'get_links\', it calls the get_links function with the input provided after \'get_links\'. If the command is \'exit\', it returns None. If the command is unknown, it returns \'Unknown command\'. If there is a value error during \'get_links\', it returns \'Error: Please provide valid numbers\'.\n    \n    return_gpt_response : The function `return_gpt_response` takes in input variables `message_log`, `prompt`, `model`, and `return_json_object`. It checks for empty inputs and then processes user chat input using OpenAI\'s GPT model to generate a response. If `return_json_object` is set to `True`, it returns a JSON object of the response; otherwise, it returns the generated chat response. If model type is not provided, it uses the default GPT model from the environment variables.\n    \n    read_file : The function "read_file" takes a file path as input and returns the content of the file. It logs an info message for the file being read, and then attempts to read and return the file\'s contents. If the file is not found, it prints a message stating the file was not found. If there is an error reading the file, it prints a message indicating an error occurred.\n    \n    write_file : The function "write_file" takes three input variables - "file_path", "content", and "mode" (with a default value of \'w\'). It writes the given content to the file specified by "file_path" in the specified mode (either overwrite or append). If the file writing operation encounters an error, an appropriate error message is displayed.\n    \n    append_to_file : The function "append_to_file" appends content to the end of a file by calling the "write_file" function with the append mode.\n    \n    delete_file : The function "delete_file" deletes the specified file. It logs the file deletion, and if the file doesn\'t exist, it prints a message that the file does not exist. If there is any error during the file deletion, it prints an error message indicating an issue with the file deletion.\n    \n    list_files_in_directory : This function lists all files in a given directory path. If the directory path exists, it returns a list of file names within that directory. If the directory does not exist or an error occurs during access, it returns an empty list with a corresponding error message.\n    \n    get_current_working_directory : The "get_current_working_directory" function returns the path to the current working directory of the program. If the directory cannot be accessed or encountered during the process, the function logs an error and returns the failure message.\n    \n    set_env_variables_with_defaults : This function sets environment variables to default values if they are not already set. It takes in a dictionary where keys are environment variable names and values are the default values for these variables. If the environment variable is not set, it is assigned the default value. If a required variable doesn\'t have a default value, it raises an error.\n    \n    return_function_options : This function takes a list of FunctionInfo objects as input and returns a string containing the name and description of each function in the list. Each function\'s name and description is concatenated together into the output string, separated by a colon and a new line.\n    \n    create_function : The `create_function` function generates a prompt for creating a function with a specified objective and programming language. It then uses the GPT (Generative Pre-trained Transformer) model to generate the source code for the function as a JSON object, including required libraries and the source code. If an error occurs during the function creation process, it raises an exception with a corresponding error message.\n    \n    create_step_list : The function "create_step_list" takes in a goal and generates a step list in the form of a JSON object. It prompts the user with the goal and returns a structured step list as a JSON object containing a list of strings outlining the steps needed to achieve the goal, as well as a string describing how to verify the completion of the goal. If any errors occur during the process, it raises a value error along with the error message.\n    \n    describe_function : The "describe_function" function takes a function string as input and returns a description of the function by using GPT-3 natural language processing. It creates a prompt matching the format of a succinct description for a function, then uses GPT-3 to generate the description based on the provided function string. If there are any errors during the process, it raises a ValueError.\n    \n    required_fields : The function checks if all the required fields specified in the list are present in the given JSON object. If all the required fields are present, it returns `True`; otherwise, it returns `False`.\n    \n\n    The json object returned should have the following properties:\n    step_list: a list of strings describing the steps to accomplish the goal\n    additional_functions: a list of descriptions of functions that need to be written to accomplish the goal.\n\n    Both properties must exist, it\'s okay if they\'re empty.\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 12:39:42,399 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 12:39:42,566 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fabfa411350>
2024-01-14 12:39:42,567 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fabfa5a2450> server_hostname='api.openai.com' timeout=5.0
2024-01-14 12:39:42,777 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fabf9c229d0>
2024-01-14 12:39:42,777 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 12:39:42,777 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 12:39:42,778 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 12:39:42,778 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 12:39:42,778 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 12:40:39,197 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 17:40:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'55799'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78350'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'1.237s'), (b'x-request-id', b'ea86c4b2383c92130ac03a8b197c71b6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1ADPv1PbIIxSPAC7Z_UIepFDyCTDwhMGpwz1V9fcCxg-1705254039-1-ATHZt4E3oT/3fYUHDvCqrF+67R/D0qjVFeDjWJVyiEPaObbou2jCLDDIwU2yLRrQEcy4bIWjUe9ddtRYA0cVEOU=; path=/; expires=Sun, 14-Jan-24 18:10:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=EAi5.SUzWeg4wnWVABf2l8oebQkPiMLo0SRa_sTDuEE-1705254039182-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8457a8f07a8943f8-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 12:40:39,201 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 12:40:39,201 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 12:40:39,202 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 12:40:39,202 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 12:40:39,202 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 12:40:39,202 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 12:40:39,206 - INFO - functions.openai_call - Converting response 
                                                                                                     to json object
2024-01-14 12:40:39,206 - ERROR - __main__ - Error creating step list for Please post a tweet on twitter about how grskynet is
2024-01-14 12:40:39,297 - DEBUG - httpcore.connection - close.started
2024-01-14 12:40:39,298 - DEBUG - httpcore.connection - close.complete
2024-01-14 12:47:23,862 - INFO - __main__ - Skynet started
2024-01-14 12:47:23,862 - INFO - __main__ - Loading environment variables
2024-01-14 12:47:23,862 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 12:47:23,862 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 12:47:23,862 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 12:47:23,862 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 12:47:23,862 - INFO - __main__ - Loaded functions from functions
2024-01-14 12:47:23,863 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 12:47:23,863 - INFO - functions.get_functions - file size: 2609
2024-01-14 12:47:23,864 - INFO - functions.get_functions - tree size: 16
2024-01-14 12:47:23,992 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 12:47:24,076 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 12:47:24,077 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 12:47:24,077 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 12:47:24,078 - INFO - functions.get_functions - file size: 2128
2024-01-14 12:47:24,078 - INFO - functions.get_functions - tree size: 7
2024-01-14 12:47:24,078 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 12:47:24,080 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 12:47:24,081 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 12:47:24,081 - INFO - functions.get_functions - file size: 2971
2024-01-14 12:47:24,082 - INFO - functions.get_functions - tree size: 10
2024-01-14 12:47:24,082 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 12:47:24,083 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 12:47:24,084 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 12:47:24,084 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 12:47:24,084 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 12:47:24,085 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 12:47:24,086 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 12:47:24,087 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 12:47:24,087 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 12:47:24,087 - INFO - functions.get_functions - file size: 0
2024-01-14 12:47:24,087 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:47:24,087 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 12:47:24,088 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 12:47:24,088 - INFO - functions.get_functions - file size: 3140
2024-01-14 12:47:24,089 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:47:24,089 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 12:47:24,090 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 12:47:24,091 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 12:47:24,091 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 12:47:24,092 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 12:47:24,093 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 12:47:24,093 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 12:47:24,094 - INFO - functions.get_functions - file size: 0
2024-01-14 12:47:24,094 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:47:24,094 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 12:47:24,094 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 12:47:24,095 - INFO - functions.get_functions - file size: 5276
2024-01-14 12:47:24,096 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:47:24,097 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 12:47:24,099 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 12:47:24,100 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 12:47:24,102 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 12:47:24,103 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 12:47:24,104 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 12:47:24,105 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 12:47:30,773 - ERROR - __main__ - Error creating step list for Post a tweet on twitter
2024-01-14 12:47:41,545 - INFO - __main__ - Skynet started
2024-01-14 12:47:41,545 - INFO - __main__ - Loading environment variables
2024-01-14 12:47:41,545 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 12:47:41,545 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 12:47:41,545 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 12:47:41,546 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 12:47:41,546 - INFO - __main__ - Loaded functions from functions
2024-01-14 12:47:41,546 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 12:47:41,546 - INFO - functions.get_functions - file size: 2609
2024-01-14 12:47:41,547 - INFO - functions.get_functions - tree size: 16
2024-01-14 12:47:41,683 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 12:47:41,772 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 12:47:41,773 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 12:47:41,774 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 12:47:41,774 - INFO - functions.get_functions - file size: 2128
2024-01-14 12:47:41,775 - INFO - functions.get_functions - tree size: 7
2024-01-14 12:47:41,775 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 12:47:41,778 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 12:47:41,778 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 12:47:41,779 - INFO - functions.get_functions - file size: 2971
2024-01-14 12:47:41,780 - INFO - functions.get_functions - tree size: 10
2024-01-14 12:47:41,780 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 12:47:41,784 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 12:47:41,785 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 12:47:41,786 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 12:47:41,787 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 12:47:41,788 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 12:47:41,789 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 12:47:41,794 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 12:47:41,794 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 12:47:41,795 - INFO - functions.get_functions - file size: 0
2024-01-14 12:47:41,795 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:47:41,795 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 12:47:41,795 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 12:47:41,796 - INFO - functions.get_functions - file size: 3140
2024-01-14 12:47:41,797 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:47:41,797 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 12:47:41,798 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 12:47:41,800 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 12:47:41,802 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 12:47:41,803 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 12:47:41,807 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 12:47:41,807 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 12:47:41,808 - INFO - functions.get_functions - file size: 0
2024-01-14 12:47:41,810 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:47:41,811 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 12:47:41,812 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 12:47:41,812 - INFO - functions.get_functions - file size: 5276
2024-01-14 12:47:41,814 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:47:41,816 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 12:47:41,820 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 12:47:41,821 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 12:47:41,826 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 12:47:41,827 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 12:47:41,828 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 12:47:41,832 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 12:47:45,715 - INFO - functions.openai_call - 
Sending Prompt:
Create a list of atomic functions that would need to be called to accomplishes the following: Post a tweet on twitter

    Note that you can only use python to write these functions.

    The json object returned should have the following properties:    
    function_list: a list of function descriptions that accomplish the goal. This should just describe what the functions do.

    


2024-01-14 12:47:45,722 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Create a list of atomic functions that would need to be called to accomplishes the following: Post a tweet on twitter\n\n    Note that you can only use python to write these functions.\n\n    The json object returned should have the following properties:    \n    function_list: a list of function descriptions that accomplish the goal. This should just describe what the functions do.\n\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 12:47:45,737 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 12:47:45,866 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fbb376dd690>
2024-01-14 12:47:45,867 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fbb38046570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 12:47:45,971 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fbb376dd210>
2024-01-14 12:47:45,972 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 12:47:45,973 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 12:47:45,973 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 12:47:45,974 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 12:47:45,974 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 12:48:53,685 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 17:48:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'67558'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79886'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'85ms'), (b'x-request-id', b'b2807fdc88e331850b7ddf9ab9da8991'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=g_POMyL5K_kpNrlXLhXfGr.j40HqdsIBNc8w7Oss_BM-1705254533-1-Ad2JC3sbDl9RAo5NRnRZBFlJsOIesvd9C2ThJyfshltuJRwELuR9B64fdk7Zh4b3Xee0ClkOn+AGUMJIgTVdPv0=; path=/; expires=Sun, 14-Jan-24 18:18:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=wOJiBFLww8Iv2yls7KWPgWDOeJB0tvxyIRbssesixR4-1705254533656-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8457b4bc5917727b-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 12:48:53,686 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 12:48:53,687 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 12:48:53,688 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 12:48:53,688 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 12:48:53,689 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 12:48:53,689 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 12:48:53,699 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\n                                                                                                    ', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 12:48:53,700 - ERROR - __main__ - Error creating step list for Post a tweet on twitter
2024-01-14 12:48:53,827 - DEBUG - httpcore.connection - close.started
2024-01-14 12:48:53,829 - DEBUG - httpcore.connection - close.complete
2024-01-14 12:51:14,359 - INFO - __main__ - Skynet started
2024-01-14 12:51:14,360 - INFO - __main__ - Loading environment variables
2024-01-14 12:51:14,360 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 12:51:14,360 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 12:51:14,360 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 12:51:14,360 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 12:51:14,360 - INFO - __main__ - Loaded functions from functions
2024-01-14 12:51:14,360 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 12:51:14,361 - INFO - functions.get_functions - file size: 2609
2024-01-14 12:51:14,362 - INFO - functions.get_functions - tree size: 16
2024-01-14 12:51:14,511 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 12:51:14,646 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 12:51:14,648 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 12:51:14,648 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 12:51:14,648 - INFO - functions.get_functions - file size: 2128
2024-01-14 12:51:14,649 - INFO - functions.get_functions - tree size: 7
2024-01-14 12:51:14,649 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 12:51:14,651 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 12:51:14,651 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 12:51:14,651 - INFO - functions.get_functions - file size: 2971
2024-01-14 12:51:14,653 - INFO - functions.get_functions - tree size: 10
2024-01-14 12:51:14,653 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 12:51:14,654 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 12:51:14,655 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 12:51:14,655 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 12:51:14,656 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 12:51:14,656 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 12:51:14,657 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 12:51:14,658 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 12:51:14,659 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 12:51:14,659 - INFO - functions.get_functions - file size: 0
2024-01-14 12:51:14,659 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:51:14,659 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 12:51:14,659 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 12:51:14,659 - INFO - functions.get_functions - file size: 3138
2024-01-14 12:51:14,660 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:51:14,660 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 12:51:14,661 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 12:51:14,662 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 12:51:14,662 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 12:51:14,663 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 12:51:14,664 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 12:51:14,664 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 12:51:14,664 - INFO - functions.get_functions - file size: 0
2024-01-14 12:51:14,664 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:51:14,664 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 12:51:14,664 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 12:51:14,665 - INFO - functions.get_functions - file size: 5276
2024-01-14 12:51:14,666 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:51:14,666 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 12:51:14,669 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 12:51:14,669 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 12:51:14,671 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 12:51:14,672 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 12:51:14,672 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 12:51:14,673 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 12:51:24,723 - INFO - functions.openai_call - 
Sending Prompt:
Create a list of atomic functions that would need to be called to accomplishes the following: Please post a tweet on twitter

    Note that you can only use python to write these functions.

    The json object returned should have the following properties:
    
    function_list: a list of function descriptions that accomplish the goal. This should just describe what the functions do.
    


2024-01-14 12:51:24,759 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Create a list of atomic functions that would need to be called to accomplishes the following: Please post a tweet on twitter\n\n    Note that you can only use python to write these functions.\n\n    The json object returned should have the following properties:\n    \n    function_list: a list of function descriptions that accomplish the goal. This should just describe what the functions do.\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 12:51:24,780 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 12:51:24,940 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff8c3e03c50>
2024-01-14 12:51:24,940 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff8c475e570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 12:51:25,005 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff8c3e00e90>
2024-01-14 12:51:25,006 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 12:51:25,007 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 12:51:25,008 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 12:51:25,008 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 12:51:25,009 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 12:52:16,285 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 17:52:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'50777'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79884'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'87ms'), (b'x-request-id', b'bd578d0d6664504fd8c49f533b7eabd1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ZOS_qFATZbUxZzAvw35Dmcacyy4D9MEsFuIv53nXLx0-1705254736-1-AXJme904Iiq6d/68iFTlWR5FfWAwtdsVe1TWiQFwHgf66NKBV3Ao2SxObOYMY6bcKdT20m+ScjUwCMS2PWR65VY=; path=/; expires=Sun, 14-Jan-24 18:22:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=HT82QbI7nnfTU63HorA4WHJjfCvTpzTKlQI3PR6VqXo-1705254736118-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8457ba155cc742fc-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 12:52:16,288 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 12:52:16,288 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 12:52:16,289 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 12:52:16,289 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 12:52:16,289 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 12:52:16,289 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 12:52:16,292 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\n                                                                                                      ', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 12:52:16,292 - ERROR - __main__ - Error creating step list for Please post a tweet on twitter
2024-01-14 12:52:16,391 - DEBUG - httpcore.connection - close.started
2024-01-14 12:52:16,392 - DEBUG - httpcore.connection - close.complete
2024-01-14 12:59:20,828 - INFO - __main__ - Skynet started
2024-01-14 12:59:20,829 - INFO - __main__ - Loading environment variables
2024-01-14 12:59:20,829 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 12:59:20,829 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 12:59:20,829 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 12:59:20,829 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 12:59:20,829 - INFO - __main__ - Loaded functions from functions
2024-01-14 12:59:20,829 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 12:59:20,830 - INFO - functions.get_functions - file size: 2609
2024-01-14 12:59:20,831 - INFO - functions.get_functions - tree size: 16
2024-01-14 12:59:20,994 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 12:59:21,114 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 12:59:21,116 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 12:59:21,116 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 12:59:21,117 - INFO - functions.get_functions - file size: 2128
2024-01-14 12:59:21,118 - INFO - functions.get_functions - tree size: 7
2024-01-14 12:59:21,118 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 12:59:21,122 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 12:59:21,123 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 12:59:21,124 - INFO - functions.get_functions - file size: 2971
2024-01-14 12:59:21,126 - INFO - functions.get_functions - tree size: 10
2024-01-14 12:59:21,127 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 12:59:21,128 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 12:59:21,129 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 12:59:21,129 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 12:59:21,130 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 12:59:21,130 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 12:59:21,131 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 12:59:21,132 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 12:59:21,132 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 12:59:21,132 - INFO - functions.get_functions - file size: 0
2024-01-14 12:59:21,132 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:59:21,133 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 12:59:21,133 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 12:59:21,133 - INFO - functions.get_functions - file size: 3182
2024-01-14 12:59:21,134 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:59:21,134 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 12:59:21,135 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 12:59:21,136 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 12:59:21,137 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 12:59:21,137 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 12:59:21,138 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 12:59:21,138 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 12:59:21,138 - INFO - functions.get_functions - file size: 0
2024-01-14 12:59:21,139 - INFO - functions.get_functions - tree size: 0
2024-01-14 12:59:21,139 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 12:59:21,139 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 12:59:21,139 - INFO - functions.get_functions - file size: 5276
2024-01-14 12:59:21,141 - INFO - functions.get_functions - tree size: 9
2024-01-14 12:59:21,141 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 12:59:21,143 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 12:59:21,144 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 12:59:21,146 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 12:59:21,146 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 12:59:21,147 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 12:59:21,148 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 12:59:32,019 - INFO - functions.openai_call - 
Sending Prompt:
Create a list of atomic functions that would need to be called to accomplishes the following: Post a tweet on twitter

    Note that you can only use python to write these functions.

    The json object returned should have the following properties:
    
    function_list: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.


2024-01-14 12:59:32,028 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Create a list of atomic functions that would need to be called to accomplishes the following: Post a tweet on twitter\n\n    Note that you can only use python to write these functions.\n\n    The json object returned should have the following properties:\n    \n    function_list: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.'}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 12:59:32,094 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 12:59:32,241 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb5360dbdd0>
2024-01-14 12:59:32,241 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb536a46570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 12:59:32,415 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb5360e08d0>
2024-01-14 12:59:32,415 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 12:59:32,417 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 12:59:32,417 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 12:59:32,417 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 12:59:32,417 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 12:59:33,808 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 17:59:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1004'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79875'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'93ms'), (b'x-request-id', b'9ddff8193ef03e8e615aeea440f5b664'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Xr.P5WdsDBGDOUQWL3xIMdVyNrzXFb.7da2KmeWiMac-1705255173-1-AXd8DhMns2mFHz8mnJ2HsoQ2WVcbqPfaEuyf7M01zQwL/6DGH3umfhze/EO53xm+ffQUZEMer0tS8g81HspY7kI=; path=/; expires=Sun, 14-Jan-24 18:29:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=KFlMHLANBtsHd.jlOT30dMgz2LwDlOTrGxvSpMAvaj8-1705255173738-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8457c5fb9c977d1e-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 12:59:33,810 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 12:59:33,811 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 12:59:33,812 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 12:59:33,812 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 12:59:33,812 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 12:59:33,813 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 12:59:33,816 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='  {\n\n"function_list": [\n\n"Open a connection to the Twitter API using OAuth authentication",\n\n"Create a function to format the tweet message including any desired hashtags or mentions",\n\n"Encode the tweet message into a valid JSON format",\n\n"Send the JSON formatted tweet to the Twitter API using a POST request",\n\n"Handle any error responses from the Twitter API"\n\n]\n\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 13:00:19,011 - DEBUG - httpcore.connection - close.started
2024-01-14 13:00:19,013 - DEBUG - httpcore.connection - close.complete
2024-01-14 13:01:57,084 - INFO - __main__ - Skynet started
2024-01-14 13:01:57,084 - INFO - __main__ - Loading environment variables
2024-01-14 13:01:57,084 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 13:01:57,084 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 13:01:57,084 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 13:01:57,084 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 13:01:57,085 - INFO - __main__ - Loaded functions from functions
2024-01-14 13:01:57,085 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 13:01:57,085 - INFO - functions.get_functions - file size: 2609
2024-01-14 13:01:57,086 - INFO - functions.get_functions - tree size: 16
2024-01-14 13:01:57,284 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 13:01:57,439 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 13:01:57,440 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 13:01:57,441 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 13:01:57,441 - INFO - functions.get_functions - file size: 2128
2024-01-14 13:01:57,442 - INFO - functions.get_functions - tree size: 7
2024-01-14 13:01:57,442 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 13:01:57,445 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 13:01:57,445 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 13:01:57,446 - INFO - functions.get_functions - file size: 2971
2024-01-14 13:01:57,448 - INFO - functions.get_functions - tree size: 10
2024-01-14 13:01:57,448 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 13:01:57,450 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 13:01:57,451 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 13:01:57,452 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 13:01:57,454 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 13:01:57,455 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 13:01:57,456 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 13:01:57,459 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 13:01:57,459 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 13:01:57,460 - INFO - functions.get_functions - file size: 0
2024-01-14 13:01:57,460 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:01:57,461 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 13:01:57,461 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 13:01:57,462 - INFO - functions.get_functions - file size: 3248
2024-01-14 13:01:57,463 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:01:57,464 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 13:01:57,466 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 13:01:57,467 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 13:01:57,469 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 13:01:57,471 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 13:01:57,473 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 13:01:57,473 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 13:01:57,474 - INFO - functions.get_functions - file size: 0
2024-01-14 13:01:57,475 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:01:57,475 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 13:01:57,476 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 13:01:57,477 - INFO - functions.get_functions - file size: 5276
2024-01-14 13:01:57,479 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:01:57,481 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 13:01:57,487 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 13:01:57,489 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 13:01:57,492 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 13:01:57,493 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 13:01:57,495 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 13:01:57,497 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 13:02:03,008 - INFO - functions.openai_call - 
Sending Prompt:
Create a list describing atomic functions that would need to be called to accomplishes the following: Post a tweet to twitter

    When coming up with this list, please try to describe "abstract" functions that will be re-useable for other purposes

    The json object returned should have the following properties:
    
    function_list: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.


2024-01-14 13:02:03,015 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Create a list describing atomic functions that would need to be called to accomplishes the following: Post a tweet to twitter\n\n    When coming up with this list, please try to describe "abstract" functions that will be re-useable for other purposes\n\n    The json object returned should have the following properties:\n    \n    function_list: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.'}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 13:02:03,082 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 13:02:03,372 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ffa6d530110>
2024-01-14 13:02:03,373 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7ffa6d6ae4e0> server_hostname='api.openai.com' timeout=5.0
2024-01-14 13:02:03,526 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ffa6cd45710>
2024-01-14 13:02:03,527 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 13:02:03,528 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 13:02:03,528 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 13:02:03,529 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 13:02:03,529 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 13:02:38,367 - DEBUG - httpcore.http11 - receive_response_headers.failed exception=KeyboardInterrupt()
2024-01-14 13:02:38,369 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 13:02:38,370 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 13:02:38,371 - ERROR - __main__ - Error creating step list for Post a tweet to twitter
2024-01-14 13:02:40,148 - INFO - __main__ - Skynet started
2024-01-14 13:02:40,148 - INFO - __main__ - Loading environment variables
2024-01-14 13:02:40,149 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 13:02:40,149 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 13:02:40,149 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 13:02:40,149 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 13:02:40,149 - INFO - __main__ - Loaded functions from functions
2024-01-14 13:02:40,149 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 13:02:40,149 - INFO - functions.get_functions - file size: 2609
2024-01-14 13:02:40,150 - INFO - functions.get_functions - tree size: 16
2024-01-14 13:02:40,285 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 13:02:40,381 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 13:02:40,382 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 13:02:40,383 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 13:02:40,383 - INFO - functions.get_functions - file size: 2128
2024-01-14 13:02:40,384 - INFO - functions.get_functions - tree size: 7
2024-01-14 13:02:40,384 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 13:02:40,387 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 13:02:40,387 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 13:02:40,388 - INFO - functions.get_functions - file size: 2971
2024-01-14 13:02:40,389 - INFO - functions.get_functions - tree size: 10
2024-01-14 13:02:40,389 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 13:02:40,391 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 13:02:40,392 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 13:02:40,392 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 13:02:40,393 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 13:02:40,394 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 13:02:40,395 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 13:02:40,396 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 13:02:40,397 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 13:02:40,397 - INFO - functions.get_functions - file size: 0
2024-01-14 13:02:40,397 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:02:40,398 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 13:02:40,398 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 13:02:40,398 - INFO - functions.get_functions - file size: 3248
2024-01-14 13:02:40,399 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:02:40,400 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 13:02:40,400 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 13:02:40,406 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 13:02:40,413 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 13:02:40,413 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 13:02:40,415 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 13:02:40,415 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 13:02:40,415 - INFO - functions.get_functions - file size: 0
2024-01-14 13:02:40,415 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:02:40,416 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 13:02:40,416 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 13:02:40,416 - INFO - functions.get_functions - file size: 5276
2024-01-14 13:02:40,418 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:02:40,422 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 13:02:40,425 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 13:02:40,426 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 13:02:40,433 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 13:02:40,434 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 13:02:40,435 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 13:02:40,437 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 13:02:44,595 - INFO - functions.openai_call - 
Sending Prompt:
Create a list describing atomic functions that would need to be called to accomplishes the following: Post a tweet to twitter

    When coming up with this list, please try to describe "abstract" functions that will be re-useable for other purposes

    The json object returned should have the following properties:
    
    function_list: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.


2024-01-14 13:02:44,603 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Create a list describing atomic functions that would need to be called to accomplishes the following: Post a tweet to twitter\n\n    When coming up with this list, please try to describe "abstract" functions that will be re-useable for other purposes\n\n    The json object returned should have the following properties:\n    \n    function_list: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.'}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 13:02:44,619 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 13:02:44,789 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fdd1531bf10>
2024-01-14 13:02:44,789 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fdd1509e4e0> server_hostname='api.openai.com' timeout=5.0
2024-01-14 13:02:45,067 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fdd14f0cad0>
2024-01-14 13:02:45,067 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 13:02:45,068 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 13:02:45,069 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 13:02:45,069 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 13:02:45,069 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 13:03:06,242 - DEBUG - httpcore.http11 - receive_response_headers.failed exception=KeyboardInterrupt()
2024-01-14 13:03:06,243 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 13:03:06,247 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 13:03:06,248 - ERROR - __main__ - Error creating step list for Post a tweet to twitter
2024-01-14 13:03:08,067 - INFO - __main__ - Skynet started
2024-01-14 13:03:08,068 - INFO - __main__ - Loading environment variables
2024-01-14 13:03:08,068 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 13:03:08,068 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 13:03:08,068 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 13:03:08,068 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 13:03:08,068 - INFO - __main__ - Loaded functions from functions
2024-01-14 13:03:08,068 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 13:03:08,069 - INFO - functions.get_functions - file size: 2609
2024-01-14 13:03:08,070 - INFO - functions.get_functions - tree size: 16
2024-01-14 13:03:08,207 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 13:03:08,299 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 13:03:08,301 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 13:03:08,301 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 13:03:08,302 - INFO - functions.get_functions - file size: 2128
2024-01-14 13:03:08,303 - INFO - functions.get_functions - tree size: 7
2024-01-14 13:03:08,304 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 13:03:08,310 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 13:03:08,312 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 13:03:08,313 - INFO - functions.get_functions - file size: 2971
2024-01-14 13:03:08,315 - INFO - functions.get_functions - tree size: 10
2024-01-14 13:03:08,315 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 13:03:08,317 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 13:03:08,319 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 13:03:08,320 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 13:03:08,321 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 13:03:08,322 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 13:03:08,324 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 13:03:08,330 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 13:03:08,332 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 13:03:08,334 - INFO - functions.get_functions - file size: 0
2024-01-14 13:03:08,342 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:03:08,343 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 13:03:08,345 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 13:03:08,346 - INFO - functions.get_functions - file size: 3125
2024-01-14 13:03:08,348 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:03:08,348 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 13:03:08,351 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 13:03:08,358 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 13:03:08,365 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 13:03:08,367 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 13:03:08,368 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 13:03:08,368 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 13:03:08,369 - INFO - functions.get_functions - file size: 0
2024-01-14 13:03:08,369 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:03:08,369 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 13:03:08,369 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 13:03:08,369 - INFO - functions.get_functions - file size: 5276
2024-01-14 13:03:08,371 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:03:08,371 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 13:03:08,373 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 13:03:08,374 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 13:03:08,376 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 13:03:08,376 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 13:03:08,377 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 13:03:08,379 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 13:03:11,978 - INFO - functions.openai_call - 
Sending Prompt:
Create a list describing atomic functions that would need to be called to accomplishes the following: Post a tweet to twitter

    The json object returned should have the following properties:
    
    function_list: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.


2024-01-14 13:03:11,987 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Create a list describing atomic functions that would need to be called to accomplishes the following: Post a tweet to twitter\n\n    The json object returned should have the following properties:\n    \n    function_list: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.'}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 13:03:12,006 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 13:03:12,098 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd0bfe97e50>
2024-01-14 13:03:12,099 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd0c029e4e0> server_hostname='api.openai.com' timeout=5.0
2024-01-14 13:03:12,208 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd0c010e0d0>
2024-01-14 13:03:12,209 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 13:03:12,210 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 13:03:12,210 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 13:03:12,211 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 13:03:12,211 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 13:04:12,681 - INFO - __main__ - Skynet started
2024-01-14 13:04:12,712 - INFO - __main__ - Loading environment variables
2024-01-14 13:04:12,712 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-4-1106-preview
2024-01-14 13:04:12,712 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 13:04:12,712 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 13:04:12,712 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 13:04:12,712 - INFO - __main__ - Loaded functions from functions
2024-01-14 13:04:12,713 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 13:04:12,713 - INFO - functions.get_functions - file size: 2609
2024-01-14 13:04:12,714 - INFO - functions.get_functions - tree size: 16
2024-01-14 13:04:12,859 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 13:04:13,109 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 13:04:13,110 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 13:04:13,111 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 13:04:13,111 - INFO - functions.get_functions - file size: 2128
2024-01-14 13:04:13,112 - INFO - functions.get_functions - tree size: 7
2024-01-14 13:04:13,112 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 13:04:13,114 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 13:04:13,117 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 13:04:13,118 - INFO - functions.get_functions - file size: 2971
2024-01-14 13:04:13,119 - INFO - functions.get_functions - tree size: 10
2024-01-14 13:04:13,120 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 13:04:13,121 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 13:04:13,122 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 13:04:13,122 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 13:04:13,123 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 13:04:13,126 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 13:04:13,128 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 13:04:13,130 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 13:04:13,130 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 13:04:13,131 - INFO - functions.get_functions - file size: 0
2024-01-14 13:04:13,131 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:04:13,131 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 13:04:13,131 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 13:04:13,132 - INFO - functions.get_functions - file size: 3248
2024-01-14 13:04:13,133 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:04:13,133 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 13:04:13,134 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 13:04:13,137 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 13:04:13,139 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 13:04:13,140 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 13:04:13,142 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 13:04:13,142 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 13:04:13,142 - INFO - functions.get_functions - file size: 0
2024-01-14 13:04:13,142 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:04:13,143 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 13:04:13,143 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 13:04:13,143 - INFO - functions.get_functions - file size: 5276
2024-01-14 13:04:13,147 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:04:13,147 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 13:04:13,150 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 13:04:13,151 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 13:04:13,153 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 13:04:13,154 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 13:04:13,154 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 13:04:13,158 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 13:04:21,161 - INFO - functions.openai_call - 
Sending Prompt:
Create a list describing atomic functions that would need to be called to accomplishes the following: Post a tweet to twitter

    When coming up with this list, please try to describe "abstract" functions that will be re-useable for other purposes

    The json object returned should have the following properties:
    
    function_list: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.


2024-01-14 13:04:21,169 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Create a list describing atomic functions that would need to be called to accomplishes the following: Post a tweet to twitter\n\n    When coming up with this list, please try to describe "abstract" functions that will be re-useable for other purposes\n\n    The json object returned should have the following properties:\n    \n    function_list: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.'}], 'model': 'gpt-4-1106-preview', 'response_format': {'type': 'json_object'}}}
2024-01-14 13:04:21,217 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 13:04:21,345 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7f56749250>
2024-01-14 13:04:21,346 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f7f570ae4e0> server_hostname='api.openai.com' timeout=5.0
2024-01-14 13:04:21,451 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7f56748950>
2024-01-14 13:04:21,452 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 13:04:21,453 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 13:04:21,454 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 13:04:21,454 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 13:04:21,454 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 13:04:31,586 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 18:04:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'9897'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'1500000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'1499858'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'8.179s'), (b'x-request-id', b'c42358612737570b6935704d7c62795a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Nn22BmYNAQwQCeooY20n3.vi4bWwI410wDgRy_DX_L0-1705255471-1-Ab0HKkf94rZ/+7gE8azmtGhbEhg3MXlHHccowJUAVhkdWWymsdM6H9gkMHQZC4jGNNpC2KQ2rNNF7Y1icaJ2p5I=; path=/; expires=Sun, 14-Jan-24 18:34:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LulIAOkNlIawBtHqNp4XYtt.MaN02hBI_iykEFSkc3o-1705255471473-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8457cd0a189e4376-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 13:04:31,588 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 13:04:31,588 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 13:04:31,589 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 13:04:31,589 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 13:04:31,589 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 13:04:31,589 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 13:04:31,592 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='     {\n       "function_list": [\n          "Authenticate User: Validate the user\'s credentials with Twitter\'s API.",\n          "Format Tweet: Prepare the text content of the tweet, ensuring it meets character limits and encoding requirements.",\n          "Check Media Attachments: If the tweet includes media, verify the format and size, and prepare for upload.",\n          "Upload Media: Send media files to Twitter\'s servers and obtain media identifiers if applicable.",\n          "Compose Tweet Data: Combine text content with media identifiers and additional metadata (like reply status, location, etc.) into the required format.",\n          "Post Tweet: Send the composed tweet to Twitter\'s API endpoint for posting new tweets.",\n          "Handle Response: Interpret the response from Twitter\'s API to determine success or failure of the tweet posting.",\n          "Parse Response Data: Extract relevant data from the API response to return a json object with tweet details.",\n          "Error Handling: Manage errors and exceptions that occur during the process and provide meaningful feedback.",\n          "Log Activity: Record the operation\'s details such as timestamp, success/failure status, and error messages if any."\n        ]\n    }\n', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 13:06:13,830 - DEBUG - httpcore.connection - close.started
2024-01-14 13:06:13,904 - DEBUG - httpcore.connection - close.complete
2024-01-14 13:48:04,784 - INFO - __main__ - Skynet started
2024-01-14 13:48:04,784 - INFO - __main__ - Loading environment variables
2024-01-14 13:48:04,784 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 13:48:04,785 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 13:48:04,785 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 13:48:04,785 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 13:48:04,785 - INFO - __main__ - Loaded functions from functions
2024-01-14 13:48:04,785 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 13:48:04,786 - INFO - functions.get_functions - file size: 2609
2024-01-14 13:48:04,787 - INFO - functions.get_functions - tree size: 16
2024-01-14 13:48:05,157 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 13:48:05,331 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 13:48:05,333 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 13:48:05,333 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 13:48:05,333 - INFO - functions.get_functions - file size: 2493
2024-01-14 13:48:05,334 - INFO - functions.get_functions - tree size: 7
2024-01-14 13:48:05,334 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 13:48:05,337 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 13:48:05,337 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 13:48:05,337 - INFO - functions.get_functions - file size: 2971
2024-01-14 13:48:05,339 - INFO - functions.get_functions - tree size: 10
2024-01-14 13:48:05,339 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 13:48:05,342 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 13:48:05,342 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 13:48:05,343 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 13:48:05,344 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 13:48:05,351 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 13:48:05,352 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 13:48:05,353 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 13:48:05,354 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 13:48:05,354 - INFO - functions.get_functions - file size: 0
2024-01-14 13:48:05,354 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:48:05,354 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 13:48:05,354 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 13:48:05,354 - INFO - functions.get_functions - file size: 3266
2024-01-14 13:48:05,355 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:48:05,355 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 13:48:05,356 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 13:48:05,357 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 13:48:05,357 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 13:48:05,358 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 13:48:05,359 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 13:48:05,359 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 13:48:05,359 - INFO - functions.get_functions - file size: 0
2024-01-14 13:48:05,359 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:48:05,359 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 13:48:05,360 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 13:48:05,360 - INFO - functions.get_functions - file size: 5276
2024-01-14 13:48:05,362 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:48:05,362 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 13:48:05,364 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 13:48:05,365 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 13:48:05,368 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 13:48:05,368 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 13:48:05,368 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 13:48:05,369 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 13:48:11,747 - INFO - functions.openai_call - 
Sending Prompt:
Create a list describing atomic functions that would need to be called to accomplishes the following: Post a tweet to twitter

    When coming up with this list, please try to describe "abstract" functions that will be re-useable for other purposes

    The json object returned should have the following properties:
    
    function_list: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.


2024-01-14 13:48:11,753 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Create a list describing atomic functions that would need to be called to accomplishes the following: Post a tweet to twitter\n\n    When coming up with this list, please try to describe "abstract" functions that will be re-useable for other purposes\n\n    The json object returned should have the following properties:\n    \n    function_list: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.'}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 13:48:11,813 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 13:48:11,953 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fdbd3d65ad0>
2024-01-14 13:48:11,954 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fdbd3efa570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 13:48:12,195 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fdbd3d67090>
2024-01-14 13:48:12,196 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 13:48:12,196 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 13:48:12,196 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 13:48:12,196 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 13:48:12,197 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 13:49:15,465 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 18:49:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'63076'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79858'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'106ms'), (b'x-request-id', b'e6bee38554a1f1f2bf0f196bfd29d440'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=JiVq1bt6amxyg.uIVZRkXW6qsoiElhV8OyNhL6FxAdo-1705258155-1-AS4X4/+HJxVTOsjTnwifW/QgGQQXHgv2YRpHOekUxWARPMxE9mskAx5fHhiNfFGChVYDULjFpT1T8/q47oYMz/E=; path=/; expires=Sun, 14-Jan-24 19:19:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=7fwcrY_mBANPjfFDwdyRMDe1vKP4jpPGXXQbYQwWY4U-1705258155428-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84580d4498567d00-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 13:49:15,467 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 13:49:15,468 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 13:49:15,469 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 13:49:15,469 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 13:49:15,469 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 13:49:15,469 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 13:49:15,474 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='        \n\n     \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n        \n  \n\n       \n  \n\n       \n  \n\n       \n  \n\n      \n  \n\n     \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n  \n\n    \n\n  \n\n  \n\n  \n  \n\n  \n\n  \n  \n\n  \n  \n\n  \n  \n\n  \n  \n\n  \n  \n\n  \n  \n\n  \n  \n\n  \n  \n\n  \n  \n\n  \n  \n\n  \n  \n\n  \n  \n\n  ', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 13:49:15,474 - ERROR - functions.openai_call - The response from the AI could not be converted to a json object.
2024-01-14 13:49:15,474 - ERROR - __main__ - Error creating step list for Post a tweet to twitter
2024-01-14 13:49:15,643 - DEBUG - httpcore.connection - close.started
2024-01-14 13:49:15,644 - DEBUG - httpcore.connection - close.complete
2024-01-14 13:57:54,784 - INFO - __main__ - Skynet started
2024-01-14 13:57:54,786 - INFO - __main__ - Loading environment variables
2024-01-14 13:57:54,786 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 13:57:54,786 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 13:57:54,786 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 13:57:54,786 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 13:57:54,786 - INFO - __main__ - Loaded functions from functions
2024-01-14 13:57:54,786 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 13:57:54,786 - INFO - functions.get_functions - file size: 2609
2024-01-14 13:57:54,788 - INFO - functions.get_functions - tree size: 16
2024-01-14 13:57:54,962 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 13:57:55,118 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 13:57:55,120 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 13:57:55,120 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 13:57:55,121 - INFO - functions.get_functions - file size: 2493
2024-01-14 13:57:55,121 - INFO - functions.get_functions - tree size: 7
2024-01-14 13:57:55,122 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 13:57:55,126 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 13:57:55,127 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 13:57:55,128 - INFO - functions.get_functions - file size: 2971
2024-01-14 13:57:55,129 - INFO - functions.get_functions - tree size: 10
2024-01-14 13:57:55,130 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 13:57:55,131 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 13:57:55,132 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 13:57:55,133 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 13:57:55,133 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 13:57:55,134 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 13:57:55,135 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 13:57:55,136 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 13:57:55,137 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 13:57:55,137 - INFO - functions.get_functions - file size: 0
2024-01-14 13:57:55,138 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:57:55,138 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 13:57:55,138 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 13:57:55,138 - INFO - functions.get_functions - file size: 3250
2024-01-14 13:57:55,139 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:57:55,140 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 13:57:55,141 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 13:57:55,143 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 13:57:55,144 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 13:57:55,145 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 13:57:55,146 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 13:57:55,147 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 13:57:55,147 - INFO - functions.get_functions - file size: 0
2024-01-14 13:57:55,147 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:57:55,148 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 13:57:55,148 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 13:57:55,148 - INFO - functions.get_functions - file size: 5276
2024-01-14 13:57:55,150 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:57:55,150 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 13:57:55,153 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 13:57:55,154 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 13:57:55,157 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 13:57:55,158 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 13:57:55,159 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 13:57:55,162 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 13:58:14,090 - INFO - functions.openai_call - 
Sending Prompt:
Describe the steps that would need to be called to accomplishes the following: Tweet on twitter

    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes

    return a JSON object with the following property
    
    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.
    
    JSON OBJECT:
    


2024-01-14 13:58:14,098 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Tweet on twitter\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 13:58:14,167 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 13:58:20,334 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fba62322b50>
2024-01-14 13:58:20,334 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fba62c9a570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 13:58:20,580 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fba62334290>
2024-01-14 13:58:20,580 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 13:58:20,581 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 13:58:20,581 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 13:58:20,581 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 13:58:20,581 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 13:58:22,484 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 18:58:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1618'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79864'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'102ms'), (b'x-request-id', b'ae30080f6334978032d44d6dae98359c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_nIKPm0O86rUxxEFrcO6C._yPR.8L2z.LNHT.41AhUw-1705258702-1-Adj7oUtukXfaay95ck8GSCKur+IxQrQUjhvOwgs3Qk+4kU/SvD2OwFTUDFBAxFzTlSfIDzFZI44GLFSQZp64leI=; path=/; expires=Sun, 14-Jan-24 19:28:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=IYL5m2VyjTbRa0jZwsPzmNVoOW9fqqxCDXuFOTJljj0-1705258702441-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84581c1f7e8d43d3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 13:58:22,488 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 13:58:22,490 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 13:58:22,491 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 13:58:22,493 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 13:58:22,494 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 13:58:22,495 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 13:58:22,530 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\n  "function_descriptions": [\n    "Open Twitter app or website",\n    "Authenticate user\'s login credentials",\n    "Navigate to the Tweet section",\n    "Compose the tweet message",\n    "Click \'Tweet\'",\n    "Return confirmation or error message"\n  ]\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 13:58:22,531 - ERROR - functions.prompt_creation - The json object returned from the language model did not contain the required fields.
2024-01-14 13:58:22,532 - ERROR - __main__ - Error creating step list for Tweet on twitter
2024-01-14 13:58:22,691 - DEBUG - httpcore.connection - close.started
2024-01-14 13:58:22,693 - DEBUG - httpcore.connection - close.complete
2024-01-14 13:59:00,600 - INFO - __main__ - Skynet started
2024-01-14 13:59:00,600 - INFO - __main__ - Loading environment variables
2024-01-14 13:59:00,601 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 13:59:00,601 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 13:59:00,601 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 13:59:00,601 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 13:59:00,602 - INFO - __main__ - Loaded functions from functions
2024-01-14 13:59:00,602 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 13:59:00,602 - INFO - functions.get_functions - file size: 2609
2024-01-14 13:59:00,603 - INFO - functions.get_functions - tree size: 16
2024-01-14 13:59:00,737 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 13:59:00,838 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 13:59:00,840 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 13:59:00,840 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 13:59:00,840 - INFO - functions.get_functions - file size: 2493
2024-01-14 13:59:00,841 - INFO - functions.get_functions - tree size: 7
2024-01-14 13:59:00,841 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 13:59:00,843 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 13:59:00,844 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 13:59:00,844 - INFO - functions.get_functions - file size: 2971
2024-01-14 13:59:00,845 - INFO - functions.get_functions - tree size: 10
2024-01-14 13:59:00,845 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 13:59:00,846 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 13:59:00,847 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 13:59:00,847 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 13:59:00,847 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 13:59:00,848 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 13:59:00,849 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 13:59:00,850 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 13:59:00,850 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 13:59:00,850 - INFO - functions.get_functions - file size: 0
2024-01-14 13:59:00,851 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:59:00,851 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 13:59:00,851 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 13:59:00,851 - INFO - functions.get_functions - file size: 3258
2024-01-14 13:59:00,852 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:59:00,852 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 13:59:00,852 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 13:59:00,853 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 13:59:00,854 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 13:59:00,854 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 13:59:00,856 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 13:59:00,856 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 13:59:00,856 - INFO - functions.get_functions - file size: 0
2024-01-14 13:59:00,856 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:59:00,856 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 13:59:00,856 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 13:59:00,856 - INFO - functions.get_functions - file size: 5276
2024-01-14 13:59:00,858 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:59:00,858 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 13:59:00,860 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 13:59:00,861 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 13:59:00,863 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 13:59:00,863 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 13:59:00,864 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 13:59:00,865 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 13:59:05,719 - INFO - functions.openai_call - 
Sending Prompt:
Describe the steps that would need to be called to accomplishes the following: Tweet on twitter

    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes

    return a JSON object with the following property
    
    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.
    
    JSON OBJECT:
    


2024-01-14 13:59:05,727 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Tweet on twitter\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 13:59:05,744 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 13:59:05,896 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc775b1fb10>
2024-01-14 13:59:05,896 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc776272570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 13:59:06,000 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc7760e6550>
2024-01-14 13:59:06,000 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 13:59:06,000 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 13:59:06,001 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 13:59:06,001 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 13:59:06,001 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 13:59:08,456 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 18:59:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'2223'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79864'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'102ms'), (b'x-request-id', b'266666f8bab4ce43f05784d839b16ebe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hlY_suCFg8lNDJgIHhidrRkVuTMm3PPsku9Azp_jnAA-1705258748-1-AXAPrk7uTrJL4ukh1UzIn8Ahb5Aoom4bsJ9l0DfUpFTZMUOYEHY1sCXnWezhEsQDDiU5CyGI9IaGLgNlm0BXmqw=; path=/; expires=Sun, 14-Jan-24 19:29:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=X0h0TE.zPg9OWOe4if7AeclVtSWXTrRUJExpVq9mEfE-1705258748458-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84581d3b593b6a57-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 13:59:08,458 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 13:59:08,458 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 13:59:08,458 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 13:59:08,459 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 13:59:08,459 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 13:59:08,459 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 13:59:08,462 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\n  "function_descriptions": [\n    "Authenticate user: This function verifies the user\'s login credentials and allows them to access the Twitter API.",\n    "Compose tweet: This function allows the user to input their tweet content and prepares it for posting.",\n    "Post tweet: This function sends the prepared tweet to Twitter\'s servers for posting.",\n    "Handle response: This function receives and processes the response from Twitter whether the tweet was successfully posted or if there was an error."\n  ]\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 13:59:08,462 - ERROR - __main__ - Error creating step list for Tweet on twitter
2024-01-14 13:59:08,586 - DEBUG - httpcore.connection - close.started
2024-01-14 13:59:08,586 - DEBUG - httpcore.connection - close.complete
2024-01-14 13:59:29,664 - INFO - __main__ - Skynet started
2024-01-14 13:59:29,665 - INFO - __main__ - Loading environment variables
2024-01-14 13:59:29,665 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 13:59:29,665 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 13:59:29,665 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 13:59:29,666 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 13:59:29,666 - INFO - __main__ - Loaded functions from functions
2024-01-14 13:59:29,666 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 13:59:29,666 - INFO - functions.get_functions - file size: 2609
2024-01-14 13:59:29,668 - INFO - functions.get_functions - tree size: 16
2024-01-14 13:59:29,816 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 13:59:29,998 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 13:59:30,013 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 13:59:30,017 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 13:59:30,019 - INFO - functions.get_functions - file size: 2493
2024-01-14 13:59:30,029 - INFO - functions.get_functions - tree size: 7
2024-01-14 13:59:30,031 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 13:59:30,053 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 13:59:30,056 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 13:59:30,057 - INFO - functions.get_functions - file size: 2971
2024-01-14 13:59:30,061 - INFO - functions.get_functions - tree size: 10
2024-01-14 13:59:30,068 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 13:59:30,071 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 13:59:30,076 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 13:59:30,086 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 13:59:30,087 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 13:59:30,088 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 13:59:30,094 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 13:59:30,096 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 13:59:30,096 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 13:59:30,097 - INFO - functions.get_functions - file size: 0
2024-01-14 13:59:30,097 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:59:30,097 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 13:59:30,098 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 13:59:30,098 - INFO - functions.get_functions - file size: 3258
2024-01-14 13:59:30,100 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:59:30,101 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 13:59:30,103 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 13:59:30,109 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 13:59:30,110 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 13:59:30,111 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 13:59:30,113 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 13:59:30,113 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 13:59:30,114 - INFO - functions.get_functions - file size: 0
2024-01-14 13:59:30,115 - INFO - functions.get_functions - tree size: 0
2024-01-14 13:59:30,115 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 13:59:30,116 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 13:59:30,116 - INFO - functions.get_functions - file size: 5276
2024-01-14 13:59:30,130 - INFO - functions.get_functions - tree size: 9
2024-01-14 13:59:30,131 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 13:59:30,133 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 13:59:30,134 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 13:59:30,139 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 13:59:30,140 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 13:59:30,141 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 13:59:30,144 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 13:59:34,640 - INFO - functions.openai_call - 
Sending Prompt:
Describe the steps that would need to be called to accomplishes the following: Tweet on twitter

    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes

    return a JSON object with the following property
    
    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.
    
    JSON OBJECT:
    


2024-01-14 13:59:34,648 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Tweet on twitter\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 13:59:34,664 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 13:59:39,887 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1d4c3e85d0>
2024-01-14 13:59:39,888 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f1d4cd52570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 13:59:40,605 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1d4c748310>
2024-01-14 13:59:40,606 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 13:59:40,607 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 13:59:40,607 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 13:59:40,607 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 13:59:40,607 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 13:59:42,351 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 18:59:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1528'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79864'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'102ms'), (b'x-request-id', b'5a6afdf298cc4e3a128d5f14ac2942ec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4fd13cEF0uqLod9A9d3eQAaoMTorRvI7eijWo.VNgx0-1705258782-1-AQqbkwXOb6aQsGavvmEFiiMNYvfBtoLZ2opwVgd9G2ZbsoFkw+A1hW1M1SpiTsakmmFeH+1uzA9dfx79P8kO/7s=; path=/; expires=Sun, 14-Jan-24 19:29:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=sKrZFtpHlUC8zfUkb1HKHItVjYhzWHMgy2NX3NTu22c-1705258782390-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84581e13ac7a4294-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 13:59:42,353 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 13:59:42,354 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 13:59:42,448 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 13:59:42,449 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 13:59:42,449 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 13:59:42,449 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 13:59:42,452 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\n  "function_descriptions": [\n    "Authenticate user on Twitter API",\n    "Compose tweet content",\n    "Post tweet using Twitter API"\n  ]\n}\n\n  \n     \n  \n\n  \n  \n  ', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:15:40,803 - DEBUG - httpcore.connection - close.started
2024-01-14 14:15:40,875 - DEBUG - httpcore.connection - close.complete
2024-01-14 14:15:43,413 - INFO - __main__ - Skynet started
2024-01-14 14:15:43,413 - INFO - __main__ - Loading environment variables
2024-01-14 14:15:43,414 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 14:15:43,414 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 14:15:43,415 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 14:15:43,415 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 14:15:43,416 - INFO - __main__ - Loaded functions from functions
2024-01-14 14:15:43,416 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 14:15:43,417 - INFO - functions.get_functions - file size: 2609
2024-01-14 14:15:43,418 - INFO - functions.get_functions - tree size: 16
2024-01-14 14:15:43,614 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 14:15:43,769 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 14:15:43,770 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 14:15:43,770 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 14:15:43,771 - INFO - functions.get_functions - file size: 2493
2024-01-14 14:15:43,772 - INFO - functions.get_functions - tree size: 7
2024-01-14 14:15:43,772 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 14:15:43,774 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 14:15:43,774 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 14:15:43,775 - INFO - functions.get_functions - file size: 2971
2024-01-14 14:15:43,776 - INFO - functions.get_functions - tree size: 10
2024-01-14 14:15:43,776 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 14:15:43,777 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 14:15:43,778 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 14:15:43,778 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 14:15:43,779 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 14:15:43,780 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 14:15:43,780 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 14:15:43,782 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 14:15:43,782 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 14:15:43,782 - INFO - functions.get_functions - file size: 0
2024-01-14 14:15:43,782 - INFO - functions.get_functions - tree size: 0
2024-01-14 14:15:43,783 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 14:15:43,783 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 14:15:43,783 - INFO - functions.get_functions - file size: 3276
2024-01-14 14:15:43,784 - INFO - functions.get_functions - tree size: 9
2024-01-14 14:15:43,784 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 14:15:43,784 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 14:15:43,785 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 14:15:43,786 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 14:15:43,786 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 14:15:43,788 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 14:15:43,788 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 14:15:43,788 - INFO - functions.get_functions - file size: 0
2024-01-14 14:15:43,788 - INFO - functions.get_functions - tree size: 0
2024-01-14 14:15:43,788 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 14:15:43,789 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 14:15:43,789 - INFO - functions.get_functions - file size: 5276
2024-01-14 14:15:43,790 - INFO - functions.get_functions - tree size: 9
2024-01-14 14:15:43,791 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 14:15:43,793 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 14:15:43,794 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 14:15:43,796 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 14:15:43,796 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 14:15:43,797 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 14:15:43,798 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 14:15:49,245 - INFO - functions.openai_call - 
Sending Prompt:
Describe the steps that would need to be called to accomplishes the following: tweet to twitter

    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes

    return a JSON object with the following property
    
    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.
    
    JSON OBJECT:
    


2024-01-14 14:15:49,250 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: tweet to twitter\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:15:49,347 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 14:15:49,552 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8e68edb550>
2024-01-14 14:15:49,553 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8e69846570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 14:15:49,658 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8e68ed9ed0>
2024-01-14 14:15:49,659 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:15:49,660 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:15:49,660 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:15:49,660 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:15:49,660 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:15:50,787 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:15:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'712'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79864'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'102ms'), (b'x-request-id', b'ce94d63a2524d51e253169629b53feab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xms3ltRG2hZHKwBV3s.Qmfy0tE3JLfmqWJPRO5x9nPM-1705259750-1-AdekSkv2udmNwhPn8ADFqmPCbtzwqTATr3GnbIifrEQKwq8lYcauMmhwkC/H1fXJhXW0lWNfp2wFxtLdU0SZD6k=; path=/; expires=Sun, 14-Jan-24 19:45:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=P8yVabvvcrvnM0TUQBwP6eUqUEV5ZrR_jfJnvTV59GQ-1705259750707-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845835bb6c987d18-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:15:50,789 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:15:50,789 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:15:51,190 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:15:51,190 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:15:51,191 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:15:51,191 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:15:51,222 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\n  "function_descriptions": [\n    "Authenticate user with Twitter API",\n    "Create function to format and send tweet content",\n    "Call function to send tweet"\n  ]\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:15:51,223 - INFO - functions.openai_call - 
Sending Prompt:
Create a function that accomplishes the following: Authenticate user with Twitter API

    Using the python programming language.

    it should return a json object with the following properties:

    required_libraries: a list of strings

    source_code: a string

    The source code should ONLY be the function definition, including the function definition and the function body.

    JSON OBJECT:
    


2024-01-14 14:15:51,230 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: tweet to twitter\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Authenticate user with Twitter API\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string\n\n    The source code should ONLY be the function definition, including the function definition and the function body.\n\n    JSON OBJECT:\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:15:51,234 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:15:51,238 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:15:51,240 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:15:51,241 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:15:51,242 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:15:53,138 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:15:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1465'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79761'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'179ms'), (b'x-request-id', b'e3cb0fdf83f761062a61ff6fa6b46534'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845835c54a837d18-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:15:53,139 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:15:53,139 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:15:53,140 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:15:53,140 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:15:53,140 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:15:53,141 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:15:53,143 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\n  "function_descriptions": [\n    "Create function authenticate_user_twitter_API() to handle user authentication with the Twitter API"\n  ]\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:15:53,144 - ERROR - functions.prompt_creation - The json object returned from the language model did not contain the required fields.
2024-01-14 14:15:53,144 - ERROR - __main__ - Error creating step list for tweet to twitter
2024-01-14 14:15:53,246 - DEBUG - httpcore.connection - close.started
2024-01-14 14:15:53,247 - DEBUG - httpcore.connection - close.complete
2024-01-14 14:23:16,884 - INFO - __main__ - Skynet started
2024-01-14 14:23:16,884 - INFO - __main__ - Loading environment variables
2024-01-14 14:23:16,884 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 14:23:16,884 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 14:23:16,884 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 14:23:16,884 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 14:23:16,885 - INFO - __main__ - Loaded functions from functions
2024-01-14 14:23:16,885 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 14:23:16,885 - INFO - functions.get_functions - file size: 2609
2024-01-14 14:23:16,886 - INFO - functions.get_functions - tree size: 16
2024-01-14 14:23:17,015 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 14:23:17,175 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 14:23:17,184 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 14:23:17,185 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 14:23:17,190 - INFO - functions.get_functions - file size: 2493
2024-01-14 14:23:17,192 - INFO - functions.get_functions - tree size: 7
2024-01-14 14:23:17,192 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 14:23:17,200 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 14:23:17,200 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 14:23:17,201 - INFO - functions.get_functions - file size: 2971
2024-01-14 14:23:17,203 - INFO - functions.get_functions - tree size: 10
2024-01-14 14:23:17,203 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 14:23:17,205 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 14:23:17,208 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 14:23:17,215 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 14:23:17,216 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 14:23:17,217 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 14:23:17,218 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 14:23:17,228 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 14:23:17,229 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 14:23:17,229 - INFO - functions.get_functions - file size: 0
2024-01-14 14:23:17,230 - INFO - functions.get_functions - tree size: 0
2024-01-14 14:23:17,230 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 14:23:17,231 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 14:23:17,231 - INFO - functions.get_functions - file size: 3250
2024-01-14 14:23:17,232 - INFO - functions.get_functions - tree size: 9
2024-01-14 14:23:17,233 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 14:23:17,234 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 14:23:17,236 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 14:23:17,237 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 14:23:17,238 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 14:23:17,241 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 14:23:17,242 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 14:23:17,242 - INFO - functions.get_functions - file size: 0
2024-01-14 14:23:17,243 - INFO - functions.get_functions - tree size: 0
2024-01-14 14:23:17,243 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 14:23:17,243 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 14:23:17,245 - INFO - functions.get_functions - file size: 5276
2024-01-14 14:23:17,252 - INFO - functions.get_functions - tree size: 9
2024-01-14 14:23:17,256 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 14:23:17,259 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 14:23:17,263 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 14:23:17,270 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 14:23:17,271 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 14:23:17,272 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 14:23:17,279 - INFO - __main__ - The following 18 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields']
2024-01-14 14:23:21,294 - INFO - functions.openai_call - 
Sending Prompt:
Describe the steps that would need to be called to accomplishes the following: Tweet to twitter

    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes

    return a JSON object with the following property
    
    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.
    
    JSON OBJECT:
    


2024-01-14 14:23:21,341 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Tweet to twitter\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:23:21,362 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 14:23:22,584 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89d11060d0>
2024-01-14 14:23:22,584 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89d129a570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 14:23:22,690 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89d1106390>
2024-01-14 14:23:22,690 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:23:22,691 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:23:22,691 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:23:22,692 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:23:22,692 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:23:24,429 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:23:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1575'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79864'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'102ms'), (b'x-request-id', b'fc73eb4dabecf36bbd2665b4120c1619'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jAVo6ZHvyIcxRqMJK0ov3Pll8pCcAQqXzReJy1Wk_fM-1705260204-1-AfaNjYL1zcoJN3w2Vt8IDPI1/aM5cVBoFF3cS4E11QYAoHG0tpKCgJ7ukTw9rKSenfBDsI1zLfvKKc8uSL+cH0M=; path=/; expires=Sun, 14-Jan-24 19:53:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LkBhHM.FFj8.P1gVN.z55nWwWAq1f7qrTgTIdVbQBlw-1705260204372-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845840cac9da72a7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:23:24,431 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:23:24,431 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:23:24,431 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:23:24,432 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:23:24,432 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:23:24,432 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:23:24,435 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\n  "function_descriptions": [\n    "Initialize API credentials for Twitter",\n    "Create a function to format the tweet message",\n    "Create a function to authenticate with the Twitter API",\n    "Create a function to make the actual tweet"\n  ]\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:23:24,435 - INFO - functions.openai_call - 
Sending Prompt:
Create a function that accomplishes the following: Initialize API credentials for Twitter

    Using the python programming language.

    it should return a json object with the following properties:

    required_libraries: a list of strings

    source_code: a string containing just the function definition and the function body (no imports or anything else)

    JSON OBJECT:
    


2024-01-14 14:23:24,441 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Tweet to twitter\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Initialize API credentials for Twitter\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:23:24,442 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:23:24,443 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:23:24,443 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:23:24,443 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:23:24,443 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:23:25,865 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:23:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'967'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79767'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'174ms'), (b'x-request-id', b'81c6f1a305f24f5ebc7d28ae1a4259bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845840d5bdb172a7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:23:25,866 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:23:25,866 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:23:25,867 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:23:25,867 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:23:25,868 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:23:25,868 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:23:25,870 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\n  "required_libraries": ["tweepy"],\n  "source_code": "def initialize_twitter_api(api_key, api_secret_key, access_token, access_token_secret):\\n    auth = tweepy.OAuthHandler(api_key, api_secret_key)\\n    auth.set_access_token(access_token, access_token_secret)\\n    api = tweepy.API(auth)\\n    return api"\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:23:25,871 - INFO - __main__ - Make sure the library tweepy is installed
2024-01-14 14:23:25,871 - INFO - functions.file_system_primitives - Writing to file ./functions/generated_functions.py
2024-01-14 14:23:25,872 - INFO - functions.openai_call - 
Sending Prompt:
Create a function that accomplishes the following: Create a function to format the tweet message

    Using the python programming language.

    it should return a json object with the following properties:

    required_libraries: a list of strings

    source_code: a string containing just the function definition and the function body (no imports or anything else)

    JSON OBJECT:
    


2024-01-14 14:23:25,883 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Tweet to twitter\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Initialize API credentials for Twitter\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Create a function to format the tweet message\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:23:25,886 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:23:25,887 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:23:25,888 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:23:25,888 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:23:25,890 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:23:28,224 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:23:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1768'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79668'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'249ms'), (b'x-request-id', b'37cf77909a5ab68f0bc746dfe778ff3f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845840decc6172a7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:23:28,226 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:23:28,226 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:23:28,227 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:23:28,228 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:23:28,229 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:23:28,229 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:23:28,233 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\n  "function_descriptions": [\n    "Initialize API credentials for Twitter. This function should store and return the necessary API credentials.",\n    "Create a function to format the tweet message. This function should take in parameters for the message and any additional formatting, and return the formatted message ready to be tweeted."\n  ]\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:23:28,234 - ERROR - functions.prompt_creation - The json object returned from the language model did not contain the required fields.
2024-01-14 14:23:28,236 - ERROR - __main__ - Error creating step list for Tweet to twitter
2024-01-14 14:23:28,500 - DEBUG - httpcore.connection - close.started
2024-01-14 14:23:28,501 - DEBUG - httpcore.connection - close.complete
2024-01-14 14:26:21,766 - INFO - __main__ - Skynet started
2024-01-14 14:26:21,766 - INFO - __main__ - Loading environment variables
2024-01-14 14:26:21,766 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-3.5-turbo-1106
2024-01-14 14:26:21,767 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 14:26:21,767 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 14:26:21,767 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 14:26:21,767 - INFO - __main__ - Loaded functions from functions
2024-01-14 14:26:21,767 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 14:26:21,767 - INFO - functions.get_functions - file size: 2609
2024-01-14 14:26:21,768 - INFO - functions.get_functions - tree size: 16
2024-01-14 14:26:22,034 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 14:26:22,175 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 14:26:22,176 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 14:26:22,177 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 14:26:22,177 - INFO - functions.get_functions - file size: 2493
2024-01-14 14:26:22,177 - INFO - functions.get_functions - tree size: 7
2024-01-14 14:26:22,178 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 14:26:22,180 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 14:26:22,180 - INFO - __main__ - Trying to load functions from ./functions/generated_functions.py
2024-01-14 14:26:22,180 - INFO - functions.get_functions - file size: 246
2024-01-14 14:26:22,180 - INFO - functions.get_functions - tree size: 1
2024-01-14 14:26:22,180 - INFO - functions.get_functions - Looking at function: initialize_twitter_api
2024-01-14 14:26:22,181 - INFO - __main__ - Loaded 1 functions from ./functions/generated_functions.py
2024-01-14 14:26:22,181 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 14:26:22,181 - INFO - functions.get_functions - file size: 2971
2024-01-14 14:26:22,182 - INFO - functions.get_functions - tree size: 10
2024-01-14 14:26:22,182 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 14:26:22,183 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 14:26:22,184 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 14:26:22,185 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 14:26:22,185 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 14:26:22,186 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 14:26:22,186 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 14:26:22,188 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 14:26:22,188 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 14:26:22,188 - INFO - functions.get_functions - file size: 0
2024-01-14 14:26:22,188 - INFO - functions.get_functions - tree size: 0
2024-01-14 14:26:22,188 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 14:26:22,188 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 14:26:22,188 - INFO - functions.get_functions - file size: 3250
2024-01-14 14:26:22,189 - INFO - functions.get_functions - tree size: 9
2024-01-14 14:26:22,189 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 14:26:22,190 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 14:26:22,191 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 14:26:22,191 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 14:26:22,192 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 14:26:22,193 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 14:26:22,193 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 14:26:22,193 - INFO - functions.get_functions - file size: 0
2024-01-14 14:26:22,193 - INFO - functions.get_functions - tree size: 0
2024-01-14 14:26:22,193 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 14:26:22,194 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 14:26:22,194 - INFO - functions.get_functions - file size: 5276
2024-01-14 14:26:22,195 - INFO - functions.get_functions - tree size: 9
2024-01-14 14:26:22,196 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 14:26:22,198 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 14:26:22,199 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 14:26:22,201 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 14:26:22,201 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 14:26:22,202 - INFO - functions.prompt_creation - Describing function
2024-01-14 14:26:22,202 - INFO - functions.openai_call - 
Sending Prompt:
Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: 
    
    def initialize_twitter_api(api_key, api_secret_key, access_token, access_token_secret):
    auth = tweepy.OAuthHandler(api_key, api_secret_key)
    auth.set_access_token(access_token, access_token_secret)
    api = tweepy.API(auth)
    return api
    
    Description:


2024-01-14 14:26:22,207 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def initialize_twitter_api(api_key, api_secret_key, access_token, access_token_secret):\n    auth = tweepy.OAuthHandler(api_key, api_secret_key)\n    auth.set_access_token(access_token, access_token_secret)\n    api = tweepy.API(auth)\n    return api\n    \n    Description:'}], 'model': 'gpt-3.5-turbo-1106'}}
2024-01-14 14:26:22,225 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 14:26:22,402 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f08ce85ce50>
2024-01-14 14:26:22,403 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f08ce9ee570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 14:26:22,509 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f08ce086710>
2024-01-14 14:26:22,510 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:26:22,510 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:26:22,511 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:26:22,511 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:26:22,511 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:26:23,734 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:26:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1049'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79878'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'91ms'), (b'x-request-id', b'a41998983f9a8d5cef6a212806d5e051'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=UJVP7YY.nsY8L1sForRGPSL7iZY82IC1UX69wsRgzNo-1705260383-1-AR/2b1DfgB22f0fmBGvKY26YSm6tcFGzdnS+w307OGoDdcur+J1JnVJRtFO4WVh+F7LB1FyxzclJSHFrKENFDYQ=; path=/; expires=Sun, 14-Jan-24 19:56:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Af4V7HnzqAGLr3g0GGWy8r0TvlMlNCIVyK991aKnT9Y-1705260383656-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8458452ea98a6a4f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:26:23,736 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:26:23,736 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:26:23,737 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:26:23,737 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:26:23,737 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:26:23,737 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:26:23,740 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 14:26:23,741 - INFO - __main__ - The following 19 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields', 'initialize_twitter_api']
2024-01-14 14:26:34,564 - INFO - functions.openai_call - 
Sending Prompt:
Describe the steps that would need to be called to accomplishes the following: Send an email to my co-worker with email robert@pretension.io

    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes

    return a JSON object with the following property
    
    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.
    
    JSON OBJECT:
    


2024-01-14 14:26:34,586 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def initialize_twitter_api(api_key, api_secret_key, access_token, access_token_secret):\n    auth = tweepy.OAuthHandler(api_key, api_secret_key)\n    auth.set_access_token(access_token, access_token_secret)\n    api = tweepy.API(auth)\n    return api\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Send an email to my co-worker with email robert@pretension.io\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:26:34,589 - DEBUG - httpcore.connection - close.started
2024-01-14 14:26:34,590 - DEBUG - httpcore.connection - close.complete
2024-01-14 14:26:34,591 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 14:26:34,793 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f08ce072890>
2024-01-14 14:26:34,794 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f08ce9ee570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 14:26:35,001 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f08ce072150>
2024-01-14 14:26:35,002 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:26:35,002 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:26:35,002 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:26:35,002 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:26:35,003 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:26:36,643 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:26:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'1484'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79747'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'189ms'), (b'x-request-id', b'6d3ddf13a396846b0c2bd96163c001a2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8458457cbcae8cbf-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:26:36,643 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:26:36,644 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:26:36,644 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:26:36,644 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:26:36,644 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:26:36,644 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:26:36,647 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\n  "function_descriptions": [\n    "Create a function that initializes an email service with provider credentials",\n    "Create a function that generates an email body and subject",\n    "Create a function that sends the email to a specified recipient"\n  ]\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:26:36,647 - INFO - functions.openai_call - 
Sending Prompt:
Create a function that accomplishes the following: Create a function that initializes an email service with provider credentials

    Using the python programming language.

    it should return a json object with the following properties:

    required_libraries: a list of strings

    source_code: a string containing just the function definition and the function body (no imports or anything else)

    JSON OBJECT:
    


2024-01-14 14:26:36,657 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the function, using the input variables. Make the description succinct though covering its entire functionality using plain english: \n    \n    def initialize_twitter_api(api_key, api_secret_key, access_token, access_token_secret):\n    auth = tweepy.OAuthHandler(api_key, api_secret_key)\n    auth.set_access_token(access_token, access_token_secret)\n    api = tweepy.API(auth)\n    return api\n    \n    Description:'}, {'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Send an email to my co-worker with email robert@pretension.io\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Create a function that initializes an email service with provider credentials\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}], 'model': 'gpt-3.5-turbo-1106', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:26:36,659 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:26:36,660 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:26:36,661 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:26:36,662 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:26:36,662 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:26:37,353 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:26:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-1106'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'295'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79640'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'270ms'), (b'x-request-id', b'66a50614a27d4cfc582ac666d0439cc4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845845871acf8cbf-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:26:37,354 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:26:37,354 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:26:37,355 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:26:37,355 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:26:37,355 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:26:37,355 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:26:37,357 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\n    "function_descriptions": [\n        "Initialize an email service with provider credentials"\n    ]\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:26:37,358 - ERROR - functions.prompt_creation - The json object returned from the language model did not contain the required fields.
2024-01-14 14:26:37,358 - ERROR - __main__ - Error creating step list for Send an email to my co-worker with email robert@pretension.io
2024-01-14 14:26:37,478 - DEBUG - httpcore.connection - close.started
2024-01-14 14:26:37,480 - DEBUG - httpcore.connection - close.complete
2024-01-14 14:29:24,749 - INFO - __main__ - Skynet started
2024-01-14 14:29:24,750 - INFO - __main__ - Loading environment variables
2024-01-14 14:29:24,750 - INFO - functions.file_system_primitives - Setting environment variable DEFAULT_GPT_MODEL to default value gpt-4-1106-preview
2024-01-14 14:29:24,750 - INFO - functions.file_system_primitives - Setting environment variable FUNCTIONS_FOLDER to default value functions
2024-01-14 14:29:24,750 - INFO - functions.file_system_primitives - Setting environment variable FUNCTION_INFO_SERIALIZATION_FILES to default value serialized_function_info.json
2024-01-14 14:29:24,750 - INFO - functions.file_system_primitives - Listing files in directory functions
2024-01-14 14:29:24,750 - INFO - __main__ - Loaded functions from functions
2024-01-14 14:29:24,751 - INFO - __main__ - Trying to load functions from ./functions/web_browsing.py
2024-01-14 14:29:24,751 - INFO - functions.get_functions - file size: 2609
2024-01-14 14:29:24,752 - INFO - functions.get_functions - tree size: 16
2024-01-14 14:29:24,961 - INFO - functions.get_functions - Looking at function: get_links
2024-01-14 14:29:25,153 - INFO - functions.get_functions - Looking at function: process_command
2024-01-14 14:29:25,154 - INFO - __main__ - Loaded 2 functions from ./functions/web_browsing.py
2024-01-14 14:29:25,155 - INFO - __main__ - Trying to load functions from ./functions/openai_call.py
2024-01-14 14:29:25,155 - INFO - functions.get_functions - file size: 2493
2024-01-14 14:29:25,156 - INFO - functions.get_functions - tree size: 7
2024-01-14 14:29:25,157 - INFO - functions.get_functions - Looking at function: return_gpt_response
2024-01-14 14:29:25,160 - INFO - __main__ - Loaded 1 functions from ./functions/openai_call.py
2024-01-14 14:29:25,161 - INFO - __main__ - Trying to load functions from ./functions/generated_functions.py
2024-01-14 14:29:25,171 - INFO - functions.get_functions - file size: 246
2024-01-14 14:29:25,172 - INFO - functions.get_functions - tree size: 1
2024-01-14 14:29:25,172 - INFO - functions.get_functions - Looking at function: initialize_twitter_api
2024-01-14 14:29:25,173 - INFO - __main__ - Loaded 1 functions from ./functions/generated_functions.py
2024-01-14 14:29:25,174 - INFO - __main__ - Trying to load functions from ./functions/file_system_primitives.py
2024-01-14 14:29:25,176 - INFO - functions.get_functions - file size: 2971
2024-01-14 14:29:25,177 - INFO - functions.get_functions - tree size: 10
2024-01-14 14:29:25,178 - INFO - functions.get_functions - Looking at function: read_file
2024-01-14 14:29:25,180 - INFO - functions.get_functions - Looking at function: write_file
2024-01-14 14:29:25,181 - INFO - functions.get_functions - Looking at function: append_to_file
2024-01-14 14:29:25,183 - INFO - functions.get_functions - Looking at function: delete_file
2024-01-14 14:29:25,186 - INFO - functions.get_functions - Looking at function: list_files_in_directory
2024-01-14 14:29:25,189 - INFO - functions.get_functions - Looking at function: get_current_working_directory
2024-01-14 14:29:25,190 - INFO - functions.get_functions - Looking at function: set_env_variables_with_defaults
2024-01-14 14:29:25,193 - INFO - __main__ - Loaded 7 functions from ./functions/file_system_primitives.py
2024-01-14 14:29:25,194 - INFO - __main__ - Trying to load functions from ./functions/__init__.py
2024-01-14 14:29:25,195 - INFO - functions.get_functions - file size: 0
2024-01-14 14:29:25,195 - INFO - functions.get_functions - tree size: 0
2024-01-14 14:29:25,196 - INFO - __main__ - Loaded 0 functions from ./functions/__init__.py
2024-01-14 14:29:25,196 - INFO - __main__ - Trying to load functions from ./functions/prompt_creation.py
2024-01-14 14:29:25,197 - INFO - functions.get_functions - file size: 3250
2024-01-14 14:29:25,198 - INFO - functions.get_functions - tree size: 9
2024-01-14 14:29:25,204 - INFO - functions.get_functions - Looking at function: return_function_options
2024-01-14 14:29:25,207 - INFO - functions.get_functions - Looking at function: create_function
2024-01-14 14:29:25,208 - INFO - functions.get_functions - Looking at function: create_step_list
2024-01-14 14:29:25,210 - INFO - functions.get_functions - Looking at function: required_fields
2024-01-14 14:29:25,212 - INFO - functions.get_functions - Looking at function: describe_function
2024-01-14 14:29:25,217 - INFO - __main__ - Loaded 5 functions from ./functions/prompt_creation.py
2024-01-14 14:29:25,218 - INFO - __main__ - Trying to load functions from ./functions/system_loop_primatives.py
2024-01-14 14:29:25,219 - INFO - functions.get_functions - file size: 0
2024-01-14 14:29:25,219 - INFO - functions.get_functions - tree size: 0
2024-01-14 14:29:25,220 - INFO - __main__ - Loaded 0 functions from ./functions/system_loop_primatives.py
2024-01-14 14:29:25,220 - INFO - __main__ - Trying to load functions from ./functions/get_functions.py
2024-01-14 14:29:25,221 - INFO - functions.get_functions - file size: 5276
2024-01-14 14:29:25,228 - INFO - functions.get_functions - tree size: 9
2024-01-14 14:29:25,230 - INFO - functions.get_functions - Looking at function: load_functions_from_file
2024-01-14 14:29:25,233 - INFO - functions.get_functions - Looking at function: list_functions
2024-01-14 14:29:25,235 - INFO - functions.get_functions - Looking at function: get_argument_values
2024-01-14 14:29:25,238 - INFO - __main__ - Loaded 3 functions from ./functions/get_functions.py
2024-01-14 14:29:25,240 - INFO - system_objects.functions - Loading function infos from serialized_function_info.json
2024-01-14 14:29:25,242 - INFO - system_objects.functions - Saving function infos to serialized_function_info.json
2024-01-14 14:29:25,244 - INFO - __main__ - The following 19 function(s) were loaded: ['load_functions_from_file', 'list_functions', 'get_argument_values', 'get_links', 'process_command', 'return_gpt_response', 'read_file', 'write_file', 'append_to_file', 'delete_file', 'list_files_in_directory', 'get_current_working_directory', 'set_env_variables_with_defaults', 'return_function_options', 'create_function', 'create_step_list', 'describe_function', 'required_fields', 'initialize_twitter_api']
2024-01-14 14:29:36,732 - INFO - functions.openai_call - 
Sending Prompt:
Describe the steps that would need to be called to accomplishes the following: Send an email to my co-worker with email robert@pretension.io

    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes

    return a JSON object with the following property
    
    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.
    
    JSON OBJECT:
    


2024-01-14 14:29:36,739 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Send an email to my co-worker with email robert@pretension.io\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}], 'model': 'gpt-4-1106-preview', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:29:36,756 - DEBUG - httpcore.connection - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-14 14:29:36,967 - DEBUG - httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fcba7ce60d0>
2024-01-14 14:29:36,967 - DEBUG - httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fcba8656570> server_hostname='api.openai.com' timeout=5.0
2024-01-14 14:29:37,072 - DEBUG - httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fcba7cf4c50>
2024-01-14 14:29:37,072 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:29:37,073 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:29:37,073 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:29:37,074 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:29:37,074 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:29:41,985 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:29:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'4748'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'1500000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'1499853'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'8.467s'), (b'x-request-id', b'3a2d7f80d6a8331b70112bf3784ed116'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=q6pOoch6AA9k7UTBQX2qchBM9gw0WVvmHGT4mck68IY-1705260581-1-AVkdYKZ5oIgs13wU5aLww3KCROcFh1MOEH0AvdS/5cr4m7Jul/wQ8zCsmQTGR1Pm7tURRtrywnr5gdarJXazS/g=; path=/; expires=Sun, 14-Jan-24 19:59:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=IvdBuJhFPqoiF_ZQRGXHQcuIF.ZtvtMR91sPi.9TrxI-1705260581924-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'845849eead008cb1-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:29:41,987 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:29:42,019 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:29:42,020 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:29:42,021 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:29:42,022 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:29:42,023 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:29:42,029 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\n{\n  "function_descriptions": [\n    "Initialize email client: This function initializes the email client and sets up the connection with necessary credentials for sending an email.",\n    "Compose email: This function takes the recipient\'s address, subject, and body of the email as inputs and creates an email object ready to be sent.",\n    "Validate email address: This function checks if the given email address is valid to ensure the email can be delivered.",\n    "Send email: This function takes a composed email object and sends it to the specified recipient using the email client.",\n    "Generate result JSON: This function creates and returns a JSON object with details about the success or failure of the email sending operation."\n  ]\n}\n\n\n \n \n\n \n\n \n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n ', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:29:42,032 - INFO - functions.openai_call - 
Sending Prompt:
Create a function that accomplishes the following: Initialize email client: This function initializes the email client and sets up the connection with necessary credentials for sending an email.

    Using the python programming language.

    it should return a json object with the following properties:

    required_libraries: a list of strings

    source_code: a string containing just the function definition and the function body (no imports or anything else)

    JSON OBJECT:
    


2024-01-14 14:29:42,051 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Send an email to my co-worker with email robert@pretension.io\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Initialize email client: This function initializes the email client and sets up the connection with necessary credentials for sending an email.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}], 'model': 'gpt-4-1106-preview', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:29:42,052 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:29:42,053 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:29:42,053 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:29:42,053 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:29:42,053 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:29:47,925 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:29:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'5688'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'1500000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'1499547'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'26.08s'), (b'x-request-id', b'e18046f0508e04593e8a5211436362a1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84584a0dcf848cb1-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:29:47,927 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:29:47,927 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:29:47,928 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:29:47,928 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:29:47,929 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:29:47,930 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:29:47,937 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\n    \t{\n\t    "required_libraries": ["smtplib", "email"],\n\t    "source_code": "def initialize_email_client(server_address, server_port, username, password):\\n    import smtplib\\n    from email.mime.text import MIMEText\\n    from email.mime.multipart import MIMEMultipart\\n\\n    # Create SMTP session for sending the mail\\n    session = smtplib.SMTP(server_address, server_port)\\n    session.starttls() # enable security\\n    session.login(username, password)\\n    return session"\n\t}\n    ', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:29:47,938 - INFO - __main__ - Make sure the library smtplib is installed
2024-01-14 14:29:47,939 - INFO - __main__ - Make sure the library email is installed
2024-01-14 14:29:47,939 - INFO - functions.file_system_primitives - Writing to file ./functions/generated_functions.py
2024-01-14 14:29:47,941 - INFO - functions.openai_call - 
Sending Prompt:
Create a function that accomplishes the following: Compose email: This function takes the recipient's address, subject, and body of the email as inputs and creates an email object ready to be sent.

    Using the python programming language.

    it should return a json object with the following properties:

    required_libraries: a list of strings

    source_code: a string containing just the function definition and the function body (no imports or anything else)

    JSON OBJECT:
    


2024-01-14 14:29:47,950 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Send an email to my co-worker with email robert@pretension.io\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Initialize email client: This function initializes the email client and sets up the connection with necessary credentials for sending an email.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}, {'role': 'user', 'content': "Create a function that accomplishes the following: Compose email: This function takes the recipient's address, subject, and body of the email as inputs and creates an email object ready to be sent.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    "}], 'model': 'gpt-4-1106-preview', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:29:47,953 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:29:47,954 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:29:47,954 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:29:47,954 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:29:47,955 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:29:55,810 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:29:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'7627'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'1500000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'1499210'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'45.463s'), (b'x-request-id', b'66ca419c2625d437463862abaf8562d9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84584a32ac648cb1-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:29:55,811 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:29:55,812 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:29:55,812 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:29:55,813 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:29:55,816 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:29:55,816 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:29:55,820 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\n{\n  "required_libraries": [\n    "email.mime.text",\n    "email.mime.multipart"\n  ],\n  "source_code": "def compose_email(to_address, subject, body):\\n    # Create a MIMEText object to represent the email\\n    from email.mime.multipart import MIMEMultipart\\n    from email.mime.text import MIMEText\\n\\n    # Create a message object using MIMEMultipart\\n    message = MIMEMultipart()\\n    message[\'To\'] = to_address\\n    message[\'Subject\'] = subject\\n\\n    # Attach the email body to the message. It is assumed body is a plain text\\n    message.attach(MIMEText(body, \'plain\'))\\n\\n    return message"\n}\n', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:29:55,820 - INFO - __main__ - Make sure the library email.mime.text is installed
2024-01-14 14:29:55,820 - INFO - __main__ - Make sure the library email.mime.multipart is installed
2024-01-14 14:29:55,820 - INFO - functions.file_system_primitives - Writing to file ./functions/generated_functions.py
2024-01-14 14:29:55,821 - INFO - functions.openai_call - 
Sending Prompt:
Create a function that accomplishes the following: Validate email address: This function checks if the given email address is valid to ensure the email can be delivered.

    Using the python programming language.

    it should return a json object with the following properties:

    required_libraries: a list of strings

    source_code: a string containing just the function definition and the function body (no imports or anything else)

    JSON OBJECT:
    


2024-01-14 14:29:55,829 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Send an email to my co-worker with email robert@pretension.io\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Initialize email client: This function initializes the email client and sets up the connection with necessary credentials for sending an email.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}, {'role': 'user', 'content': "Create a function that accomplishes the following: Compose email: This function takes the recipient's address, subject, and body of the email as inputs and creates an email object ready to be sent.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    "}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Validate email address: This function checks if the given email address is valid to ensure the email can be delivered.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}], 'model': 'gpt-4-1106-preview', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:29:55,830 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:29:55,831 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:29:55,831 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:29:55,831 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:29:55,831 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:30:01,749 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:30:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'5573'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'1500000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'1498778'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1m10.356s'), (b'x-request-id', b'725352a950caca3a4510ded2f74bd70d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84584a63ea638cb1-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:30:01,750 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:30:01,750 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:30:01,751 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:30:01,752 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:30:01,752 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:30:01,752 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:30:01,756 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\n{\n    "required_libraries": ["re"],\n    "source_code": "def validate_email_address(email_address):\\n    # Using a simple regex pattern to validate email address.\\n    # This pattern can be replaced or modified to suit more specific validation requirements.\\n    pattern = r\'(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+$)\'\\n    if re.match(pattern, email_address):\\n        return True\\n    else:\\n        return False"\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:30:01,756 - INFO - __main__ - Make sure the library re is installed
2024-01-14 14:30:01,756 - INFO - functions.file_system_primitives - Writing to file ./functions/generated_functions.py
2024-01-14 14:30:01,757 - INFO - functions.openai_call - 
Sending Prompt:
Create a function that accomplishes the following: Send email: This function takes a composed email object and sends it to the specified recipient using the email client.

    Using the python programming language.

    it should return a json object with the following properties:

    required_libraries: a list of strings

    source_code: a string containing just the function definition and the function body (no imports or anything else)

    JSON OBJECT:
    


2024-01-14 14:30:01,767 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Send an email to my co-worker with email robert@pretension.io\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Initialize email client: This function initializes the email client and sets up the connection with necessary credentials for sending an email.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}, {'role': 'user', 'content': "Create a function that accomplishes the following: Compose email: This function takes the recipient's address, subject, and body of the email as inputs and creates an email object ready to be sent.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    "}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Validate email address: This function checks if the given email address is valid to ensure the email can be delivered.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Send email: This function takes a composed email object and sends it to the specified recipient using the email client.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}], 'model': 'gpt-4-1106-preview', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:30:01,769 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:30:01,769 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:30:01,770 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:30:01,770 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:30:01,770 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:30:06,462 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:30:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'4517'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'1500000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'1498255'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1m40.483s'), (b'x-request-id', b'c361922b97a117450ba300657502ae8a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84584a890f808cb1-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:30:06,463 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:30:06,463 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:30:06,463 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:30:06,463 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:30:06,464 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:30:06,464 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:30:06,468 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\n{\n    "required_libraries": ["smtplib"],\n    "source_code": "def send_email(email_obj, email_client):\\n    \\"\\"\\"Sends an email object using the given email client.\\n\\n    Args:\\n        email_obj: An email object that contains the recipient address, subject, and body.\\n        email_client: An initialized email client configured to send emails.\\n\\n    Returns:\\n        Sends the email and does not return a value.\\n    \\"\\"\\"\\n    try:\\n        # Use the send_message method of email_client to send the email\\n        email_client.send_message(email_obj)\\n        print(\'Email sent successfully\')\\n    except Exception as e:\\n        print(\'Failed to send email:\', e)\\n"\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:30:06,476 - INFO - __main__ - Make sure the library smtplib is installed
2024-01-14 14:30:06,477 - INFO - functions.file_system_primitives - Writing to file ./functions/generated_functions.py
2024-01-14 14:30:06,479 - INFO - functions.openai_call - 
Sending Prompt:
Create a function that accomplishes the following: Generate result JSON: This function creates and returns a JSON object with details about the success or failure of the email sending operation.

    Using the python programming language.

    it should return a json object with the following properties:

    required_libraries: a list of strings

    source_code: a string containing just the function definition and the function body (no imports or anything else)

    JSON OBJECT:
    


2024-01-14 14:30:06,507 - DEBUG - openai._base_client - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Describe the steps that would need to be called to accomplishes the following: Send an email to my co-worker with email robert@pretension.io\n\n    When coming up with this list, describe "abstract" functions that will be re-useable for other purposes\n\n    return a JSON object with the following property\n    \n    function_descriptions: a list of strings that describe the functions used to accomplish the goal. Each list item should just describe in plain english what the functions should do.\n    \n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Initialize email client: This function initializes the email client and sets up the connection with necessary credentials for sending an email.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}, {'role': 'user', 'content': "Create a function that accomplishes the following: Compose email: This function takes the recipient's address, subject, and body of the email as inputs and creates an email object ready to be sent.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    "}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Validate email address: This function checks if the given email address is valid to ensure the email can be delivered.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Send email: This function takes a composed email object and sends it to the specified recipient using the email client.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}, {'role': 'user', 'content': 'Create a function that accomplishes the following: Generate result JSON: This function creates and returns a JSON object with details about the success or failure of the email sending operation.\n\n    Using the python programming language.\n\n    it should return a json object with the following properties:\n\n    required_libraries: a list of strings\n\n    source_code: a string containing just the function definition and the function body (no imports or anything else)\n\n    JSON OBJECT:\n    '}], 'model': 'gpt-4-1106-preview', 'response_format': {'type': 'json_object'}}}
2024-01-14 14:30:06,510 - DEBUG - httpcore.http11 - send_request_headers.started request=<Request [b'POST']>
2024-01-14 14:30:06,511 - DEBUG - httpcore.http11 - send_request_headers.complete
2024-01-14 14:30:06,513 - DEBUG - httpcore.http11 - send_request_body.started request=<Request [b'POST']>
2024-01-14 14:30:06,514 - DEBUG - httpcore.http11 - send_request_body.complete
2024-01-14 14:30:06,516 - DEBUG - httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>
2024-01-14 14:30:08,815 - DEBUG - httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 14 Jan 2024 19:30:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-codnuftfktazlnfurmq8wq2u'), (b'openai-processing-ms', b'2082'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'1500000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'1497568'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'2m20.036s'), (b'x-request-id', b'a5855963c2881a136b097885539146c3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84584aa6ab1c8cb1-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-14 14:30:08,816 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-14 14:30:08,816 - DEBUG - httpcore.http11 - receive_response_body.started request=<Request [b'POST']>
2024-01-14 14:30:08,817 - DEBUG - httpcore.http11 - receive_response_body.complete
2024-01-14 14:30:08,817 - DEBUG - httpcore.http11 - response_closed.started
2024-01-14 14:30:08,817 - DEBUG - httpcore.http11 - response_closed.complete
2024-01-14 14:30:08,818 - DEBUG - openai._base_client - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-14 14:30:08,820 - INFO - functions.openai_call - Converting response Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\n{\n    "required_libraries": ["json"],\n    "source_code": "def generate_result_json(status, message):\\n    result = { \'status\': status, \'message\': message }\\n    return json.dumps(result)"\n}', role='assistant', function_call=None, tool_calls=None)) to json object
2024-01-14 14:30:08,820 - INFO - __main__ - Make sure the library json is installed
2024-01-14 14:30:08,820 - INFO - functions.file_system_primitives - Writing to file ./functions/generated_functions.py
2024-01-14 14:34:03,550 - DEBUG - httpcore.connection - close.started
2024-01-14 14:34:03,550 - DEBUG - httpcore.connection - close.complete
